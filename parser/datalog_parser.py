# Generated from Datalog.g4 by ANTLR 4.8
# encoding: utf-8
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
	from typing import TextIO
else:
	from typing.io import TextIO




def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3.")
        buf.write("\u0167\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7")
        buf.write("\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r\4\16")
        buf.write("\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23\t\23")
        buf.write("\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\3\2\3\2\3\2\3")
        buf.write("\2\3\2\3\2\3\2\3\2\7\2\67\n\2\f\2\16\2:\13\2\3\2\3\2\3")
        buf.write("\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\7\3F\n\3\f\3\16\3I\13\3")
        buf.write("\3\3\3\3\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\7\4W")
        buf.write("\n\4\f\4\16\4Z\13\4\3\4\3\4\3\4\3\5\3\5\3\5\3\5\3\5\3")
        buf.write("\5\3\6\3\6\3\6\3\6\3\6\3\6\7\6k\n\6\f\6\16\6n\13\6\3\6")
        buf.write("\3\6\3\7\3\7\3\7\5\7u\n\7\3\7\3\7\5\7y\n\7\3\7\3\7\5\7")
        buf.write("}\n\7\3\7\3\7\3\7\3\7\3\7\3\7\3\7\5\7\u0086\n\7\3\7\3")
        buf.write("\7\3\7\3\b\3\b\3\b\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t")
        buf.write("\3\t\3\t\3\t\3\t\5\t\u009b\n\t\3\t\3\t\7\t\u009f\n\t\f")
        buf.write("\t\16\t\u00a2\13\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t")
        buf.write("\3\t\3\t\3\t\5\t\u00b0\n\t\3\t\3\t\3\n\3\n\3\n\3\n\3\13")
        buf.write("\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13")
        buf.write("\3\13\3\13\3\13\3\13\3\13\5\13\u00c9\n\13\3\13\3\13\3")
        buf.write("\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13")
        buf.write("\3\13\5\13\u00d9\n\13\7\13\u00db\n\13\f\13\16\13\u00de")
        buf.write("\13\13\3\13\3\13\3\13\3\f\3\f\3\f\3\f\3\f\3\f\3\f\3\f")
        buf.write("\3\r\3\r\3\r\3\r\3\r\3\r\3\r\3\r\3\r\3\16\3\16\3\16\3")
        buf.write("\16\3\16\5\16\u00f9\n\16\3\16\3\16\3\16\3\16\3\16\3\16")
        buf.write("\5\16\u0101\n\16\3\16\3\16\3\17\3\17\3\17\3\17\3\17\3")
        buf.write("\17\3\17\3\17\3\17\5\17\u010e\n\17\3\17\3\17\3\17\3\20")
        buf.write("\3\20\3\20\3\20\3\20\3\20\5\20\u0119\n\20\3\21\3\21\3")
        buf.write("\21\3\21\3\21\3\21\3\21\3\21\3\21\3\22\3\22\3\22\3\22")
        buf.write("\3\22\3\22\3\22\3\23\3\23\3\23\3\23\3\23\3\23\3\23\3\23")
        buf.write("\3\23\3\23\3\23\3\23\5\23\u0137\n\23\3\24\3\24\3\24\3")
        buf.write("\24\3\24\3\24\3\24\3\24\3\24\3\24\5\24\u0143\n\24\3\25")
        buf.write("\3\25\3\25\3\25\3\25\3\25\3\25\3\25\5\25\u014d\n\25\3")
        buf.write("\26\3\26\3\26\3\26\5\26\u0153\n\26\3\27\3\27\3\27\3\27")
        buf.write("\3\27\3\27\3\27\3\27\3\27\3\27\3\27\3\27\3\27\3\27\3\27")
        buf.write("\3\27\5\27\u0165\n\27\3\27\2\2\30\2\4\6\b\n\f\16\20\22")
        buf.write("\24\26\30\32\34\36 \"$&(*,\2\2\2\u0180\2.\3\2\2\2\4=\3")
        buf.write("\2\2\2\6L\3\2\2\2\b^\3\2\2\2\nd\3\2\2\2\fq\3\2\2\2\16")
        buf.write("\u008a\3\2\2\2\20\u008d\3\2\2\2\22\u00b3\3\2\2\2\24\u00b7")
        buf.write("\3\2\2\2\26\u00e2\3\2\2\2\30\u00ea\3\2\2\2\32\u00f3\3")
        buf.write("\2\2\2\34\u0104\3\2\2\2\36\u0118\3\2\2\2 \u011a\3\2\2")
        buf.write("\2\"\u0123\3\2\2\2$\u0136\3\2\2\2&\u0142\3\2\2\2(\u014c")
        buf.write("\3\2\2\2*\u0152\3\2\2\2,\u0164\3\2\2\2./\b\2\1\2/\60\7")
        buf.write("\3\2\2\60\61\7\32\2\2\61\62\5\6\4\2\628\b\2\1\2\63\64")
        buf.write("\5\6\4\2\64\65\b\2\1\2\65\67\3\2\2\2\66\63\3\2\2\2\67")
        buf.write(":\3\2\2\28\66\3\2\2\289\3\2\2\29;\3\2\2\2:8\3\2\2\2;<")
        buf.write("\b\2\1\2<\3\3\2\2\2=>\b\3\1\2>?\7\4\2\2?@\7\32\2\2@A\5")
        buf.write("\6\4\2AG\b\3\1\2BC\5\6\4\2CD\b\3\1\2DF\3\2\2\2EB\3\2\2")
        buf.write("\2FI\3\2\2\2GE\3\2\2\2GH\3\2\2\2HJ\3\2\2\2IG\3\2\2\2J")
        buf.write("K\b\3\1\2K\5\3\2\2\2LM\b\4\1\2MN\7\25\2\2NO\b\4\1\2OP")
        buf.write("\7*\2\2PQ\5\36\20\2QX\b\4\1\2RS\7\30\2\2ST\5\36\20\2T")
        buf.write("U\b\4\1\2UW\3\2\2\2VR\3\2\2\2WZ\3\2\2\2XV\3\2\2\2XY\3")
        buf.write("\2\2\2Y[\3\2\2\2ZX\3\2\2\2[\\\7+\2\2\\]\b\4\1\2]\7\3\2")
        buf.write("\2\2^_\7\5\2\2_`\7\32\2\2`a\5\n\6\2ab\b\5\1\2bc\7\2\2")
        buf.write("\3c\t\3\2\2\2de\b\6\1\2ef\5\f\7\2fl\b\6\1\2gh\5\f\7\2")
        buf.write("hi\b\6\1\2ik\3\2\2\2jg\3\2\2\2kn\3\2\2\2lj\3\2\2\2lm\3")
        buf.write("\2\2\2mo\3\2\2\2nl\3\2\2\2op\b\6\1\2p\13\3\2\2\2qt\b\7")
        buf.write("\1\2rs\7!\2\2su\b\7\1\2tr\3\2\2\2tu\3\2\2\2ux\3\2\2\2")
        buf.write("vw\7\"\2\2wy\b\7\1\2xv\3\2\2\2xy\3\2\2\2y|\3\2\2\2z{\7")
        buf.write("#\2\2{}\b\7\1\2|z\3\2\2\2|}\3\2\2\2}~\3\2\2\2~\177\5\16")
        buf.write("\b\2\177\u0080\b\7\1\2\u0080\u0081\7\26\2\2\u0081\u0085")
        buf.write("\b\7\1\2\u0082\u0083\5\20\t\2\u0083\u0084\b\7\1\2\u0084")
        buf.write("\u0086\3\2\2\2\u0085\u0082\3\2\2\2\u0085\u0086\3\2\2\2")
        buf.write("\u0086\u0087\3\2\2\2\u0087\u0088\7\33\2\2\u0088\u0089")
        buf.write("\b\7\1\2\u0089\r\3\2\2\2\u008a\u008b\5\24\13\2\u008b\u008c")
        buf.write("\b\b\1\2\u008c\17\3\2\2\2\u008d\u00a0\b\t\1\2\u008e\u008f")
        buf.write("\5\24\13\2\u008f\u0090\b\t\1\2\u0090\u009b\3\2\2\2\u0091")
        buf.write("\u0092\5\32\16\2\u0092\u0093\b\t\1\2\u0093\u009b\3\2\2")
        buf.write("\2\u0094\u0095\5\26\f\2\u0095\u0096\b\t\1\2\u0096\u009b")
        buf.write("\3\2\2\2\u0097\u0098\5\22\n\2\u0098\u0099\b\t\1\2\u0099")
        buf.write("\u009b\3\2\2\2\u009a\u008e\3\2\2\2\u009a\u0091\3\2\2\2")
        buf.write("\u009a\u0094\3\2\2\2\u009a\u0097\3\2\2\2\u009b\u009c\3")
        buf.write("\2\2\2\u009c\u009d\7\30\2\2\u009d\u009f\3\2\2\2\u009e")
        buf.write("\u009a\3\2\2\2\u009f\u00a2\3\2\2\2\u00a0\u009e\3\2\2\2")
        buf.write("\u00a0\u00a1\3\2\2\2\u00a1\u00af\3\2\2\2\u00a2\u00a0\3")
        buf.write("\2\2\2\u00a3\u00a4\5\24\13\2\u00a4\u00a5\b\t\1\2\u00a5")
        buf.write("\u00b0\3\2\2\2\u00a6\u00a7\5\32\16\2\u00a7\u00a8\b\t\1")
        buf.write("\2\u00a8\u00b0\3\2\2\2\u00a9\u00aa\5\26\f\2\u00aa\u00ab")
        buf.write("\b\t\1\2\u00ab\u00b0\3\2\2\2\u00ac\u00ad\5\22\n\2\u00ad")
        buf.write("\u00ae\b\t\1\2\u00ae\u00b0\3\2\2\2\u00af\u00a3\3\2\2\2")
        buf.write("\u00af\u00a6\3\2\2\2\u00af\u00a9\3\2\2\2\u00af\u00ac\3")
        buf.write("\2\2\2\u00b0\u00b1\3\2\2\2\u00b1\u00b2\b\t\1\2\u00b2\21")
        buf.write("\3\2\2\2\u00b3\u00b4\7 \2\2\u00b4\u00b5\5\24\13\2\u00b5")
        buf.write("\u00b6\b\n\1\2\u00b6\23\3\2\2\2\u00b7\u00b8\b\13\1\2\u00b8")
        buf.write("\u00b9\7\25\2\2\u00b9\u00ba\b\13\1\2\u00ba\u00c8\7*\2")
        buf.write("\2\u00bb\u00bc\7\25\2\2\u00bc\u00c9\b\13\1\2\u00bd\u00be")
        buf.write("\5\34\17\2\u00be\u00bf\b\13\1\2\u00bf\u00c9\3\2\2\2\u00c0")
        buf.write("\u00c1\7\27\2\2\u00c1\u00c9\b\13\1\2\u00c2\u00c3\5*\26")
        buf.write("\2\u00c3\u00c4\b\13\1\2\u00c4\u00c9\3\2\2\2\u00c5\u00c6")
        buf.write("\5\30\r\2\u00c6\u00c7\b\13\1\2\u00c7\u00c9\3\2\2\2\u00c8")
        buf.write("\u00bb\3\2\2\2\u00c8\u00bd\3\2\2\2\u00c8\u00c0\3\2\2\2")
        buf.write("\u00c8\u00c2\3\2\2\2\u00c8\u00c5\3\2\2\2\u00c9\u00dc\3")
        buf.write("\2\2\2\u00ca\u00d8\7\30\2\2\u00cb\u00cc\7\25\2\2\u00cc")
        buf.write("\u00d9\b\13\1\2\u00cd\u00ce\5\34\17\2\u00ce\u00cf\b\13")
        buf.write("\1\2\u00cf\u00d9\3\2\2\2\u00d0\u00d1\7\27\2\2\u00d1\u00d9")
        buf.write("\b\13\1\2\u00d2\u00d3\5*\26\2\u00d3\u00d4\b\13\1\2\u00d4")
        buf.write("\u00d9\3\2\2\2\u00d5\u00d6\5\30\r\2\u00d6\u00d7\b\13\1")
        buf.write("\2\u00d7\u00d9\3\2\2\2\u00d8\u00cb\3\2\2\2\u00d8\u00cd")
        buf.write("\3\2\2\2\u00d8\u00d0\3\2\2\2\u00d8\u00d2\3\2\2\2\u00d8")
        buf.write("\u00d5\3\2\2\2\u00d9\u00db\3\2\2\2\u00da\u00ca\3\2\2\2")
        buf.write("\u00db\u00de\3\2\2\2\u00dc\u00da\3\2\2\2\u00dc\u00dd\3")
        buf.write("\2\2\2\u00dd\u00df\3\2\2\2\u00de\u00dc\3\2\2\2\u00df\u00e0")
        buf.write("\7+\2\2\u00e0\u00e1\b\13\1\2\u00e1\25\3\2\2\2\u00e2\u00e3")
        buf.write("\b\f\1\2\u00e3\u00e4\7\25\2\2\u00e4\u00e5\b\f\1\2\u00e5")
        buf.write("\u00e6\7%\2\2\u00e6\u00e7\5\30\r\2\u00e7\u00e8\b\f\1\2")
        buf.write("\u00e8\u00e9\b\f\1\2\u00e9\27\3\2\2\2\u00ea\u00eb\b\r")
        buf.write("\1\2\u00eb\u00ec\7\25\2\2\u00ec\u00ed\b\r\1\2\u00ed\u00ee")
        buf.write("\5(\25\2\u00ee\u00ef\b\r\1\2\u00ef\u00f0\7\25\2\2\u00f0")
        buf.write("\u00f1\b\r\1\2\u00f1\u00f2\b\r\1\2\u00f2\31\3\2\2\2\u00f3")
        buf.write("\u00f8\b\16\1\2\u00f4\u00f5\7\25\2\2\u00f5\u00f9\b\16")
        buf.write("\1\2\u00f6\u00f7\7\6\2\2\u00f7\u00f9\b\16\1\2\u00f8\u00f4")
        buf.write("\3\2\2\2\u00f8\u00f6\3\2\2\2\u00f9\u00fa\3\2\2\2\u00fa")
        buf.write("\u00fb\5$\23\2\u00fb\u0100\b\16\1\2\u00fc\u00fd\7\25\2")
        buf.write("\2\u00fd\u0101\b\16\1\2\u00fe\u00ff\7\6\2\2\u00ff\u0101")
        buf.write("\b\16\1\2\u0100\u00fc\3\2\2\2\u0100\u00fe\3\2\2\2\u0101")
        buf.write("\u0102\3\2\2\2\u0102\u0103\b\16\1\2\u0103\33\3\2\2\2\u0104")
        buf.write("\u0105\b\17\1\2\u0105\u0106\5&\24\2\u0106\u0107\b\17\1")
        buf.write("\2\u0107\u010d\7*\2\2\u0108\u0109\7\25\2\2\u0109\u010e")
        buf.write("\b\17\1\2\u010a\u010b\5\30\r\2\u010b\u010c\b\17\1\2\u010c")
        buf.write("\u010e\3\2\2\2\u010d\u0108\3\2\2\2\u010d\u010a\3\2\2\2")
        buf.write("\u010e\u010f\3\2\2\2\u010f\u0110\7+\2\2\u0110\u0111\b")
        buf.write("\17\1\2\u0111\35\3\2\2\2\u0112\u0113\5\"\22\2\u0113\u0114")
        buf.write("\b\20\1\2\u0114\u0119\3\2\2\2\u0115\u0116\5 \21\2\u0116")
        buf.write("\u0117\b\20\1\2\u0117\u0119\3\2\2\2\u0118\u0112\3\2\2")
        buf.write("\2\u0118\u0115\3\2\2\2\u0119\37\3\2\2\2\u011a\u011b\b")
        buf.write("\21\1\2\u011b\u011c\7,\2\2\u011c\u011d\7\25\2\2\u011d")
        buf.write("\u011e\b\21\1\2\u011e\u011f\7-\2\2\u011f\u0120\5,\27\2")
        buf.write("\u0120\u0121\b\21\1\2\u0121\u0122\b\21\1\2\u0122!\3\2")
        buf.write("\2\2\u0123\u0124\b\22\1\2\u0124\u0125\7\25\2\2\u0125\u0126")
        buf.write("\b\22\1\2\u0126\u0127\5,\27\2\u0127\u0128\b\22\1\2\u0128")
        buf.write("\u0129\b\22\1\2\u0129#\3\2\2\2\u012a\u012b\7$\2\2\u012b")
        buf.write("\u0137\b\23\1\2\u012c\u012d\7%\2\2\u012d\u0137\b\23\1")
        buf.write("\2\u012e\u012f\7\'\2\2\u012f\u0137\b\23\1\2\u0130\u0131")
        buf.write("\7&\2\2\u0131\u0137\b\23\1\2\u0132\u0133\7)\2\2\u0133")
        buf.write("\u0137\b\23\1\2\u0134\u0135\7(\2\2\u0135\u0137\b\23\1")
        buf.write("\2\u0136\u012a\3\2\2\2\u0136\u012c\3\2\2\2\u0136\u012e")
        buf.write("\3\2\2\2\u0136\u0130\3\2\2\2\u0136\u0132\3\2\2\2\u0136")
        buf.write("\u0134\3\2\2\2\u0137%\3\2\2\2\u0138\u0139\7\20\2\2\u0139")
        buf.write("\u0143\b\24\1\2\u013a\u013b\7\21\2\2\u013b\u0143\b\24")
        buf.write("\1\2\u013c\u013d\7\22\2\2\u013d\u0143\b\24\1\2\u013e\u013f")
        buf.write("\7\23\2\2\u013f\u0143\b\24\1\2\u0140\u0141\7\24\2\2\u0141")
        buf.write("\u0143\b\24\1\2\u0142\u0138\3\2\2\2\u0142\u013a\3\2\2")
        buf.write("\2\u0142\u013c\3\2\2\2\u0142\u013e\3\2\2\2\u0142\u0140")
        buf.write("\3\2\2\2\u0143\'\3\2\2\2\u0144\u0145\7\34\2\2\u0145\u014d")
        buf.write("\b\25\1\2\u0146\u0147\7\35\2\2\u0147\u014d\b\25\1\2\u0148")
        buf.write("\u0149\7\36\2\2\u0149\u014d\b\25\1\2\u014a\u014b\7\37")
        buf.write("\2\2\u014b\u014d\b\25\1\2\u014c\u0144\3\2\2\2\u014c\u0146")
        buf.write("\3\2\2\2\u014c\u0148\3\2\2\2\u014c\u014a\3\2\2\2\u014d")
        buf.write(")\3\2\2\2\u014e\u014f\7\6\2\2\u014f\u0153\b\26\1\2\u0150")
        buf.write("\u0151\7\7\2\2\u0151\u0153\b\26\1\2\u0152\u014e\3\2\2")
        buf.write("\2\u0152\u0150\3\2\2\2\u0153+\3\2\2\2\u0154\u0155\7\b")
        buf.write("\2\2\u0155\u0165\b\27\1\2\u0156\u0157\7\t\2\2\u0157\u0165")
        buf.write("\b\27\1\2\u0158\u0159\7\n\2\2\u0159\u0165\b\27\1\2\u015a")
        buf.write("\u015b\7\13\2\2\u015b\u0165\b\27\1\2\u015c\u015d\7\f\2")
        buf.write("\2\u015d\u0165\b\27\1\2\u015e\u015f\7\r\2\2\u015f\u0165")
        buf.write("\b\27\1\2\u0160\u0161\7\16\2\2\u0161\u0165\b\27\1\2\u0162")
        buf.write("\u0163\7\17\2\2\u0163\u0165\b\27\1\2\u0164\u0154\3\2\2")
        buf.write("\2\u0164\u0156\3\2\2\2\u0164\u0158\3\2\2\2\u0164\u015a")
        buf.write("\3\2\2\2\u0164\u015c\3\2\2\2\u0164\u015e\3\2\2\2\u0164")
        buf.write("\u0160\3\2\2\2\u0164\u0162\3\2\2\2\u0165-\3\2\2\2\318")
        buf.write("GXltx|\u0085\u009a\u00a0\u00af\u00c8\u00d8\u00dc\u00f8")
        buf.write("\u0100\u010d\u0118\u0136\u0142\u014c\u0152\u0164")
        return buf.getvalue()


class DatalogParser ( Parser ):

    grammarFileName = "Datalog.g4"

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    sharedContextCache = PredictionContextCache()

    literalNames = [ "<INVALID>", "'EDB_DECL'", "'IDB_DECL'", "'RULE_DECL'", 
                     "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "<INVALID>", "'MIN'", "'MAX'", "'SUM'", 
                     "'COUNT'", "'COUNT_DISTINCT'", "<INVALID>", "':-'", 
                     "'_'", "','", "';'", "':'", "'.'", "'+'", "'-'", "'*'", 
                     "'/'", "'!'", "'[!dedup]'", "'[!set-diff]'", "'[dedup-only]'", 
                     "'!='", "'='", "'>='", "'>'", "'<='", "'<'", "'('", 
                     "')'", "'['", "']'" ]

    symbolicNames = [ "<INVALID>", "TOKEN_EDB", "TOKEN_IDB", "TOKEN_RULE", 
                      "TOKEN_INTEGER", "TOKEN_STRING", "TOKEN_INT", "TOKEN_LONG", 
                      "TOKEN_FLOAT", "TOKEN_DOUBLE", "TOKEN_VARCHAR", "TOKEN_CHAR", 
                      "TOKEN_DATE", "TOKEN_DATETIME", "TOKEN_MIN", "TOKEN_MAX", 
                      "TOKEN_SUM", "TOKEN_COUNT", "TOKEN_COUNT_DISTINCT", 
                      "TOKEN_ID", "TOKEN_BODY_HEAD_SEP", "TOKEN_ANY", "TOKEN_COMMA", 
                      "TOKEN_SEMICOLON", "TOKEN_COLON", "TOKEN_DOT", "TOKEN_PLUS", 
                      "TOKEN_MINUS", "TOKEN_MULT", "TOKEN_DIV", "TOKEN_NOT", 
                      "TOKEN_NON_DEDUP", "TOKEN_NON_SET_DIFF", "TOKEN_DEDUP_ONLY", 
                      "TOKEN_NOT_EQUALS", "TOKEN_EQUALS", "TOKEN_GREATER_EQUAL_THAN", 
                      "TOKEN_GREATER_THAN", "TOKEN_LESS_EQUAL_THAN", "TOKEN_LESS_THAN", 
                      "TOKEN_LEFT_PAREN", "TOKEN_RIGHT_PAREN", "TOKEN_LEFT_BRACKET", 
                      "TOKEN_RIGHT_BRACKET", "TOKEN_WS" ]

    RULE_datalog_edb_declare = 0
    RULE_datalog_idb_declare = 1
    RULE_datalog_relation_schema = 2
    RULE_datalog_rule_declare = 3
    RULE_datalog_program = 4
    RULE_datalog_rule = 5
    RULE_head = 6
    RULE_body = 7
    RULE_negation = 8
    RULE_atom = 9
    RULE_assign = 10
    RULE_math_expr = 11
    RULE_compare_expr = 12
    RULE_aggregation_expr = 13
    RULE_attribute = 14
    RULE_key_attribute = 15
    RULE_non_key_attribute = 16
    RULE_compare_op = 17
    RULE_aggregation_op = 18
    RULE_math_op = 19
    RULE_constant = 20
    RULE_data_type = 21

    ruleNames =  [ "datalog_edb_declare", "datalog_idb_declare", "datalog_relation_schema", 
                   "datalog_rule_declare", "datalog_program", "datalog_rule", 
                   "head", "body", "negation", "atom", "assign", "math_expr", 
                   "compare_expr", "aggregation_expr", "attribute", "key_attribute", 
                   "non_key_attribute", "compare_op", "aggregation_op", 
                   "math_op", "constant", "data_type" ]

    EOF = Token.EOF
    TOKEN_EDB=1
    TOKEN_IDB=2
    TOKEN_RULE=3
    TOKEN_INTEGER=4
    TOKEN_STRING=5
    TOKEN_INT=6
    TOKEN_LONG=7
    TOKEN_FLOAT=8
    TOKEN_DOUBLE=9
    TOKEN_VARCHAR=10
    TOKEN_CHAR=11
    TOKEN_DATE=12
    TOKEN_DATETIME=13
    TOKEN_MIN=14
    TOKEN_MAX=15
    TOKEN_SUM=16
    TOKEN_COUNT=17
    TOKEN_COUNT_DISTINCT=18
    TOKEN_ID=19
    TOKEN_BODY_HEAD_SEP=20
    TOKEN_ANY=21
    TOKEN_COMMA=22
    TOKEN_SEMICOLON=23
    TOKEN_COLON=24
    TOKEN_DOT=25
    TOKEN_PLUS=26
    TOKEN_MINUS=27
    TOKEN_MULT=28
    TOKEN_DIV=29
    TOKEN_NOT=30
    TOKEN_NON_DEDUP=31
    TOKEN_NON_SET_DIFF=32
    TOKEN_DEDUP_ONLY=33
    TOKEN_NOT_EQUALS=34
    TOKEN_EQUALS=35
    TOKEN_GREATER_EQUAL_THAN=36
    TOKEN_GREATER_THAN=37
    TOKEN_LESS_EQUAL_THAN=38
    TOKEN_LESS_THAN=39
    TOKEN_LEFT_PAREN=40
    TOKEN_RIGHT_PAREN=41
    TOKEN_LEFT_BRACKET=42
    TOKEN_RIGHT_BRACKET=43
    TOKEN_WS=44

    def __init__(self, input:TokenStream, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.8")
        self._interp = ParserATNSimulator(self, self.atn, self.decisionsToDFA, self.sharedContextCache)
        self._predicates = None




    class AtomArg():
        def __init__(self, arg_name, arg_type, key_attribute=False):
            self.name = arg_name
            self.type = arg_type
            self.key_attribute = key_attribute



    class Datalog_edb_declareContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.schema1 = None # Datalog_relation_schemaContext
            self.schema2 = None # Datalog_relation_schemaContext

        def TOKEN_EDB(self):
            return self.getToken(DatalogParser.TOKEN_EDB, 0)

        def TOKEN_COLON(self):
            return self.getToken(DatalogParser.TOKEN_COLON, 0)

        def datalog_relation_schema(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Datalog_relation_schemaContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Datalog_relation_schemaContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_edb_declare




    def datalog_edb_declare(self):

        localctx = DatalogParser.Datalog_edb_declareContext(self, self._ctx, self.state)
        self.enterRule(localctx, 0, self.RULE_datalog_edb_declare)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            edb_list = []
            self.state = 45
            self.match(DatalogParser.TOKEN_EDB)
            self.state = 46
            self.match(DatalogParser.TOKEN_COLON)
            self.state = 47
            localctx.schema1 = self.datalog_relation_schema()
            edb_list.append(localctx.schema1.r)
            self.state = 54
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_ID:
                self.state = 49
                localctx.schema2 = self.datalog_relation_schema()
                edb_list.append(localctx.schema2.r)
                self.state = 56
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            localctx.r = edb_list
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_idb_declareContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.schema1 = None # Datalog_relation_schemaContext
            self.schema2 = None # Datalog_relation_schemaContext

        def TOKEN_IDB(self):
            return self.getToken(DatalogParser.TOKEN_IDB, 0)

        def TOKEN_COLON(self):
            return self.getToken(DatalogParser.TOKEN_COLON, 0)

        def datalog_relation_schema(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Datalog_relation_schemaContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Datalog_relation_schemaContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_idb_declare




    def datalog_idb_declare(self):

        localctx = DatalogParser.Datalog_idb_declareContext(self, self._ctx, self.state)
        self.enterRule(localctx, 2, self.RULE_datalog_idb_declare)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            idb_list = []
            self.state = 60
            self.match(DatalogParser.TOKEN_IDB)
            self.state = 61
            self.match(DatalogParser.TOKEN_COLON)
            self.state = 62
            localctx.schema1 = self.datalog_relation_schema()
            idb_list.append(localctx.schema1.r)
            self.state = 69
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_ID:
                self.state = 64
                localctx.schema2 = self.datalog_relation_schema()
                idb_list.append(localctx.schema2.r)
                self.state = 71
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            localctx.r = idb_list
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_relation_schemaContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.relation_name = None # Token
            self.t1 = None # AttributeContext
            self.t2 = None # AttributeContext

        def TOKEN_LEFT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_PAREN, 0)

        def TOKEN_RIGHT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_PAREN, 0)

        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def attribute(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.AttributeContext)
            else:
                return self.getTypedRuleContext(DatalogParser.AttributeContext,i)


        def TOKEN_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_COMMA)
            else:
                return self.getToken(DatalogParser.TOKEN_COMMA, i)

        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_relation_schema




    def datalog_relation_schema(self):

        localctx = DatalogParser.Datalog_relation_schemaContext(self, self._ctx, self.state)
        self.enterRule(localctx, 4, self.RULE_datalog_relation_schema)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            schema = {'name': '', 'attributes': []}
            self.state = 75
            localctx.relation_name = self.match(DatalogParser.TOKEN_ID)
            schema['name'] = (None if localctx.relation_name is None else localctx.relation_name.text)
            self.state = 77
            self.match(DatalogParser.TOKEN_LEFT_PAREN)
            self.state = 78
            localctx.t1 = self.attribute()
            schema['attributes'].append(self.AtomArg(localctx.t1.r['name'], localctx.t1.r['type'], localctx.t1.r['is_key']))
            self.state = 86
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_COMMA:
                self.state = 80
                self.match(DatalogParser.TOKEN_COMMA)
                self.state = 81
                localctx.t2 = self.attribute()
                schema['attributes'].append(self.AtomArg(localctx.t2.r['name'], localctx.t2.r['type'], localctx.t2.r['is_key']))
                self.state = 88
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 89
            self.match(DatalogParser.TOKEN_RIGHT_PAREN)
            localctx.r = schema
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_rule_declareContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.dp = None # Datalog_programContext

        def TOKEN_RULE(self):
            return self.getToken(DatalogParser.TOKEN_RULE, 0)

        def TOKEN_COLON(self):
            return self.getToken(DatalogParser.TOKEN_COLON, 0)

        def EOF(self):
            return self.getToken(DatalogParser.EOF, 0)

        def datalog_program(self):
            return self.getTypedRuleContext(DatalogParser.Datalog_programContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_rule_declare




    def datalog_rule_declare(self):

        localctx = DatalogParser.Datalog_rule_declareContext(self, self._ctx, self.state)
        self.enterRule(localctx, 6, self.RULE_datalog_rule_declare)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 92
            self.match(DatalogParser.TOKEN_RULE)
            self.state = 93
            self.match(DatalogParser.TOKEN_COLON)
            self.state = 94
            localctx.dp = self.datalog_program()
            localctx.r = localctx.dp.r
            self.state = 96
            self.match(DatalogParser.EOF)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_programContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.r1 = None # Datalog_ruleContext
            self.r2 = None # Datalog_ruleContext

        def datalog_rule(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Datalog_ruleContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Datalog_ruleContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_program




    def datalog_program(self):

        localctx = DatalogParser.Datalog_programContext(self, self._ctx, self.state)
        self.enterRule(localctx, 8, self.RULE_datalog_program)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            rule_list = []
            self.state = 99
            localctx.r1 = self.datalog_rule()
            rule_list.append(localctx.r1.r)
            self.state = 106
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << DatalogParser.TOKEN_ID) | (1 << DatalogParser.TOKEN_NON_DEDUP) | (1 << DatalogParser.TOKEN_NON_SET_DIFF) | (1 << DatalogParser.TOKEN_DEDUP_ONLY))) != 0):
                self.state = 101
                localctx.r2 = self.datalog_rule()
                rule_list.append(localctx.r2.r)
                self.state = 108
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            localctx.r = rule_list
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_ruleContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.h = None # HeadContext
            self.b = None # BodyContext

        def TOKEN_BODY_HEAD_SEP(self):
            return self.getToken(DatalogParser.TOKEN_BODY_HEAD_SEP, 0)

        def TOKEN_DOT(self):
            return self.getToken(DatalogParser.TOKEN_DOT, 0)

        def head(self):
            return self.getTypedRuleContext(DatalogParser.HeadContext,0)


        def TOKEN_NON_DEDUP(self):
            return self.getToken(DatalogParser.TOKEN_NON_DEDUP, 0)

        def TOKEN_NON_SET_DIFF(self):
            return self.getToken(DatalogParser.TOKEN_NON_SET_DIFF, 0)

        def TOKEN_DEDUP_ONLY(self):
            return self.getToken(DatalogParser.TOKEN_DEDUP_ONLY, 0)

        def body(self):
            return self.getTypedRuleContext(DatalogParser.BodyContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_rule




    def datalog_rule(self):

        localctx = DatalogParser.Datalog_ruleContext(self, self._ctx, self.state)
        self.enterRule(localctx, 10, self.RULE_datalog_rule)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            rule_map = {}
            self.state = 114
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==DatalogParser.TOKEN_NON_DEDUP:
                self.state = 112
                self.match(DatalogParser.TOKEN_NON_DEDUP)
                rule_map['non-dedup'] = True


            self.state = 118
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==DatalogParser.TOKEN_NON_SET_DIFF:
                self.state = 116
                self.match(DatalogParser.TOKEN_NON_SET_DIFF)
                rule_map['non-set-diff'] = True


            self.state = 122
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==DatalogParser.TOKEN_DEDUP_ONLY:
                self.state = 120
                self.match(DatalogParser.TOKEN_DEDUP_ONLY)
                rule_map['dedup-only'] = True


            self.state = 124
            localctx.h = self.head()
            rule_map['head'] = localctx.h.r
            self.state = 126
            self.match(DatalogParser.TOKEN_BODY_HEAD_SEP)
            rule_map['body'] = None
            self.state = 131
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << DatalogParser.TOKEN_INTEGER) | (1 << DatalogParser.TOKEN_ID) | (1 << DatalogParser.TOKEN_NOT))) != 0):
                self.state = 128
                localctx.b = self.body()
                rule_map['body'] = localctx.b.r


            self.state = 133
            self.match(DatalogParser.TOKEN_DOT)
            localctx.r = rule_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class HeadContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a = None # AtomContext

        def atom(self):
            return self.getTypedRuleContext(DatalogParser.AtomContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_head




    def head(self):

        localctx = DatalogParser.HeadContext(self, self._ctx, self.state)
        self.enterRule(localctx, 12, self.RULE_head)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 136
            localctx.a = self.atom()
            localctx.r = localctx.a.r
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class BodyContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.b1 = None # AtomContext
            self.b2 = None # Compare_exprContext
            self.b3 = None # AssignContext
            self.b4 = None # NegationContext
            self.b5 = None # AtomContext
            self.b6 = None # Compare_exprContext
            self.b7 = None # AssignContext
            self.b8 = None # NegationContext

        def TOKEN_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_COMMA)
            else:
                return self.getToken(DatalogParser.TOKEN_COMMA, i)

        def atom(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.AtomContext)
            else:
                return self.getTypedRuleContext(DatalogParser.AtomContext,i)


        def compare_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Compare_exprContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Compare_exprContext,i)


        def assign(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.AssignContext)
            else:
                return self.getTypedRuleContext(DatalogParser.AssignContext,i)


        def negation(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.NegationContext)
            else:
                return self.getTypedRuleContext(DatalogParser.NegationContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_body




    def body(self):

        localctx = DatalogParser.BodyContext(self, self._ctx, self.state)
        self.enterRule(localctx, 14, self.RULE_body)
        try:
            self.enterOuterAlt(localctx, 1)
            body_map = {'atoms':[], 'compares': [], 'assigns':[], 'negations':[]}
            self.state = 158
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,9,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 152
                    self._errHandler.sync(self)
                    la_ = self._interp.adaptivePredict(self._input,8,self._ctx)
                    if la_ == 1:
                        self.state = 140
                        localctx.b1 = self.atom()
                        body_map['atoms'].append(localctx.b1.r)
                        pass

                    elif la_ == 2:
                        self.state = 143
                        localctx.b2 = self.compare_expr()
                        body_map['compares'].append(localctx.b2.r)
                        pass

                    elif la_ == 3:
                        self.state = 146
                        localctx.b3 = self.assign()
                        body_map['assigns'].append(localctx.b3.r)
                        pass

                    elif la_ == 4:
                        self.state = 149
                        localctx.b4 = self.negation()
                        body_map['negations'].append(localctx.b4.r)
                        pass


                    self.state = 154
                    self.match(DatalogParser.TOKEN_COMMA) 
                self.state = 160
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,9,self._ctx)

            self.state = 173
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,10,self._ctx)
            if la_ == 1:
                self.state = 161
                localctx.b5 = self.atom()
                body_map['atoms'].append(localctx.b5.r)
                pass

            elif la_ == 2:
                self.state = 164
                localctx.b6 = self.compare_expr()
                body_map['compares'].append(localctx.b6.r)
                pass

            elif la_ == 3:
                self.state = 167
                localctx.b7 = self.assign()
                body_map['assigns'].append(localctx.b7.r)
                pass

            elif la_ == 4:
                self.state = 170
                localctx.b8 = self.negation()
                body_map['negations'].append(localctx.b8.r)
                pass


            localctx.r = body_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class NegationContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a = None # AtomContext

        def TOKEN_NOT(self):
            return self.getToken(DatalogParser.TOKEN_NOT, 0)

        def atom(self):
            return self.getTypedRuleContext(DatalogParser.AtomContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_negation




    def negation(self):

        localctx = DatalogParser.NegationContext(self, self._ctx, self.state)
        self.enterRule(localctx, 16, self.RULE_negation)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 177
            self.match(DatalogParser.TOKEN_NOT)
            self.state = 178
            localctx.a = self.atom()
            localctx.r = localctx.a.r
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AtomContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token
            self.a2 = None # Token
            self.a3 = None # Aggregation_exprContext
            self.a4 = None # Token
            self.a5 = None # ConstantContext
            self.a6 = None # Math_exprContext
            self.a7 = None # Token
            self.a8 = None # Aggregation_exprContext
            self.a9 = None # Token
            self.a10 = None # ConstantContext
            self.a11 = None # Math_exprContext

        def TOKEN_LEFT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_PAREN, 0)

        def TOKEN_RIGHT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_PAREN, 0)

        def TOKEN_ID(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ID)
            else:
                return self.getToken(DatalogParser.TOKEN_ID, i)

        def aggregation_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Aggregation_exprContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Aggregation_exprContext,i)


        def TOKEN_ANY(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ANY)
            else:
                return self.getToken(DatalogParser.TOKEN_ANY, i)

        def constant(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.ConstantContext)
            else:
                return self.getTypedRuleContext(DatalogParser.ConstantContext,i)


        def math_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Math_exprContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Math_exprContext,i)


        def TOKEN_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_COMMA)
            else:
                return self.getToken(DatalogParser.TOKEN_COMMA, i)

        def getRuleIndex(self):
            return DatalogParser.RULE_atom




    def atom(self):

        localctx = DatalogParser.AtomContext(self, self._ctx, self.state)
        self.enterRule(localctx, 18, self.RULE_atom)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            atom_map = {'name': None, 'arg_list':[]}
            self.state = 182
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            atom_map['name'] = (None if localctx.a1 is None else localctx.a1.text)
            self.state = 184
            self.match(DatalogParser.TOKEN_LEFT_PAREN)
            self.state = 198
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,11,self._ctx)
            if la_ == 1:
                self.state = 185
                localctx.a2 = self.match(DatalogParser.TOKEN_ID)
                atom_map['arg_list'].append(self.AtomArg((None if localctx.a2 is None else localctx.a2.text), 'variable'))
                pass

            elif la_ == 2:
                self.state = 187
                localctx.a3 = self.aggregation_expr()
                atom_map['arg_list'].append(self.AtomArg(localctx.a3.r, 'aggregation'))
                pass

            elif la_ == 3:
                self.state = 190
                localctx.a4 = self.match(DatalogParser.TOKEN_ANY)
                atom_map['arg_list'].append(self.AtomArg((None if localctx.a4 is None else localctx.a4.text), 'any'))
                pass

            elif la_ == 4:
                self.state = 192
                localctx.a5 = self.constant()
                atom_map['arg_list'].append(self.AtomArg((None if localctx.a5 is None else self._input.getText(localctx.a5.start,localctx.a5.stop)), 'constant'))
                pass

            elif la_ == 5:
                self.state = 195
                localctx.a6 = self.math_expr()
                atom_map['arg_list'].append(self.AtomArg(localctx.a6.r, 'math_expr'))
                pass


            self.state = 218
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_COMMA:
                self.state = 200
                self.match(DatalogParser.TOKEN_COMMA)
                self.state = 214
                self._errHandler.sync(self)
                la_ = self._interp.adaptivePredict(self._input,12,self._ctx)
                if la_ == 1:
                    self.state = 201
                    localctx.a7 = self.match(DatalogParser.TOKEN_ID)
                    atom_map['arg_list'].append(self.AtomArg((None if localctx.a7 is None else localctx.a7.text), 'variable'))
                    pass

                elif la_ == 2:
                    self.state = 203
                    localctx.a8 = self.aggregation_expr()
                    atom_map['arg_list'].append(self.AtomArg(localctx.a8.r, 'aggregation'))
                    pass

                elif la_ == 3:
                    self.state = 206
                    localctx.a9 = self.match(DatalogParser.TOKEN_ANY)
                    atom_map['arg_list'].append(self.AtomArg((None if localctx.a9 is None else localctx.a9.text), 'any'))
                    pass

                elif la_ == 4:
                    self.state = 208
                    localctx.a10 = self.constant()
                    atom_map['arg_list'].append(self.AtomArg((None if localctx.a10 is None else self._input.getText(localctx.a10.start,localctx.a10.stop)), 'constant'))
                    pass

                elif la_ == 5:
                    self.state = 211
                    localctx.a11 = self.math_expr()
                    atom_map['arg_list'].append(self.AtomArg(localctx.a11.r, 'math_expr'))
                    pass


                self.state = 220
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 221
            self.match(DatalogParser.TOKEN_RIGHT_PAREN)
            localctx.r = atom_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AssignContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token
            self.a2 = None # Math_exprContext

        def TOKEN_EQUALS(self):
            return self.getToken(DatalogParser.TOKEN_EQUALS, 0)

        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def math_expr(self):
            return self.getTypedRuleContext(DatalogParser.Math_exprContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_assign




    def assign(self):

        localctx = DatalogParser.AssignContext(self, self._ctx, self.state)
        self.enterRule(localctx, 20, self.RULE_assign)
        try:
            self.enterOuterAlt(localctx, 1)
            assign_map = {}
            self.state = 225
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            assign_map['lhs'] = (None if localctx.a1 is None else localctx.a1.text)
            self.state = 227
            self.match(DatalogParser.TOKEN_EQUALS)
            self.state = 228
            localctx.a2 = self.math_expr()
            assign_map['rhs'] = localctx.a2.r
            localctx.r = assign_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Math_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.m1 = None # Token
            self.m2 = None # Math_opContext
            self.m3 = None # Token

        def TOKEN_ID(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ID)
            else:
                return self.getToken(DatalogParser.TOKEN_ID, i)

        def math_op(self):
            return self.getTypedRuleContext(DatalogParser.Math_opContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_math_expr




    def math_expr(self):

        localctx = DatalogParser.Math_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 22, self.RULE_math_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            math_map = {}
            self.state = 233
            localctx.m1 = self.match(DatalogParser.TOKEN_ID)
            math_map['lhs'] = (None if localctx.m1 is None else localctx.m1.text)
            self.state = 235
            localctx.m2 = self.math_op()
            math_map['op'] = localctx.m2.r
            self.state = 237
            localctx.m3 = self.match(DatalogParser.TOKEN_ID)
            math_map['rhs'] = (None if localctx.m3 is None else localctx.m3.text)
            localctx.r = math_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Compare_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.c1 = None # Token
            self.c2 = None # Token
            self.op = None # Compare_opContext
            self.c4 = None # Token
            self.c5 = None # Token

        def compare_op(self):
            return self.getTypedRuleContext(DatalogParser.Compare_opContext,0)


        def TOKEN_ID(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ID)
            else:
                return self.getToken(DatalogParser.TOKEN_ID, i)

        def TOKEN_INTEGER(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_INTEGER)
            else:
                return self.getToken(DatalogParser.TOKEN_INTEGER, i)

        def getRuleIndex(self):
            return DatalogParser.RULE_compare_expr




    def compare_expr(self):

        localctx = DatalogParser.Compare_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 24, self.RULE_compare_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            compare_map = {}
            self.state = 246
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_ID]:
                self.state = 242
                localctx.c1 = self.match(DatalogParser.TOKEN_ID)
                compare_map['lhs'] = [(None if localctx.c1 is None else localctx.c1.text), 'var']
                pass
            elif token in [DatalogParser.TOKEN_INTEGER]:
                self.state = 244
                localctx.c2 = self.match(DatalogParser.TOKEN_INTEGER)
                compare_map['lhs'] = [(None if localctx.c2 is None else localctx.c2.text), 'num']
                pass
            else:
                raise NoViableAltException(self)

            self.state = 248
            localctx.op = self.compare_op()
            compare_map['op'] = localctx.op.r
            self.state = 254
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_ID]:
                self.state = 250
                localctx.c4 = self.match(DatalogParser.TOKEN_ID)
                compare_map['rhs'] = [(None if localctx.c4 is None else localctx.c4.text), 'var']
                pass
            elif token in [DatalogParser.TOKEN_INTEGER]:
                self.state = 252
                localctx.c5 = self.match(DatalogParser.TOKEN_INTEGER)
                compare_map['rhs'] = [(None if localctx.c5 is None else localctx.c5.text), 'num']
                pass
            else:
                raise NoViableAltException(self)

            localctx.r = compare_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Aggregation_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Aggregation_opContext
            self.a2 = None # Token
            self.a3 = None # Math_exprContext

        def TOKEN_LEFT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_PAREN, 0)

        def TOKEN_RIGHT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_PAREN, 0)

        def aggregation_op(self):
            return self.getTypedRuleContext(DatalogParser.Aggregation_opContext,0)


        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def math_expr(self):
            return self.getTypedRuleContext(DatalogParser.Math_exprContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_aggregation_expr




    def aggregation_expr(self):

        localctx = DatalogParser.Aggregation_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 26, self.RULE_aggregation_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            agg_map = {'agg_op': None, 'agg_arg': None}
            self.state = 259
            localctx.a1 = self.aggregation_op()
            agg_map['agg_op'] = localctx.a1.r
            self.state = 261
            self.match(DatalogParser.TOKEN_LEFT_PAREN)
            self.state = 267
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,16,self._ctx)
            if la_ == 1:
                self.state = 262
                localctx.a2 = self.match(DatalogParser.TOKEN_ID)
                agg_map['agg_arg'] = {'type': 'attribute', 'content': (None if localctx.a2 is None else localctx.a2.text)}
                pass

            elif la_ == 2:
                self.state = 264
                localctx.a3 = self.math_expr()
                agg_map['agg_arg'] = {'type': 'math_expr', 'content': localctx.a3.r}
                pass


            self.state = 269
            self.match(DatalogParser.TOKEN_RIGHT_PAREN)
            localctx.r = agg_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AttributeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Non_key_attributeContext
            self.a2 = None # Key_attributeContext

        def non_key_attribute(self):
            return self.getTypedRuleContext(DatalogParser.Non_key_attributeContext,0)


        def key_attribute(self):
            return self.getTypedRuleContext(DatalogParser.Key_attributeContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_attribute




    def attribute(self):

        localctx = DatalogParser.AttributeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 28, self.RULE_attribute)
        try:
            self.state = 278
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_ID]:
                self.enterOuterAlt(localctx, 1)
                self.state = 272
                localctx.a1 = self.non_key_attribute()
                localctx.r = localctx.a1.r
                pass
            elif token in [DatalogParser.TOKEN_LEFT_BRACKET]:
                self.enterOuterAlt(localctx, 2)
                self.state = 275
                localctx.a2 = self.key_attribute()
                localctx.r = localctx.a2.r
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Key_attributeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token
            self.d1 = None # Data_typeContext

        def TOKEN_LEFT_BRACKET(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_BRACKET, 0)

        def TOKEN_RIGHT_BRACKET(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_BRACKET, 0)

        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def data_type(self):
            return self.getTypedRuleContext(DatalogParser.Data_typeContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_key_attribute




    def key_attribute(self):

        localctx = DatalogParser.Key_attributeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 30, self.RULE_key_attribute)
        try:
            self.enterOuterAlt(localctx, 1)
            attribute_map = {'name': None, 'type': None, 'is_key': True}
            self.state = 281
            self.match(DatalogParser.TOKEN_LEFT_BRACKET)
            self.state = 282
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            attribute_map['name'] = (None if localctx.a1 is None else localctx.a1.text)
            self.state = 284
            self.match(DatalogParser.TOKEN_RIGHT_BRACKET)
            self.state = 285
            localctx.d1 = self.data_type()
            attribute_map['type'] = localctx.d1.r
            localctx.r = attribute_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Non_key_attributeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token
            self.d1 = None # Data_typeContext

        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def data_type(self):
            return self.getTypedRuleContext(DatalogParser.Data_typeContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_non_key_attribute




    def non_key_attribute(self):

        localctx = DatalogParser.Non_key_attributeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 32, self.RULE_non_key_attribute)
        try:
            self.enterOuterAlt(localctx, 1)
            attribute_map = {'name': None, 'type': None, 'is_key': False}
            self.state = 290
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            attribute_map['name'] = (None if localctx.a1 is None else localctx.a1.text)
            self.state = 292
            localctx.d1 = self.data_type()
            attribute_map['type'] = localctx.d1.r
            localctx.r = attribute_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Compare_opContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.op1 = None # Token
            self.op2 = None # Token
            self.op3 = None # Token
            self.op4 = None # Token
            self.op5 = None # Token
            self.op6 = None # Token

        def TOKEN_NOT_EQUALS(self):
            return self.getToken(DatalogParser.TOKEN_NOT_EQUALS, 0)

        def TOKEN_EQUALS(self):
            return self.getToken(DatalogParser.TOKEN_EQUALS, 0)

        def TOKEN_GREATER_THAN(self):
            return self.getToken(DatalogParser.TOKEN_GREATER_THAN, 0)

        def TOKEN_GREATER_EQUAL_THAN(self):
            return self.getToken(DatalogParser.TOKEN_GREATER_EQUAL_THAN, 0)

        def TOKEN_LESS_THAN(self):
            return self.getToken(DatalogParser.TOKEN_LESS_THAN, 0)

        def TOKEN_LESS_EQUAL_THAN(self):
            return self.getToken(DatalogParser.TOKEN_LESS_EQUAL_THAN, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_compare_op




    def compare_op(self):

        localctx = DatalogParser.Compare_opContext(self, self._ctx, self.state)
        self.enterRule(localctx, 34, self.RULE_compare_op)
        try:
            self.state = 308
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_NOT_EQUALS]:
                self.enterOuterAlt(localctx, 1)
                self.state = 296
                localctx.op1 = self.match(DatalogParser.TOKEN_NOT_EQUALS)
                localctx.r = (None if localctx.op1 is None else localctx.op1.text)
                pass
            elif token in [DatalogParser.TOKEN_EQUALS]:
                self.enterOuterAlt(localctx, 2)
                self.state = 298
                localctx.op2 = self.match(DatalogParser.TOKEN_EQUALS)
                localctx.r = (None if localctx.op2 is None else localctx.op2.text)
                pass
            elif token in [DatalogParser.TOKEN_GREATER_THAN]:
                self.enterOuterAlt(localctx, 3)
                self.state = 300
                localctx.op3 = self.match(DatalogParser.TOKEN_GREATER_THAN)
                localctx.r = (None if localctx.op3 is None else localctx.op3.text)
                pass
            elif token in [DatalogParser.TOKEN_GREATER_EQUAL_THAN]:
                self.enterOuterAlt(localctx, 4)
                self.state = 302
                localctx.op4 = self.match(DatalogParser.TOKEN_GREATER_EQUAL_THAN)
                localctx.r = (None if localctx.op4 is None else localctx.op4.text)
                pass
            elif token in [DatalogParser.TOKEN_LESS_THAN]:
                self.enterOuterAlt(localctx, 5)
                self.state = 304
                localctx.op5 = self.match(DatalogParser.TOKEN_LESS_THAN)
                localctx.r = (None if localctx.op5 is None else localctx.op5.text)
                pass
            elif token in [DatalogParser.TOKEN_LESS_EQUAL_THAN]:
                self.enterOuterAlt(localctx, 6)
                self.state = 306
                localctx.op6 = self.match(DatalogParser.TOKEN_LESS_EQUAL_THAN)
                localctx.r = (None if localctx.op6 is None else localctx.op6.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Aggregation_opContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.op1 = None # Token
            self.op2 = None # Token
            self.op3 = None # Token
            self.op4 = None # Token
            self.op5 = None # Token

        def TOKEN_MIN(self):
            return self.getToken(DatalogParser.TOKEN_MIN, 0)

        def TOKEN_MAX(self):
            return self.getToken(DatalogParser.TOKEN_MAX, 0)

        def TOKEN_SUM(self):
            return self.getToken(DatalogParser.TOKEN_SUM, 0)

        def TOKEN_COUNT(self):
            return self.getToken(DatalogParser.TOKEN_COUNT, 0)

        def TOKEN_COUNT_DISTINCT(self):
            return self.getToken(DatalogParser.TOKEN_COUNT_DISTINCT, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_aggregation_op




    def aggregation_op(self):

        localctx = DatalogParser.Aggregation_opContext(self, self._ctx, self.state)
        self.enterRule(localctx, 36, self.RULE_aggregation_op)
        try:
            self.state = 320
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_MIN]:
                self.enterOuterAlt(localctx, 1)
                self.state = 310
                localctx.op1 = self.match(DatalogParser.TOKEN_MIN)
                localctx.r = (None if localctx.op1 is None else localctx.op1.text)
                pass
            elif token in [DatalogParser.TOKEN_MAX]:
                self.enterOuterAlt(localctx, 2)
                self.state = 312
                localctx.op2 = self.match(DatalogParser.TOKEN_MAX)
                localctx.r = (None if localctx.op2 is None else localctx.op2.text)
                pass
            elif token in [DatalogParser.TOKEN_SUM]:
                self.enterOuterAlt(localctx, 3)
                self.state = 314
                localctx.op3 = self.match(DatalogParser.TOKEN_SUM)
                localctx.r = (None if localctx.op3 is None else localctx.op3.text)
                pass
            elif token in [DatalogParser.TOKEN_COUNT]:
                self.enterOuterAlt(localctx, 4)
                self.state = 316
                localctx.op4 = self.match(DatalogParser.TOKEN_COUNT)
                localctx.r = (None if localctx.op4 is None else localctx.op4.text)
                pass
            elif token in [DatalogParser.TOKEN_COUNT_DISTINCT]:
                self.enterOuterAlt(localctx, 5)
                self.state = 318
                localctx.op5 = self.match(DatalogParser.TOKEN_COUNT_DISTINCT)
                localctx.r = (None if localctx.op5 is None else localctx.op5.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Math_opContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.op1 = None # Token
            self.op2 = None # Token
            self.op3 = None # Token
            self.op4 = None # Token

        def TOKEN_PLUS(self):
            return self.getToken(DatalogParser.TOKEN_PLUS, 0)

        def TOKEN_MINUS(self):
            return self.getToken(DatalogParser.TOKEN_MINUS, 0)

        def TOKEN_MULT(self):
            return self.getToken(DatalogParser.TOKEN_MULT, 0)

        def TOKEN_DIV(self):
            return self.getToken(DatalogParser.TOKEN_DIV, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_math_op




    def math_op(self):

        localctx = DatalogParser.Math_opContext(self, self._ctx, self.state)
        self.enterRule(localctx, 38, self.RULE_math_op)
        try:
            self.state = 330
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_PLUS]:
                self.enterOuterAlt(localctx, 1)
                self.state = 322
                localctx.op1 = self.match(DatalogParser.TOKEN_PLUS)
                localctx.r = (None if localctx.op1 is None else localctx.op1.text)
                pass
            elif token in [DatalogParser.TOKEN_MINUS]:
                self.enterOuterAlt(localctx, 2)
                self.state = 324
                localctx.op2 = self.match(DatalogParser.TOKEN_MINUS)
                localctx.r = (None if localctx.op2 is None else localctx.op2.text)
                pass
            elif token in [DatalogParser.TOKEN_MULT]:
                self.enterOuterAlt(localctx, 3)
                self.state = 326
                localctx.op3 = self.match(DatalogParser.TOKEN_MULT)
                localctx.r = (None if localctx.op3 is None else localctx.op3.text)
                pass
            elif token in [DatalogParser.TOKEN_DIV]:
                self.enterOuterAlt(localctx, 4)
                self.state = 328
                localctx.op4 = self.match(DatalogParser.TOKEN_DIV)
                localctx.r = (None if localctx.op4 is None else localctx.op4.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ConstantContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.c1 = None # Token
            self.c2 = None # Token

        def TOKEN_INTEGER(self):
            return self.getToken(DatalogParser.TOKEN_INTEGER, 0)

        def TOKEN_STRING(self):
            return self.getToken(DatalogParser.TOKEN_STRING, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_constant




    def constant(self):

        localctx = DatalogParser.ConstantContext(self, self._ctx, self.state)
        self.enterRule(localctx, 40, self.RULE_constant)
        try:
            self.state = 336
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_INTEGER]:
                self.enterOuterAlt(localctx, 1)
                self.state = 332
                localctx.c1 = self.match(DatalogParser.TOKEN_INTEGER)
                localctx.r = (None if localctx.c1 is None else localctx.c1.text)
                pass
            elif token in [DatalogParser.TOKEN_STRING]:
                self.enterOuterAlt(localctx, 2)
                self.state = 334
                localctx.c2 = self.match(DatalogParser.TOKEN_STRING)
                localctx.r = (None if localctx.c2 is None else localctx.c2.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Data_typeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.dt1 = None # Token
            self.dt2 = None # Token
            self.dt3 = None # Token
            self.dt4 = None # Token
            self.dt5 = None # Token
            self.dt6 = None # Token
            self.dt7 = None # Token
            self.dt8 = None # Token

        def TOKEN_INT(self):
            return self.getToken(DatalogParser.TOKEN_INT, 0)

        def TOKEN_LONG(self):
            return self.getToken(DatalogParser.TOKEN_LONG, 0)

        def TOKEN_FLOAT(self):
            return self.getToken(DatalogParser.TOKEN_FLOAT, 0)

        def TOKEN_DOUBLE(self):
            return self.getToken(DatalogParser.TOKEN_DOUBLE, 0)

        def TOKEN_VARCHAR(self):
            return self.getToken(DatalogParser.TOKEN_VARCHAR, 0)

        def TOKEN_CHAR(self):
            return self.getToken(DatalogParser.TOKEN_CHAR, 0)

        def TOKEN_DATE(self):
            return self.getToken(DatalogParser.TOKEN_DATE, 0)

        def TOKEN_DATETIME(self):
            return self.getToken(DatalogParser.TOKEN_DATETIME, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_data_type




    def data_type(self):

        localctx = DatalogParser.Data_typeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 42, self.RULE_data_type)
        try:
            self.state = 354
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_INT]:
                self.enterOuterAlt(localctx, 1)
                self.state = 338
                localctx.dt1 = self.match(DatalogParser.TOKEN_INT)
                localctx.r = (None if localctx.dt1 is None else localctx.dt1.text)
                pass
            elif token in [DatalogParser.TOKEN_LONG]:
                self.enterOuterAlt(localctx, 2)
                self.state = 340
                localctx.dt2 = self.match(DatalogParser.TOKEN_LONG)
                localctx.r = (None if localctx.dt2 is None else localctx.dt2.text)
                pass
            elif token in [DatalogParser.TOKEN_FLOAT]:
                self.enterOuterAlt(localctx, 3)
                self.state = 342
                localctx.dt3 = self.match(DatalogParser.TOKEN_FLOAT)
                localctx.r = (None if localctx.dt3 is None else localctx.dt3.text)
                pass
            elif token in [DatalogParser.TOKEN_DOUBLE]:
                self.enterOuterAlt(localctx, 4)
                self.state = 344
                localctx.dt4 = self.match(DatalogParser.TOKEN_DOUBLE)
                localctx.r = (None if localctx.dt4 is None else localctx.dt4.text)
                pass
            elif token in [DatalogParser.TOKEN_VARCHAR]:
                self.enterOuterAlt(localctx, 5)
                self.state = 346
                localctx.dt5 = self.match(DatalogParser.TOKEN_VARCHAR)
                localctx.r = (None if localctx.dt5 is None else localctx.dt5.text)
                pass
            elif token in [DatalogParser.TOKEN_CHAR]:
                self.enterOuterAlt(localctx, 6)
                self.state = 348
                localctx.dt6 = self.match(DatalogParser.TOKEN_CHAR)
                localctx.r = (None if localctx.dt6 is None else localctx.dt6.text)
                pass
            elif token in [DatalogParser.TOKEN_DATE]:
                self.enterOuterAlt(localctx, 7)
                self.state = 350
                localctx.dt7 = self.match(DatalogParser.TOKEN_DATE)
                localctx.r = (None if localctx.dt7 is None else localctx.dt7.text)
                pass
            elif token in [DatalogParser.TOKEN_DATETIME]:
                self.enterOuterAlt(localctx, 8)
                self.state = 352
                localctx.dt8 = self.match(DatalogParser.TOKEN_DATETIME)
                localctx.r = (None if localctx.dt8 is None else localctx.dt8.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx





