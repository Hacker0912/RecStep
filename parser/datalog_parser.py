# Generated from Datalog.g4 by ANTLR 4.8
# encoding: utf-8
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
	from typing import TextIO
else:
	from typing.io import TextIO




def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3)")
        buf.write("\u013f\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7")
        buf.write("\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r\4\16")
        buf.write("\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23\t\23")
        buf.write("\4\24\t\24\3\2\3\2\3\2\3\2\3\2\3\2\3\2\3\2\7\2\61\n\2")
        buf.write("\f\2\16\2\64\13\2\3\2\3\2\3\3\3\3\3\3\3\3\3\3\3\3\3\3")
        buf.write("\3\3\7\3@\n\3\f\3\16\3C\13\3\3\3\3\3\3\4\3\4\3\4\3\4\3")
        buf.write("\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\7\4S\n\4\f\4\16\4V\13\4")
        buf.write("\3\4\3\4\3\4\3\5\3\5\3\5\3\5\3\5\3\5\3\6\3\6\3\6\3\6\3")
        buf.write("\6\3\6\7\6g\n\6\f\6\16\6j\13\6\3\6\3\6\3\7\3\7\3\7\3\7")
        buf.write("\3\7\3\7\3\7\3\7\5\7v\n\7\3\7\3\7\3\7\3\b\3\b\3\b\3\t")
        buf.write("\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\5\t\u008b")
        buf.write("\n\t\3\t\3\t\7\t\u008f\n\t\f\t\16\t\u0092\13\t\3\t\3\t")
        buf.write("\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\5\t\u00a0\n\t")
        buf.write("\3\t\3\t\3\n\3\n\3\n\3\n\3\13\3\13\3\13\3\13\3\13\3\13")
        buf.write("\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13")
        buf.write("\5\13\u00b9\n\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3")
        buf.write("\13\3\13\3\13\3\13\3\13\3\13\3\13\5\13\u00c9\n\13\7\13")
        buf.write("\u00cb\n\13\f\13\16\13\u00ce\13\13\3\13\3\13\3\13\3\f")
        buf.write("\3\f\3\f\3\f\3\f\3\f\3\f\3\f\3\r\3\r\3\r\3\r\3\r\3\r\3")
        buf.write("\r\3\r\3\r\3\16\3\16\3\16\3\16\3\16\5\16\u00e9\n\16\3")
        buf.write("\16\3\16\3\16\3\16\3\16\3\16\5\16\u00f1\n\16\3\16\3\16")
        buf.write("\3\17\3\17\3\17\3\17\3\17\3\17\3\17\3\17\3\17\5\17\u00fe")
        buf.write("\n\17\3\17\3\17\3\17\3\20\3\20\3\20\3\20\3\20\3\20\3\20")
        buf.write("\3\20\3\20\3\20\3\20\3\20\5\20\u010f\n\20\3\21\3\21\3")
        buf.write("\21\3\21\3\21\3\21\3\21\3\21\3\21\3\21\5\21\u011b\n\21")
        buf.write("\3\22\3\22\3\22\3\22\3\22\3\22\3\22\3\22\5\22\u0125\n")
        buf.write("\22\3\23\3\23\3\23\3\23\5\23\u012b\n\23\3\24\3\24\3\24")
        buf.write("\3\24\3\24\3\24\3\24\3\24\3\24\3\24\3\24\3\24\3\24\3\24")
        buf.write("\3\24\3\24\5\24\u013d\n\24\3\24\2\2\25\2\4\6\b\n\f\16")
        buf.write("\20\22\24\26\30\32\34\36 \"$&\2\2\2\u0157\2(\3\2\2\2\4")
        buf.write("\67\3\2\2\2\6F\3\2\2\2\bZ\3\2\2\2\n`\3\2\2\2\fm\3\2\2")
        buf.write("\2\16z\3\2\2\2\20}\3\2\2\2\22\u00a3\3\2\2\2\24\u00a7\3")
        buf.write("\2\2\2\26\u00d2\3\2\2\2\30\u00da\3\2\2\2\32\u00e3\3\2")
        buf.write("\2\2\34\u00f4\3\2\2\2\36\u010e\3\2\2\2 \u011a\3\2\2\2")
        buf.write("\"\u0124\3\2\2\2$\u012a\3\2\2\2&\u013c\3\2\2\2()\b\2\1")
        buf.write("\2)*\7\3\2\2*+\7\32\2\2+,\5\6\4\2,\62\b\2\1\2-.\5\6\4")
        buf.write("\2./\b\2\1\2/\61\3\2\2\2\60-\3\2\2\2\61\64\3\2\2\2\62")
        buf.write("\60\3\2\2\2\62\63\3\2\2\2\63\65\3\2\2\2\64\62\3\2\2\2")
        buf.write("\65\66\b\2\1\2\66\3\3\2\2\2\678\b\3\1\289\7\4\2\29:\7")
        buf.write("\32\2\2:;\5\6\4\2;A\b\3\1\2<=\5\6\4\2=>\b\3\1\2>@\3\2")
        buf.write("\2\2?<\3\2\2\2@C\3\2\2\2A?\3\2\2\2AB\3\2\2\2BD\3\2\2\2")
        buf.write("CA\3\2\2\2DE\b\3\1\2E\5\3\2\2\2FG\b\4\1\2GH\7\25\2\2H")
        buf.write("I\b\4\1\2IJ\7\'\2\2JK\7\25\2\2KL\5&\24\2LT\b\4\1\2MN\7")
        buf.write("\30\2\2NO\7\25\2\2OP\5&\24\2PQ\b\4\1\2QS\3\2\2\2RM\3\2")
        buf.write("\2\2SV\3\2\2\2TR\3\2\2\2TU\3\2\2\2UW\3\2\2\2VT\3\2\2\2")
        buf.write("WX\7(\2\2XY\b\4\1\2Y\7\3\2\2\2Z[\7\5\2\2[\\\7\32\2\2\\")
        buf.write("]\5\n\6\2]^\b\5\1\2^_\7\2\2\3_\t\3\2\2\2`a\b\6\1\2ab\5")
        buf.write("\f\7\2bh\b\6\1\2cd\5\f\7\2de\b\6\1\2eg\3\2\2\2fc\3\2\2")
        buf.write("\2gj\3\2\2\2hf\3\2\2\2hi\3\2\2\2ik\3\2\2\2jh\3\2\2\2k")
        buf.write("l\b\6\1\2l\13\3\2\2\2mn\b\7\1\2no\5\16\b\2op\b\7\1\2p")
        buf.write("q\7\26\2\2qu\b\7\1\2rs\5\20\t\2st\b\7\1\2tv\3\2\2\2ur")
        buf.write("\3\2\2\2uv\3\2\2\2vw\3\2\2\2wx\7\33\2\2xy\b\7\1\2y\r\3")
        buf.write("\2\2\2z{\5\24\13\2{|\b\b\1\2|\17\3\2\2\2}\u0090\b\t\1")
        buf.write("\2~\177\5\24\13\2\177\u0080\b\t\1\2\u0080\u008b\3\2\2")
        buf.write("\2\u0081\u0082\5\32\16\2\u0082\u0083\b\t\1\2\u0083\u008b")
        buf.write("\3\2\2\2\u0084\u0085\5\26\f\2\u0085\u0086\b\t\1\2\u0086")
        buf.write("\u008b\3\2\2\2\u0087\u0088\5\22\n\2\u0088\u0089\b\t\1")
        buf.write("\2\u0089\u008b\3\2\2\2\u008a~\3\2\2\2\u008a\u0081\3\2")
        buf.write("\2\2\u008a\u0084\3\2\2\2\u008a\u0087\3\2\2\2\u008b\u008c")
        buf.write("\3\2\2\2\u008c\u008d\7\30\2\2\u008d\u008f\3\2\2\2\u008e")
        buf.write("\u008a\3\2\2\2\u008f\u0092\3\2\2\2\u0090\u008e\3\2\2\2")
        buf.write("\u0090\u0091\3\2\2\2\u0091\u009f\3\2\2\2\u0092\u0090\3")
        buf.write("\2\2\2\u0093\u0094\5\24\13\2\u0094\u0095\b\t\1\2\u0095")
        buf.write("\u00a0\3\2\2\2\u0096\u0097\5\32\16\2\u0097\u0098\b\t\1")
        buf.write("\2\u0098\u00a0\3\2\2\2\u0099\u009a\5\26\f\2\u009a\u009b")
        buf.write("\b\t\1\2\u009b\u00a0\3\2\2\2\u009c\u009d\5\22\n\2\u009d")
        buf.write("\u009e\b\t\1\2\u009e\u00a0\3\2\2\2\u009f\u0093\3\2\2\2")
        buf.write("\u009f\u0096\3\2\2\2\u009f\u0099\3\2\2\2\u009f\u009c\3")
        buf.write("\2\2\2\u00a0\u00a1\3\2\2\2\u00a1\u00a2\b\t\1\2\u00a2\21")
        buf.write("\3\2\2\2\u00a3\u00a4\7 \2\2\u00a4\u00a5\5\24\13\2\u00a5")
        buf.write("\u00a6\b\n\1\2\u00a6\23\3\2\2\2\u00a7\u00a8\b\13\1\2\u00a8")
        buf.write("\u00a9\7\25\2\2\u00a9\u00aa\b\13\1\2\u00aa\u00b8\7\'\2")
        buf.write("\2\u00ab\u00ac\7\25\2\2\u00ac\u00b9\b\13\1\2\u00ad\u00ae")
        buf.write("\5\34\17\2\u00ae\u00af\b\13\1\2\u00af\u00b9\3\2\2\2\u00b0")
        buf.write("\u00b1\7\27\2\2\u00b1\u00b9\b\13\1\2\u00b2\u00b3\5$\23")
        buf.write("\2\u00b3\u00b4\b\13\1\2\u00b4\u00b9\3\2\2\2\u00b5\u00b6")
        buf.write("\5\30\r\2\u00b6\u00b7\b\13\1\2\u00b7\u00b9\3\2\2\2\u00b8")
        buf.write("\u00ab\3\2\2\2\u00b8\u00ad\3\2\2\2\u00b8\u00b0\3\2\2\2")
        buf.write("\u00b8\u00b2\3\2\2\2\u00b8\u00b5\3\2\2\2\u00b9\u00cc\3")
        buf.write("\2\2\2\u00ba\u00c8\7\30\2\2\u00bb\u00bc\7\25\2\2\u00bc")
        buf.write("\u00c9\b\13\1\2\u00bd\u00be\5\34\17\2\u00be\u00bf\b\13")
        buf.write("\1\2\u00bf\u00c9\3\2\2\2\u00c0\u00c1\7\27\2\2\u00c1\u00c9")
        buf.write("\b\13\1\2\u00c2\u00c3\5$\23\2\u00c3\u00c4\b\13\1\2\u00c4")
        buf.write("\u00c9\3\2\2\2\u00c5\u00c6\5\30\r\2\u00c6\u00c7\b\13\1")
        buf.write("\2\u00c7\u00c9\3\2\2\2\u00c8\u00bb\3\2\2\2\u00c8\u00bd")
        buf.write("\3\2\2\2\u00c8\u00c0\3\2\2\2\u00c8\u00c2\3\2\2\2\u00c8")
        buf.write("\u00c5\3\2\2\2\u00c9\u00cb\3\2\2\2\u00ca\u00ba\3\2\2\2")
        buf.write("\u00cb\u00ce\3\2\2\2\u00cc\u00ca\3\2\2\2\u00cc\u00cd\3")
        buf.write("\2\2\2\u00cd\u00cf\3\2\2\2\u00ce\u00cc\3\2\2\2\u00cf\u00d0")
        buf.write("\7(\2\2\u00d0\u00d1\b\13\1\2\u00d1\25\3\2\2\2\u00d2\u00d3")
        buf.write("\b\f\1\2\u00d3\u00d4\7\25\2\2\u00d4\u00d5\b\f\1\2\u00d5")
        buf.write("\u00d6\7\"\2\2\u00d6\u00d7\5\30\r\2\u00d7\u00d8\b\f\1")
        buf.write("\2\u00d8\u00d9\b\f\1\2\u00d9\27\3\2\2\2\u00da\u00db\b")
        buf.write("\r\1\2\u00db\u00dc\7\25\2\2\u00dc\u00dd\b\r\1\2\u00dd")
        buf.write("\u00de\5\"\22\2\u00de\u00df\b\r\1\2\u00df\u00e0\7\25\2")
        buf.write("\2\u00e0\u00e1\b\r\1\2\u00e1\u00e2\b\r\1\2\u00e2\31\3")
        buf.write("\2\2\2\u00e3\u00e8\b\16\1\2\u00e4\u00e5\7\25\2\2\u00e5")
        buf.write("\u00e9\b\16\1\2\u00e6\u00e7\7\6\2\2\u00e7\u00e9\b\16\1")
        buf.write("\2\u00e8\u00e4\3\2\2\2\u00e8\u00e6\3\2\2\2\u00e9\u00ea")
        buf.write("\3\2\2\2\u00ea\u00eb\5\36\20\2\u00eb\u00f0\b\16\1\2\u00ec")
        buf.write("\u00ed\7\25\2\2\u00ed\u00f1\b\16\1\2\u00ee\u00ef\7\6\2")
        buf.write("\2\u00ef\u00f1\b\16\1\2\u00f0\u00ec\3\2\2\2\u00f0\u00ee")
        buf.write("\3\2\2\2\u00f1\u00f2\3\2\2\2\u00f2\u00f3\b\16\1\2\u00f3")
        buf.write("\33\3\2\2\2\u00f4\u00f5\b\17\1\2\u00f5\u00f6\5 \21\2\u00f6")
        buf.write("\u00f7\b\17\1\2\u00f7\u00fd\7\'\2\2\u00f8\u00f9\7\25\2")
        buf.write("\2\u00f9\u00fe\b\17\1\2\u00fa\u00fb\5\30\r\2\u00fb\u00fc")
        buf.write("\b\17\1\2\u00fc\u00fe\3\2\2\2\u00fd\u00f8\3\2\2\2\u00fd")
        buf.write("\u00fa\3\2\2\2\u00fe\u00ff\3\2\2\2\u00ff\u0100\7(\2\2")
        buf.write("\u0100\u0101\b\17\1\2\u0101\35\3\2\2\2\u0102\u0103\7!")
        buf.write("\2\2\u0103\u010f\b\20\1\2\u0104\u0105\7\"\2\2\u0105\u010f")
        buf.write("\b\20\1\2\u0106\u0107\7$\2\2\u0107\u010f\b\20\1\2\u0108")
        buf.write("\u0109\7#\2\2\u0109\u010f\b\20\1\2\u010a\u010b\7&\2\2")
        buf.write("\u010b\u010f\b\20\1\2\u010c\u010d\7%\2\2\u010d\u010f\b")
        buf.write("\20\1\2\u010e\u0102\3\2\2\2\u010e\u0104\3\2\2\2\u010e")
        buf.write("\u0106\3\2\2\2\u010e\u0108\3\2\2\2\u010e\u010a\3\2\2\2")
        buf.write("\u010e\u010c\3\2\2\2\u010f\37\3\2\2\2\u0110\u0111\7\20")
        buf.write("\2\2\u0111\u011b\b\21\1\2\u0112\u0113\7\21\2\2\u0113\u011b")
        buf.write("\b\21\1\2\u0114\u0115\7\22\2\2\u0115\u011b\b\21\1\2\u0116")
        buf.write("\u0117\7\23\2\2\u0117\u011b\b\21\1\2\u0118\u0119\7\24")
        buf.write("\2\2\u0119\u011b\b\21\1\2\u011a\u0110\3\2\2\2\u011a\u0112")
        buf.write("\3\2\2\2\u011a\u0114\3\2\2\2\u011a\u0116\3\2\2\2\u011a")
        buf.write("\u0118\3\2\2\2\u011b!\3\2\2\2\u011c\u011d\7\34\2\2\u011d")
        buf.write("\u0125\b\22\1\2\u011e\u011f\7\35\2\2\u011f\u0125\b\22")
        buf.write("\1\2\u0120\u0121\7\36\2\2\u0121\u0125\b\22\1\2\u0122\u0123")
        buf.write("\7\37\2\2\u0123\u0125\b\22\1\2\u0124\u011c\3\2\2\2\u0124")
        buf.write("\u011e\3\2\2\2\u0124\u0120\3\2\2\2\u0124\u0122\3\2\2\2")
        buf.write("\u0125#\3\2\2\2\u0126\u0127\7\6\2\2\u0127\u012b\b\23\1")
        buf.write("\2\u0128\u0129\7\7\2\2\u0129\u012b\b\23\1\2\u012a\u0126")
        buf.write("\3\2\2\2\u012a\u0128\3\2\2\2\u012b%\3\2\2\2\u012c\u012d")
        buf.write("\7\b\2\2\u012d\u013d\b\24\1\2\u012e\u012f\7\t\2\2\u012f")
        buf.write("\u013d\b\24\1\2\u0130\u0131\7\n\2\2\u0131\u013d\b\24\1")
        buf.write("\2\u0132\u0133\7\13\2\2\u0133\u013d\b\24\1\2\u0134\u0135")
        buf.write("\7\f\2\2\u0135\u013d\b\24\1\2\u0136\u0137\7\r\2\2\u0137")
        buf.write("\u013d\b\24\1\2\u0138\u0139\7\16\2\2\u0139\u013d\b\24")
        buf.write("\1\2\u013a\u013b\7\17\2\2\u013b\u013d\b\24\1\2\u013c\u012c")
        buf.write("\3\2\2\2\u013c\u012e\3\2\2\2\u013c\u0130\3\2\2\2\u013c")
        buf.write("\u0132\3\2\2\2\u013c\u0134\3\2\2\2\u013c\u0136\3\2\2\2")
        buf.write("\u013c\u0138\3\2\2\2\u013c\u013a\3\2\2\2\u013d\'\3\2\2")
        buf.write("\2\25\62AThu\u008a\u0090\u009f\u00b8\u00c8\u00cc\u00e8")
        buf.write("\u00f0\u00fd\u010e\u011a\u0124\u012a\u013c")
        return buf.getvalue()


class DatalogParser ( Parser ):

    grammarFileName = "Datalog.g4"

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    sharedContextCache = PredictionContextCache()

    literalNames = [ "<INVALID>", "'EDB_DECL'", "'IDB_DECL'", "'RULE_DECL'", 
                     "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "<INVALID>", "'MIN'", "'MAX'", "'SUM'", 
                     "'COUNT'", "'COUNT_DISTINCT'", "<INVALID>", "':-'", 
                     "'_'", "','", "';'", "':'", "'.'", "'+'", "'-'", "'*'", 
                     "'/'", "'!'", "'!='", "'='", "'>='", "'>'", "'<='", 
                     "'<'", "'('", "')'" ]

    symbolicNames = [ "<INVALID>", "TOKEN_EDB", "TOKEN_IDB", "TOKEN_RULE", 
                      "TOKEN_INTEGER", "TOKEN_STRING", "TOKEN_INT", "TOKEN_LONG", 
                      "TOKEN_FLOAT", "TOKEN_DOUBLE", "TOKEN_VARCHAR", "TOKEN_CHAR", 
                      "TOKEN_DATE", "TOKEN_DATETIME", "TOKEN_MIN", "TOKEN_MAX", 
                      "TOKEN_SUM", "TOKEN_COUNT", "TOKEN_COUNT_DISTINCT", 
                      "TOKEN_ID", "TOKEN_BODY_HEAD_SEP", "TOKEN_ANY", "TOKEN_COMMA", 
                      "TOKEN_SEMICOLON", "TOKEN_COLON", "TOKEN_DOT", "TOKEN_PLUS", 
                      "TOKEN_MINUS", "TOKEN_MULT", "TOKEN_DIV", "TOKEN_NOT", 
                      "TOKEN_NOT_EQUALS", "TOKEN_EQUALS", "TOKEN_GREATER_EQUAL_THAN", 
                      "TOKEN_GREATER_THAN", "TOKEN_LESS_EQUAL_THAN", "TOKEN_LESS_THAN", 
                      "TOKEN_LEFT_PAREN", "TOKEN_RIGHT_PAREN", "TOKEN_WS" ]

    RULE_datalog_edb_declare = 0
    RULE_datalog_idb_declare = 1
    RULE_datalog_relation_schema = 2
    RULE_datalog_rule_declare = 3
    RULE_datalog_program = 4
    RULE_datalog_rule = 5
    RULE_head = 6
    RULE_body = 7
    RULE_negation = 8
    RULE_atom = 9
    RULE_assign = 10
    RULE_math_expr = 11
    RULE_compare_expr = 12
    RULE_aggregation_expr = 13
    RULE_compare_op = 14
    RULE_aggregation_op = 15
    RULE_math_op = 16
    RULE_constant = 17
    RULE_data_type = 18

    ruleNames =  [ "datalog_edb_declare", "datalog_idb_declare", "datalog_relation_schema", 
                   "datalog_rule_declare", "datalog_program", "datalog_rule", 
                   "head", "body", "negation", "atom", "assign", "math_expr", 
                   "compare_expr", "aggregation_expr", "compare_op", "aggregation_op", 
                   "math_op", "constant", "data_type" ]

    EOF = Token.EOF
    TOKEN_EDB=1
    TOKEN_IDB=2
    TOKEN_RULE=3
    TOKEN_INTEGER=4
    TOKEN_STRING=5
    TOKEN_INT=6
    TOKEN_LONG=7
    TOKEN_FLOAT=8
    TOKEN_DOUBLE=9
    TOKEN_VARCHAR=10
    TOKEN_CHAR=11
    TOKEN_DATE=12
    TOKEN_DATETIME=13
    TOKEN_MIN=14
    TOKEN_MAX=15
    TOKEN_SUM=16
    TOKEN_COUNT=17
    TOKEN_COUNT_DISTINCT=18
    TOKEN_ID=19
    TOKEN_BODY_HEAD_SEP=20
    TOKEN_ANY=21
    TOKEN_COMMA=22
    TOKEN_SEMICOLON=23
    TOKEN_COLON=24
    TOKEN_DOT=25
    TOKEN_PLUS=26
    TOKEN_MINUS=27
    TOKEN_MULT=28
    TOKEN_DIV=29
    TOKEN_NOT=30
    TOKEN_NOT_EQUALS=31
    TOKEN_EQUALS=32
    TOKEN_GREATER_EQUAL_THAN=33
    TOKEN_GREATER_THAN=34
    TOKEN_LESS_EQUAL_THAN=35
    TOKEN_LESS_THAN=36
    TOKEN_LEFT_PAREN=37
    TOKEN_RIGHT_PAREN=38
    TOKEN_WS=39

    def __init__(self, input:TokenStream, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.8")
        self._interp = ParserATNSimulator(self, self.atn, self.decisionsToDFA, self.sharedContextCache)
        self._predicates = None




    class AtomArg():
        def __init__(self, arg_name, arg_type):
            self.name = arg_name
            self.type = arg_type



    class Datalog_edb_declareContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.schema1 = None # Datalog_relation_schemaContext
            self.schema2 = None # Datalog_relation_schemaContext

        def TOKEN_EDB(self):
            return self.getToken(DatalogParser.TOKEN_EDB, 0)

        def TOKEN_COLON(self):
            return self.getToken(DatalogParser.TOKEN_COLON, 0)

        def datalog_relation_schema(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Datalog_relation_schemaContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Datalog_relation_schemaContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_edb_declare




    def datalog_edb_declare(self):

        localctx = DatalogParser.Datalog_edb_declareContext(self, self._ctx, self.state)
        self.enterRule(localctx, 0, self.RULE_datalog_edb_declare)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            edb_list = []
            self.state = 39
            self.match(DatalogParser.TOKEN_EDB)
            self.state = 40
            self.match(DatalogParser.TOKEN_COLON)
            self.state = 41
            localctx.schema1 = self.datalog_relation_schema()
            edb_list.append(localctx.schema1.r)
            self.state = 48
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_ID:
                self.state = 43
                localctx.schema2 = self.datalog_relation_schema()
                edb_list.append(localctx.schema2.r)
                self.state = 50
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            localctx.r = edb_list
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_idb_declareContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.schema1 = None # Datalog_relation_schemaContext
            self.schema2 = None # Datalog_relation_schemaContext

        def TOKEN_IDB(self):
            return self.getToken(DatalogParser.TOKEN_IDB, 0)

        def TOKEN_COLON(self):
            return self.getToken(DatalogParser.TOKEN_COLON, 0)

        def datalog_relation_schema(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Datalog_relation_schemaContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Datalog_relation_schemaContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_idb_declare




    def datalog_idb_declare(self):

        localctx = DatalogParser.Datalog_idb_declareContext(self, self._ctx, self.state)
        self.enterRule(localctx, 2, self.RULE_datalog_idb_declare)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            idb_list = []
            self.state = 54
            self.match(DatalogParser.TOKEN_IDB)
            self.state = 55
            self.match(DatalogParser.TOKEN_COLON)
            self.state = 56
            localctx.schema1 = self.datalog_relation_schema()
            idb_list.append(localctx.schema1.r)
            self.state = 63
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_ID:
                self.state = 58
                localctx.schema2 = self.datalog_relation_schema()
                idb_list.append(localctx.schema2.r)
                self.state = 65
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            localctx.r = idb_list
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_relation_schemaContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.relation_name = None # Token
            self.t1 = None # Token
            self.dt1 = None # Data_typeContext
            self.t2 = None # Token
            self.dt2 = None # Data_typeContext

        def TOKEN_LEFT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_PAREN, 0)

        def TOKEN_RIGHT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_PAREN, 0)

        def TOKEN_ID(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ID)
            else:
                return self.getToken(DatalogParser.TOKEN_ID, i)

        def data_type(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Data_typeContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Data_typeContext,i)


        def TOKEN_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_COMMA)
            else:
                return self.getToken(DatalogParser.TOKEN_COMMA, i)

        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_relation_schema




    def datalog_relation_schema(self):

        localctx = DatalogParser.Datalog_relation_schemaContext(self, self._ctx, self.state)
        self.enterRule(localctx, 4, self.RULE_datalog_relation_schema)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            schema = {'name': '', 'attributes': []}
            self.state = 69
            localctx.relation_name = self.match(DatalogParser.TOKEN_ID)
            schema['name'] = (None if localctx.relation_name is None else localctx.relation_name.text)
            self.state = 71
            self.match(DatalogParser.TOKEN_LEFT_PAREN)
            self.state = 72
            localctx.t1 = self.match(DatalogParser.TOKEN_ID)
            self.state = 73
            localctx.dt1 = self.data_type()
            schema['attributes'].append(self.AtomArg((None if localctx.t1 is None else localctx.t1.text), localctx.dt1.r))
            self.state = 82
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_COMMA:
                self.state = 75
                self.match(DatalogParser.TOKEN_COMMA)
                self.state = 76
                localctx.t2 = self.match(DatalogParser.TOKEN_ID)
                self.state = 77
                localctx.dt2 = self.data_type()
                schema['attributes'].append(self.AtomArg((None if localctx.t2 is None else localctx.t2.text), localctx.dt2.r))
                self.state = 84
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 85
            self.match(DatalogParser.TOKEN_RIGHT_PAREN)
            localctx.r = schema
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_rule_declareContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.dp = None # Datalog_programContext

        def TOKEN_RULE(self):
            return self.getToken(DatalogParser.TOKEN_RULE, 0)

        def TOKEN_COLON(self):
            return self.getToken(DatalogParser.TOKEN_COLON, 0)

        def EOF(self):
            return self.getToken(DatalogParser.EOF, 0)

        def datalog_program(self):
            return self.getTypedRuleContext(DatalogParser.Datalog_programContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_rule_declare




    def datalog_rule_declare(self):

        localctx = DatalogParser.Datalog_rule_declareContext(self, self._ctx, self.state)
        self.enterRule(localctx, 6, self.RULE_datalog_rule_declare)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 88
            self.match(DatalogParser.TOKEN_RULE)
            self.state = 89
            self.match(DatalogParser.TOKEN_COLON)
            self.state = 90
            localctx.dp = self.datalog_program()
            localctx.r = localctx.dp.r
            self.state = 92
            self.match(DatalogParser.EOF)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_programContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.r1 = None # Datalog_ruleContext
            self.r2 = None # Datalog_ruleContext

        def datalog_rule(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Datalog_ruleContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Datalog_ruleContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_program




    def datalog_program(self):

        localctx = DatalogParser.Datalog_programContext(self, self._ctx, self.state)
        self.enterRule(localctx, 8, self.RULE_datalog_program)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            rule_list = []
            self.state = 95
            localctx.r1 = self.datalog_rule()
            rule_list.append(localctx.r1.r)
            self.state = 102
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_ID:
                self.state = 97
                localctx.r2 = self.datalog_rule()
                rule_list.append(localctx.r2.r)
                self.state = 104
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            localctx.r = rule_list
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_ruleContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.h = None # HeadContext
            self.b = None # BodyContext

        def TOKEN_BODY_HEAD_SEP(self):
            return self.getToken(DatalogParser.TOKEN_BODY_HEAD_SEP, 0)

        def TOKEN_DOT(self):
            return self.getToken(DatalogParser.TOKEN_DOT, 0)

        def head(self):
            return self.getTypedRuleContext(DatalogParser.HeadContext,0)


        def body(self):
            return self.getTypedRuleContext(DatalogParser.BodyContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_rule




    def datalog_rule(self):

        localctx = DatalogParser.Datalog_ruleContext(self, self._ctx, self.state)
        self.enterRule(localctx, 10, self.RULE_datalog_rule)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            rule_dic = {}
            self.state = 108
            localctx.h = self.head()
            rule_dic['head'] = localctx.h.r
            self.state = 110
            self.match(DatalogParser.TOKEN_BODY_HEAD_SEP)
            rule_dic['body'] = None
            self.state = 115
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << DatalogParser.TOKEN_INTEGER) | (1 << DatalogParser.TOKEN_ID) | (1 << DatalogParser.TOKEN_NOT))) != 0):
                self.state = 112
                localctx.b = self.body()
                rule_dic['body'] = localctx.b.r


            self.state = 117
            self.match(DatalogParser.TOKEN_DOT)
            localctx.r = rule_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class HeadContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a = None # AtomContext

        def atom(self):
            return self.getTypedRuleContext(DatalogParser.AtomContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_head




    def head(self):

        localctx = DatalogParser.HeadContext(self, self._ctx, self.state)
        self.enterRule(localctx, 12, self.RULE_head)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 120
            localctx.a = self.atom()
            localctx.r = localctx.a.r
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class BodyContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.b1 = None # AtomContext
            self.b2 = None # Compare_exprContext
            self.b3 = None # AssignContext
            self.b4 = None # NegationContext
            self.b5 = None # AtomContext
            self.b6 = None # Compare_exprContext
            self.b7 = None # AssignContext
            self.b8 = None # NegationContext

        def TOKEN_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_COMMA)
            else:
                return self.getToken(DatalogParser.TOKEN_COMMA, i)

        def atom(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.AtomContext)
            else:
                return self.getTypedRuleContext(DatalogParser.AtomContext,i)


        def compare_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Compare_exprContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Compare_exprContext,i)


        def assign(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.AssignContext)
            else:
                return self.getTypedRuleContext(DatalogParser.AssignContext,i)


        def negation(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.NegationContext)
            else:
                return self.getTypedRuleContext(DatalogParser.NegationContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_body




    def body(self):

        localctx = DatalogParser.BodyContext(self, self._ctx, self.state)
        self.enterRule(localctx, 14, self.RULE_body)
        try:
            self.enterOuterAlt(localctx, 1)
            body_dic = {'atoms':[], 'compares': [], 'assigns':[], 'negations':[]}
            self.state = 142
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,6,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 136
                    self._errHandler.sync(self)
                    la_ = self._interp.adaptivePredict(self._input,5,self._ctx)
                    if la_ == 1:
                        self.state = 124
                        localctx.b1 = self.atom()
                        body_dic['atoms'].append(localctx.b1.r)
                        pass

                    elif la_ == 2:
                        self.state = 127
                        localctx.b2 = self.compare_expr()
                        body_dic['compares'].append(localctx.b2.r)
                        pass

                    elif la_ == 3:
                        self.state = 130
                        localctx.b3 = self.assign()
                        body_dic['assigns'].append(localctx.b3.r)
                        pass

                    elif la_ == 4:
                        self.state = 133
                        localctx.b4 = self.negation()
                        body_dic['negations'].append(localctx.b4.r)
                        pass


                    self.state = 138
                    self.match(DatalogParser.TOKEN_COMMA) 
                self.state = 144
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,6,self._ctx)

            self.state = 157
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,7,self._ctx)
            if la_ == 1:
                self.state = 145
                localctx.b5 = self.atom()
                body_dic['atoms'].append(localctx.b5.r)
                pass

            elif la_ == 2:
                self.state = 148
                localctx.b6 = self.compare_expr()
                body_dic['compares'].append(localctx.b6.r)
                pass

            elif la_ == 3:
                self.state = 151
                localctx.b7 = self.assign()
                body_dic['assigns'].append(localctx.b7.r)
                pass

            elif la_ == 4:
                self.state = 154
                localctx.b8 = self.negation()
                body_dic['negations'].append(localctx.b8.r)
                pass


            localctx.r = body_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class NegationContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a = None # AtomContext

        def TOKEN_NOT(self):
            return self.getToken(DatalogParser.TOKEN_NOT, 0)

        def atom(self):
            return self.getTypedRuleContext(DatalogParser.AtomContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_negation




    def negation(self):

        localctx = DatalogParser.NegationContext(self, self._ctx, self.state)
        self.enterRule(localctx, 16, self.RULE_negation)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 161
            self.match(DatalogParser.TOKEN_NOT)
            self.state = 162
            localctx.a = self.atom()
            localctx.r = localctx.a.r
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AtomContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token
            self.a2 = None # Token
            self.a3 = None # Aggregation_exprContext
            self.a4 = None # Token
            self.a5 = None # ConstantContext
            self.a6 = None # Math_exprContext
            self.a7 = None # Token
            self.a8 = None # Aggregation_exprContext
            self.a9 = None # Token
            self.a10 = None # ConstantContext
            self.a11 = None # Math_exprContext

        def TOKEN_LEFT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_PAREN, 0)

        def TOKEN_RIGHT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_PAREN, 0)

        def TOKEN_ID(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ID)
            else:
                return self.getToken(DatalogParser.TOKEN_ID, i)

        def aggregation_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Aggregation_exprContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Aggregation_exprContext,i)


        def TOKEN_ANY(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ANY)
            else:
                return self.getToken(DatalogParser.TOKEN_ANY, i)

        def constant(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.ConstantContext)
            else:
                return self.getTypedRuleContext(DatalogParser.ConstantContext,i)


        def math_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Math_exprContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Math_exprContext,i)


        def TOKEN_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_COMMA)
            else:
                return self.getToken(DatalogParser.TOKEN_COMMA, i)

        def getRuleIndex(self):
            return DatalogParser.RULE_atom




    def atom(self):

        localctx = DatalogParser.AtomContext(self, self._ctx, self.state)
        self.enterRule(localctx, 18, self.RULE_atom)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            atom_dic = {'name': None, 'arg_list':[]}
            self.state = 166
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            atom_dic['name'] = (None if localctx.a1 is None else localctx.a1.text)
            self.state = 168
            self.match(DatalogParser.TOKEN_LEFT_PAREN)
            self.state = 182
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,8,self._ctx)
            if la_ == 1:
                self.state = 169
                localctx.a2 = self.match(DatalogParser.TOKEN_ID)
                atom_dic['arg_list'].append(self.AtomArg((None if localctx.a2 is None else localctx.a2.text), 'variable'))
                pass

            elif la_ == 2:
                self.state = 171
                localctx.a3 = self.aggregation_expr()
                atom_dic['arg_list'].append(self.AtomArg(localctx.a3.r, 'aggregation'))
                pass

            elif la_ == 3:
                self.state = 174
                localctx.a4 = self.match(DatalogParser.TOKEN_ANY)
                atom_dic['arg_list'].append(self.AtomArg((None if localctx.a4 is None else localctx.a4.text), 'any'))
                pass

            elif la_ == 4:
                self.state = 176
                localctx.a5 = self.constant()
                atom_dic['arg_list'].append(self.AtomArg((None if localctx.a5 is None else self._input.getText(localctx.a5.start,localctx.a5.stop)), 'constant'))
                pass

            elif la_ == 5:
                self.state = 179
                localctx.a6 = self.math_expr()
                atom_dic['arg_list'].append(self.AtomArg(localctx.a6.r, 'math_expr'))
                pass


            self.state = 202
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_COMMA:
                self.state = 184
                self.match(DatalogParser.TOKEN_COMMA)
                self.state = 198
                self._errHandler.sync(self)
                la_ = self._interp.adaptivePredict(self._input,9,self._ctx)
                if la_ == 1:
                    self.state = 185
                    localctx.a7 = self.match(DatalogParser.TOKEN_ID)
                    atom_dic['arg_list'].append(self.AtomArg((None if localctx.a7 is None else localctx.a7.text), 'variable'))
                    pass

                elif la_ == 2:
                    self.state = 187
                    localctx.a8 = self.aggregation_expr()
                    atom_dic['arg_list'].append(self.AtomArg(localctx.a8.r, 'aggregation'))
                    pass

                elif la_ == 3:
                    self.state = 190
                    localctx.a9 = self.match(DatalogParser.TOKEN_ANY)
                    atom_dic['arg_list'].append(self.AtomArg((None if localctx.a9 is None else localctx.a9.text), 'any'))
                    pass

                elif la_ == 4:
                    self.state = 192
                    localctx.a10 = self.constant()
                    atom_dic['arg_list'].append(self.AtomArg((None if localctx.a10 is None else self._input.getText(localctx.a10.start,localctx.a10.stop)), 'constant'))
                    pass

                elif la_ == 5:
                    self.state = 195
                    localctx.a11 = self.math_expr()
                    atom_dic['arg_list'].append(self.AtomArg(localctx.a11.r, 'math_expr'))
                    pass


                self.state = 204
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 205
            self.match(DatalogParser.TOKEN_RIGHT_PAREN)
            localctx.r = atom_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AssignContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token
            self.a2 = None # Math_exprContext

        def TOKEN_EQUALS(self):
            return self.getToken(DatalogParser.TOKEN_EQUALS, 0)

        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def math_expr(self):
            return self.getTypedRuleContext(DatalogParser.Math_exprContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_assign




    def assign(self):

        localctx = DatalogParser.AssignContext(self, self._ctx, self.state)
        self.enterRule(localctx, 20, self.RULE_assign)
        try:
            self.enterOuterAlt(localctx, 1)
            assign_dic = {}
            self.state = 209
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            assign_dic['lhs'] = (None if localctx.a1 is None else localctx.a1.text)
            self.state = 211
            self.match(DatalogParser.TOKEN_EQUALS)
            self.state = 212
            localctx.a2 = self.math_expr()
            assign_dic['rhs'] = localctx.a2.r
            localctx.r = assign_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Math_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.m1 = None # Token
            self.m2 = None # Math_opContext
            self.m3 = None # Token

        def TOKEN_ID(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ID)
            else:
                return self.getToken(DatalogParser.TOKEN_ID, i)

        def math_op(self):
            return self.getTypedRuleContext(DatalogParser.Math_opContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_math_expr




    def math_expr(self):

        localctx = DatalogParser.Math_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 22, self.RULE_math_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            math_dic = {}
            self.state = 217
            localctx.m1 = self.match(DatalogParser.TOKEN_ID)
            math_dic['lhs'] = (None if localctx.m1 is None else localctx.m1.text)
            self.state = 219
            localctx.m2 = self.math_op()
            math_dic['op'] = localctx.m2.r
            self.state = 221
            localctx.m3 = self.match(DatalogParser.TOKEN_ID)
            math_dic['rhs'] = (None if localctx.m3 is None else localctx.m3.text)
            localctx.r = math_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Compare_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.c1 = None # Token
            self.c2 = None # Token
            self.op = None # Compare_opContext
            self.c4 = None # Token
            self.c5 = None # Token

        def compare_op(self):
            return self.getTypedRuleContext(DatalogParser.Compare_opContext,0)


        def TOKEN_ID(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ID)
            else:
                return self.getToken(DatalogParser.TOKEN_ID, i)

        def TOKEN_INTEGER(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_INTEGER)
            else:
                return self.getToken(DatalogParser.TOKEN_INTEGER, i)

        def getRuleIndex(self):
            return DatalogParser.RULE_compare_expr




    def compare_expr(self):

        localctx = DatalogParser.Compare_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 24, self.RULE_compare_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            compare_dic = {}
            self.state = 230
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_ID]:
                self.state = 226
                localctx.c1 = self.match(DatalogParser.TOKEN_ID)
                compare_dic['lhs'] = [(None if localctx.c1 is None else localctx.c1.text), 'var']
                pass
            elif token in [DatalogParser.TOKEN_INTEGER]:
                self.state = 228
                localctx.c2 = self.match(DatalogParser.TOKEN_INTEGER)
                compare_dic['lhs'] = [(None if localctx.c2 is None else localctx.c2.text), 'num']
                pass
            else:
                raise NoViableAltException(self)

            self.state = 232
            localctx.op = self.compare_op()
            compare_dic['op'] = localctx.op.r
            self.state = 238
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_ID]:
                self.state = 234
                localctx.c4 = self.match(DatalogParser.TOKEN_ID)
                compare_dic['rhs'] = [(None if localctx.c4 is None else localctx.c4.text), 'var']
                pass
            elif token in [DatalogParser.TOKEN_INTEGER]:
                self.state = 236
                localctx.c5 = self.match(DatalogParser.TOKEN_INTEGER)
                compare_dic['rhs'] = [(None if localctx.c5 is None else localctx.c5.text), 'num']
                pass
            else:
                raise NoViableAltException(self)

            localctx.r = compare_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Aggregation_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Aggregation_opContext
            self.a2 = None # Token
            self.a3 = None # Math_exprContext

        def TOKEN_LEFT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_PAREN, 0)

        def TOKEN_RIGHT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_PAREN, 0)

        def aggregation_op(self):
            return self.getTypedRuleContext(DatalogParser.Aggregation_opContext,0)


        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def math_expr(self):
            return self.getTypedRuleContext(DatalogParser.Math_exprContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_aggregation_expr




    def aggregation_expr(self):

        localctx = DatalogParser.Aggregation_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 26, self.RULE_aggregation_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            agg_dic = {'agg_op': None, 'agg_arg': None}
            self.state = 243
            localctx.a1 = self.aggregation_op()
            agg_dic['agg_op'] = localctx.a1.r
            self.state = 245
            self.match(DatalogParser.TOKEN_LEFT_PAREN)
            self.state = 251
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,13,self._ctx)
            if la_ == 1:
                self.state = 246
                localctx.a2 = self.match(DatalogParser.TOKEN_ID)
                agg_dic['agg_arg'] = {'type': 'attribute', 'content': (None if localctx.a2 is None else localctx.a2.text)}
                pass

            elif la_ == 2:
                self.state = 248
                localctx.a3 = self.math_expr()
                agg_dic['agg_arg'] = {'type': 'math_expr', 'content': localctx.a3.r}
                pass


            self.state = 253
            self.match(DatalogParser.TOKEN_RIGHT_PAREN)
            localctx.r = agg_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Compare_opContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.op1 = None # Token
            self.op2 = None # Token
            self.op3 = None # Token
            self.op4 = None # Token
            self.op5 = None # Token
            self.op6 = None # Token

        def TOKEN_NOT_EQUALS(self):
            return self.getToken(DatalogParser.TOKEN_NOT_EQUALS, 0)

        def TOKEN_EQUALS(self):
            return self.getToken(DatalogParser.TOKEN_EQUALS, 0)

        def TOKEN_GREATER_THAN(self):
            return self.getToken(DatalogParser.TOKEN_GREATER_THAN, 0)

        def TOKEN_GREATER_EQUAL_THAN(self):
            return self.getToken(DatalogParser.TOKEN_GREATER_EQUAL_THAN, 0)

        def TOKEN_LESS_THAN(self):
            return self.getToken(DatalogParser.TOKEN_LESS_THAN, 0)

        def TOKEN_LESS_EQUAL_THAN(self):
            return self.getToken(DatalogParser.TOKEN_LESS_EQUAL_THAN, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_compare_op




    def compare_op(self):

        localctx = DatalogParser.Compare_opContext(self, self._ctx, self.state)
        self.enterRule(localctx, 28, self.RULE_compare_op)
        try:
            self.state = 268
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_NOT_EQUALS]:
                self.enterOuterAlt(localctx, 1)
                self.state = 256
                localctx.op1 = self.match(DatalogParser.TOKEN_NOT_EQUALS)
                localctx.r = (None if localctx.op1 is None else localctx.op1.text)
                pass
            elif token in [DatalogParser.TOKEN_EQUALS]:
                self.enterOuterAlt(localctx, 2)
                self.state = 258
                localctx.op2 = self.match(DatalogParser.TOKEN_EQUALS)
                localctx.r = (None if localctx.op2 is None else localctx.op2.text)
                pass
            elif token in [DatalogParser.TOKEN_GREATER_THAN]:
                self.enterOuterAlt(localctx, 3)
                self.state = 260
                localctx.op3 = self.match(DatalogParser.TOKEN_GREATER_THAN)
                localctx.r = (None if localctx.op3 is None else localctx.op3.text)
                pass
            elif token in [DatalogParser.TOKEN_GREATER_EQUAL_THAN]:
                self.enterOuterAlt(localctx, 4)
                self.state = 262
                localctx.op4 = self.match(DatalogParser.TOKEN_GREATER_EQUAL_THAN)
                localctx.r = (None if localctx.op4 is None else localctx.op4.text)
                pass
            elif token in [DatalogParser.TOKEN_LESS_THAN]:
                self.enterOuterAlt(localctx, 5)
                self.state = 264
                localctx.op5 = self.match(DatalogParser.TOKEN_LESS_THAN)
                localctx.r = (None if localctx.op5 is None else localctx.op5.text)
                pass
            elif token in [DatalogParser.TOKEN_LESS_EQUAL_THAN]:
                self.enterOuterAlt(localctx, 6)
                self.state = 266
                localctx.op6 = self.match(DatalogParser.TOKEN_LESS_EQUAL_THAN)
                localctx.r = (None if localctx.op6 is None else localctx.op6.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Aggregation_opContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.op1 = None # Token
            self.op2 = None # Token
            self.op3 = None # Token
            self.op4 = None # Token
            self.op5 = None # Token

        def TOKEN_MIN(self):
            return self.getToken(DatalogParser.TOKEN_MIN, 0)

        def TOKEN_MAX(self):
            return self.getToken(DatalogParser.TOKEN_MAX, 0)

        def TOKEN_SUM(self):
            return self.getToken(DatalogParser.TOKEN_SUM, 0)

        def TOKEN_COUNT(self):
            return self.getToken(DatalogParser.TOKEN_COUNT, 0)

        def TOKEN_COUNT_DISTINCT(self):
            return self.getToken(DatalogParser.TOKEN_COUNT_DISTINCT, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_aggregation_op




    def aggregation_op(self):

        localctx = DatalogParser.Aggregation_opContext(self, self._ctx, self.state)
        self.enterRule(localctx, 30, self.RULE_aggregation_op)
        try:
            self.state = 280
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_MIN]:
                self.enterOuterAlt(localctx, 1)
                self.state = 270
                localctx.op1 = self.match(DatalogParser.TOKEN_MIN)
                localctx.r = (None if localctx.op1 is None else localctx.op1.text)
                pass
            elif token in [DatalogParser.TOKEN_MAX]:
                self.enterOuterAlt(localctx, 2)
                self.state = 272
                localctx.op2 = self.match(DatalogParser.TOKEN_MAX)
                localctx.r = (None if localctx.op2 is None else localctx.op2.text)
                pass
            elif token in [DatalogParser.TOKEN_SUM]:
                self.enterOuterAlt(localctx, 3)
                self.state = 274
                localctx.op3 = self.match(DatalogParser.TOKEN_SUM)
                localctx.r = (None if localctx.op3 is None else localctx.op3.text)
                pass
            elif token in [DatalogParser.TOKEN_COUNT]:
                self.enterOuterAlt(localctx, 4)
                self.state = 276
                localctx.op4 = self.match(DatalogParser.TOKEN_COUNT)
                localctx.r = (None if localctx.op4 is None else localctx.op4.text)
                pass
            elif token in [DatalogParser.TOKEN_COUNT_DISTINCT]:
                self.enterOuterAlt(localctx, 5)
                self.state = 278
                localctx.op5 = self.match(DatalogParser.TOKEN_COUNT_DISTINCT)
                localctx.r = (None if localctx.op5 is None else localctx.op5.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Math_opContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.op1 = None # Token
            self.op2 = None # Token
            self.op3 = None # Token
            self.op4 = None # Token

        def TOKEN_PLUS(self):
            return self.getToken(DatalogParser.TOKEN_PLUS, 0)

        def TOKEN_MINUS(self):
            return self.getToken(DatalogParser.TOKEN_MINUS, 0)

        def TOKEN_MULT(self):
            return self.getToken(DatalogParser.TOKEN_MULT, 0)

        def TOKEN_DIV(self):
            return self.getToken(DatalogParser.TOKEN_DIV, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_math_op




    def math_op(self):

        localctx = DatalogParser.Math_opContext(self, self._ctx, self.state)
        self.enterRule(localctx, 32, self.RULE_math_op)
        try:
            self.state = 290
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_PLUS]:
                self.enterOuterAlt(localctx, 1)
                self.state = 282
                localctx.op1 = self.match(DatalogParser.TOKEN_PLUS)
                localctx.r = (None if localctx.op1 is None else localctx.op1.text)
                pass
            elif token in [DatalogParser.TOKEN_MINUS]:
                self.enterOuterAlt(localctx, 2)
                self.state = 284
                localctx.op2 = self.match(DatalogParser.TOKEN_MINUS)
                localctx.r = (None if localctx.op2 is None else localctx.op2.text)
                pass
            elif token in [DatalogParser.TOKEN_MULT]:
                self.enterOuterAlt(localctx, 3)
                self.state = 286
                localctx.op3 = self.match(DatalogParser.TOKEN_MULT)
                localctx.r = (None if localctx.op3 is None else localctx.op3.text)
                pass
            elif token in [DatalogParser.TOKEN_DIV]:
                self.enterOuterAlt(localctx, 4)
                self.state = 288
                localctx.op4 = self.match(DatalogParser.TOKEN_DIV)
                localctx.r = (None if localctx.op4 is None else localctx.op4.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ConstantContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.c1 = None # Token
            self.c2 = None # Token

        def TOKEN_INTEGER(self):
            return self.getToken(DatalogParser.TOKEN_INTEGER, 0)

        def TOKEN_STRING(self):
            return self.getToken(DatalogParser.TOKEN_STRING, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_constant




    def constant(self):

        localctx = DatalogParser.ConstantContext(self, self._ctx, self.state)
        self.enterRule(localctx, 34, self.RULE_constant)
        try:
            self.state = 296
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_INTEGER]:
                self.enterOuterAlt(localctx, 1)
                self.state = 292
                localctx.c1 = self.match(DatalogParser.TOKEN_INTEGER)
                localctx.r = (None if localctx.c1 is None else localctx.c1.text)
                pass
            elif token in [DatalogParser.TOKEN_STRING]:
                self.enterOuterAlt(localctx, 2)
                self.state = 294
                localctx.c2 = self.match(DatalogParser.TOKEN_STRING)
                localctx.r = (None if localctx.c2 is None else localctx.c2.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Data_typeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.dt1 = None # Token
            self.dt2 = None # Token
            self.dt3 = None # Token
            self.dt4 = None # Token
            self.dt5 = None # Token
            self.dt6 = None # Token
            self.dt7 = None # Token
            self.dt8 = None # Token

        def TOKEN_INT(self):
            return self.getToken(DatalogParser.TOKEN_INT, 0)

        def TOKEN_LONG(self):
            return self.getToken(DatalogParser.TOKEN_LONG, 0)

        def TOKEN_FLOAT(self):
            return self.getToken(DatalogParser.TOKEN_FLOAT, 0)

        def TOKEN_DOUBLE(self):
            return self.getToken(DatalogParser.TOKEN_DOUBLE, 0)

        def TOKEN_VARCHAR(self):
            return self.getToken(DatalogParser.TOKEN_VARCHAR, 0)

        def TOKEN_CHAR(self):
            return self.getToken(DatalogParser.TOKEN_CHAR, 0)

        def TOKEN_DATE(self):
            return self.getToken(DatalogParser.TOKEN_DATE, 0)

        def TOKEN_DATETIME(self):
            return self.getToken(DatalogParser.TOKEN_DATETIME, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_data_type




    def data_type(self):

        localctx = DatalogParser.Data_typeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 36, self.RULE_data_type)
        try:
            self.state = 314
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_INT]:
                self.enterOuterAlt(localctx, 1)
                self.state = 298
                localctx.dt1 = self.match(DatalogParser.TOKEN_INT)
                localctx.r = (None if localctx.dt1 is None else localctx.dt1.text)
                pass
            elif token in [DatalogParser.TOKEN_LONG]:
                self.enterOuterAlt(localctx, 2)
                self.state = 300
                localctx.dt2 = self.match(DatalogParser.TOKEN_LONG)
                localctx.r = (None if localctx.dt2 is None else localctx.dt2.text)
                pass
            elif token in [DatalogParser.TOKEN_FLOAT]:
                self.enterOuterAlt(localctx, 3)
                self.state = 302
                localctx.dt3 = self.match(DatalogParser.TOKEN_FLOAT)
                localctx.r = (None if localctx.dt3 is None else localctx.dt3.text)
                pass
            elif token in [DatalogParser.TOKEN_DOUBLE]:
                self.enterOuterAlt(localctx, 4)
                self.state = 304
                localctx.dt4 = self.match(DatalogParser.TOKEN_DOUBLE)
                localctx.r = (None if localctx.dt4 is None else localctx.dt4.text)
                pass
            elif token in [DatalogParser.TOKEN_VARCHAR]:
                self.enterOuterAlt(localctx, 5)
                self.state = 306
                localctx.dt5 = self.match(DatalogParser.TOKEN_VARCHAR)
                localctx.r = (None if localctx.dt5 is None else localctx.dt5.text)
                pass
            elif token in [DatalogParser.TOKEN_CHAR]:
                self.enterOuterAlt(localctx, 6)
                self.state = 308
                localctx.dt6 = self.match(DatalogParser.TOKEN_CHAR)
                localctx.r = (None if localctx.dt6 is None else localctx.dt6.text)
                pass
            elif token in [DatalogParser.TOKEN_DATE]:
                self.enterOuterAlt(localctx, 7)
                self.state = 310
                localctx.dt7 = self.match(DatalogParser.TOKEN_DATE)
                localctx.r = (None if localctx.dt7 is None else localctx.dt7.text)
                pass
            elif token in [DatalogParser.TOKEN_DATETIME]:
                self.enterOuterAlt(localctx, 8)
                self.state = 312
                localctx.dt8 = self.match(DatalogParser.TOKEN_DATETIME)
                localctx.r = (None if localctx.dt8 is None else localctx.dt8.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx





