# Generated from Datalog.g4 by ANTLR 4.8
# encoding: utf-8
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
	from typing import TextIO
else:
	from typing.io import TextIO




def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3\60")
        buf.write("\u0179\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7")
        buf.write("\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r\4\16")
        buf.write("\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23\t\23")
        buf.write("\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30\3\2")
        buf.write("\3\2\3\2\3\2\3\2\3\2\3\2\3\2\7\29\n\2\f\2\16\2<\13\2\3")
        buf.write("\2\3\2\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\7\3H\n\3\f\3\16")
        buf.write("\3K\13\3\3\3\3\3\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3")
        buf.write("\4\7\4Y\n\4\f\4\16\4\\\13\4\3\4\3\4\3\4\3\5\3\5\3\5\3")
        buf.write("\5\3\5\3\5\3\6\3\6\3\6\3\6\3\6\3\6\7\6m\n\6\f\6\16\6p")
        buf.write("\13\6\3\6\3\6\3\7\3\7\3\7\5\7w\n\7\3\7\3\7\5\7{\n\7\3")
        buf.write("\7\3\7\5\7\177\n\7\3\7\3\7\3\7\3\7\3\7\3\7\3\7\5\7\u0088")
        buf.write("\n\7\3\7\3\7\3\7\3\b\3\b\3\b\3\t\3\t\3\t\3\t\3\t\3\t\3")
        buf.write("\t\3\t\3\t\3\t\3\t\3\t\3\t\5\t\u009d\n\t\3\t\3\t\7\t\u00a1")
        buf.write("\n\t\f\t\16\t\u00a4\13\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3")
        buf.write("\t\3\t\3\t\3\t\3\t\5\t\u00b2\n\t\3\t\3\t\3\n\3\n\3\n\3")
        buf.write("\n\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3")
        buf.write("\13\3\13\3\13\3\13\3\13\3\13\3\13\5\13\u00cb\n\13\3\13")
        buf.write("\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13")
        buf.write("\3\13\3\13\5\13\u00db\n\13\7\13\u00dd\n\13\f\13\16\13")
        buf.write("\u00e0\13\13\3\13\3\13\3\13\3\f\3\f\3\f\3\f\3\f\3\f\3")
        buf.write("\f\3\f\3\r\3\r\3\r\3\r\3\r\3\r\5\r\u00f3\n\r\3\r\3\r\3")
        buf.write("\r\3\r\3\r\3\r\3\r\5\r\u00fc\n\r\3\r\3\r\3\16\3\16\3\16")
        buf.write("\3\16\3\16\3\16\3\16\3\16\3\16\5\16\u0109\n\16\3\16\3")
        buf.write("\16\3\16\3\17\3\17\3\17\3\17\3\17\3\17\5\17\u0114\n\17")
        buf.write("\3\17\3\17\3\17\3\17\3\17\3\17\3\17\5\17\u011d\n\17\3")
        buf.write("\17\3\17\3\20\3\20\3\20\3\20\3\20\3\20\5\20\u0127\n\20")
        buf.write("\3\21\3\21\3\21\3\21\3\21\3\21\3\21\3\21\3\21\3\22\3\22")
        buf.write("\3\22\3\22\3\22\3\22\3\22\3\23\3\23\3\23\3\23\3\23\3\23")
        buf.write("\3\23\3\23\3\23\3\23\3\23\3\23\5\23\u0145\n\23\3\24\3")
        buf.write("\24\3\24\3\24\3\24\3\24\3\24\3\24\3\24\3\24\5\24\u0151")
        buf.write("\n\24\3\25\3\25\3\25\3\25\3\25\3\25\3\25\3\25\5\25\u015b")
        buf.write("\n\25\3\26\3\26\3\26\3\26\3\26\5\26\u0162\n\26\3\27\3")
        buf.write("\27\3\27\3\30\3\30\3\30\3\30\3\30\3\30\3\30\3\30\3\30")
        buf.write("\3\30\3\30\3\30\3\30\3\30\3\30\3\30\5\30\u0177\n\30\3")
        buf.write("\30\2\2\31\2\4\6\b\n\f\16\20\22\24\26\30\32\34\36 \"$")
        buf.write("&(*,.\2\2\2\u0193\2\60\3\2\2\2\4?\3\2\2\2\6N\3\2\2\2\b")
        buf.write("`\3\2\2\2\nf\3\2\2\2\fs\3\2\2\2\16\u008c\3\2\2\2\20\u008f")
        buf.write("\3\2\2\2\22\u00b5\3\2\2\2\24\u00b9\3\2\2\2\26\u00e4\3")
        buf.write("\2\2\2\30\u00ec\3\2\2\2\32\u00ff\3\2\2\2\34\u010d\3\2")
        buf.write("\2\2\36\u0126\3\2\2\2 \u0128\3\2\2\2\"\u0131\3\2\2\2$")
        buf.write("\u0144\3\2\2\2&\u0150\3\2\2\2(\u015a\3\2\2\2*\u0161\3")
        buf.write("\2\2\2,\u0163\3\2\2\2.\u0176\3\2\2\2\60\61\b\2\1\2\61")
        buf.write("\62\7\3\2\2\62\63\7\32\2\2\63\64\5\6\4\2\64:\b\2\1\2\65")
        buf.write("\66\5\6\4\2\66\67\b\2\1\2\679\3\2\2\28\65\3\2\2\29<\3")
        buf.write("\2\2\2:8\3\2\2\2:;\3\2\2\2;=\3\2\2\2<:\3\2\2\2=>\b\2\1")
        buf.write("\2>\3\3\2\2\2?@\b\3\1\2@A\7\4\2\2AB\7\32\2\2BC\5\6\4\2")
        buf.write("CI\b\3\1\2DE\5\6\4\2EF\b\3\1\2FH\3\2\2\2GD\3\2\2\2HK\3")
        buf.write("\2\2\2IG\3\2\2\2IJ\3\2\2\2JL\3\2\2\2KI\3\2\2\2LM\b\3\1")
        buf.write("\2M\5\3\2\2\2NO\b\4\1\2OP\7\25\2\2PQ\b\4\1\2QR\7+\2\2")
        buf.write("RS\5\36\20\2SZ\b\4\1\2TU\7\30\2\2UV\5\36\20\2VW\b\4\1")
        buf.write("\2WY\3\2\2\2XT\3\2\2\2Y\\\3\2\2\2ZX\3\2\2\2Z[\3\2\2\2")
        buf.write("[]\3\2\2\2\\Z\3\2\2\2]^\7,\2\2^_\b\4\1\2_\7\3\2\2\2`a")
        buf.write("\7\5\2\2ab\7\32\2\2bc\5\n\6\2cd\b\5\1\2de\7\2\2\3e\t\3")
        buf.write("\2\2\2fg\b\6\1\2gh\5\f\7\2hn\b\6\1\2ij\5\f\7\2jk\b\6\1")
        buf.write("\2km\3\2\2\2li\3\2\2\2mp\3\2\2\2nl\3\2\2\2no\3\2\2\2o")
        buf.write("q\3\2\2\2pn\3\2\2\2qr\b\6\1\2r\13\3\2\2\2sv\b\7\1\2tu")
        buf.write("\7\"\2\2uw\b\7\1\2vt\3\2\2\2vw\3\2\2\2wz\3\2\2\2xy\7#")
        buf.write("\2\2y{\b\7\1\2zx\3\2\2\2z{\3\2\2\2{~\3\2\2\2|}\7$\2\2")
        buf.write("}\177\b\7\1\2~|\3\2\2\2~\177\3\2\2\2\177\u0080\3\2\2\2")
        buf.write("\u0080\u0081\5\16\b\2\u0081\u0082\b\7\1\2\u0082\u0083")
        buf.write("\7\26\2\2\u0083\u0087\b\7\1\2\u0084\u0085\5\20\t\2\u0085")
        buf.write("\u0086\b\7\1\2\u0086\u0088\3\2\2\2\u0087\u0084\3\2\2\2")
        buf.write("\u0087\u0088\3\2\2\2\u0088\u0089\3\2\2\2\u0089\u008a\7")
        buf.write("\33\2\2\u008a\u008b\b\7\1\2\u008b\r\3\2\2\2\u008c\u008d")
        buf.write("\5\24\13\2\u008d\u008e\b\b\1\2\u008e\17\3\2\2\2\u008f")
        buf.write("\u00a2\b\t\1\2\u0090\u0091\5\24\13\2\u0091\u0092\b\t\1")
        buf.write("\2\u0092\u009d\3\2\2\2\u0093\u0094\5\30\r\2\u0094\u0095")
        buf.write("\b\t\1\2\u0095\u009d\3\2\2\2\u0096\u0097\5\26\f\2\u0097")
        buf.write("\u0098\b\t\1\2\u0098\u009d\3\2\2\2\u0099\u009a\5\22\n")
        buf.write("\2\u009a\u009b\b\t\1\2\u009b\u009d\3\2\2\2\u009c\u0090")
        buf.write("\3\2\2\2\u009c\u0093\3\2\2\2\u009c\u0096\3\2\2\2\u009c")
        buf.write("\u0099\3\2\2\2\u009d\u009e\3\2\2\2\u009e\u009f\7\30\2")
        buf.write("\2\u009f\u00a1\3\2\2\2\u00a0\u009c\3\2\2\2\u00a1\u00a4")
        buf.write("\3\2\2\2\u00a2\u00a0\3\2\2\2\u00a2\u00a3\3\2\2\2\u00a3")
        buf.write("\u00b1\3\2\2\2\u00a4\u00a2\3\2\2\2\u00a5\u00a6\5\24\13")
        buf.write("\2\u00a6\u00a7\b\t\1\2\u00a7\u00b2\3\2\2\2\u00a8\u00a9")
        buf.write("\5\30\r\2\u00a9\u00aa\b\t\1\2\u00aa\u00b2\3\2\2\2\u00ab")
        buf.write("\u00ac\5\26\f\2\u00ac\u00ad\b\t\1\2\u00ad\u00b2\3\2\2")
        buf.write("\2\u00ae\u00af\5\22\n\2\u00af\u00b0\b\t\1\2\u00b0\u00b2")
        buf.write("\3\2\2\2\u00b1\u00a5\3\2\2\2\u00b1\u00a8\3\2\2\2\u00b1")
        buf.write("\u00ab\3\2\2\2\u00b1\u00ae\3\2\2\2\u00b2\u00b3\3\2\2\2")
        buf.write("\u00b3\u00b4\b\t\1\2\u00b4\21\3\2\2\2\u00b5\u00b6\7!\2")
        buf.write("\2\u00b6\u00b7\5\24\13\2\u00b7\u00b8\b\n\1\2\u00b8\23")
        buf.write("\3\2\2\2\u00b9\u00ba\b\13\1\2\u00ba\u00bb\7\25\2\2\u00bb")
        buf.write("\u00bc\b\13\1\2\u00bc\u00ca\7+\2\2\u00bd\u00be\7\25\2")
        buf.write("\2\u00be\u00cb\b\13\1\2\u00bf\u00c0\5\32\16\2\u00c0\u00c1")
        buf.write("\b\13\1\2\u00c1\u00cb\3\2\2\2\u00c2\u00c3\7\27\2\2\u00c3")
        buf.write("\u00cb\b\13\1\2\u00c4\u00c5\5*\26\2\u00c5\u00c6\b\13\1")
        buf.write("\2\u00c6\u00cb\3\2\2\2\u00c7\u00c8\5\34\17\2\u00c8\u00c9")
        buf.write("\b\13\1\2\u00c9\u00cb\3\2\2\2\u00ca\u00bd\3\2\2\2\u00ca")
        buf.write("\u00bf\3\2\2\2\u00ca\u00c2\3\2\2\2\u00ca\u00c4\3\2\2\2")
        buf.write("\u00ca\u00c7\3\2\2\2\u00cb\u00de\3\2\2\2\u00cc\u00da\7")
        buf.write("\30\2\2\u00cd\u00ce\7\25\2\2\u00ce\u00db\b\13\1\2\u00cf")
        buf.write("\u00d0\5\32\16\2\u00d0\u00d1\b\13\1\2\u00d1\u00db\3\2")
        buf.write("\2\2\u00d2\u00d3\7\27\2\2\u00d3\u00db\b\13\1\2\u00d4\u00d5")
        buf.write("\5*\26\2\u00d5\u00d6\b\13\1\2\u00d6\u00db\3\2\2\2\u00d7")
        buf.write("\u00d8\5\34\17\2\u00d8\u00d9\b\13\1\2\u00d9\u00db\3\2")
        buf.write("\2\2\u00da\u00cd\3\2\2\2\u00da\u00cf\3\2\2\2\u00da\u00d2")
        buf.write("\3\2\2\2\u00da\u00d4\3\2\2\2\u00da\u00d7\3\2\2\2\u00db")
        buf.write("\u00dd\3\2\2\2\u00dc\u00cc\3\2\2\2\u00dd\u00e0\3\2\2\2")
        buf.write("\u00de\u00dc\3\2\2\2\u00de\u00df\3\2\2\2\u00df\u00e1\3")
        buf.write("\2\2\2\u00e0\u00de\3\2\2\2\u00e1\u00e2\7,\2\2\u00e2\u00e3")
        buf.write("\b\13\1\2\u00e3\25\3\2\2\2\u00e4\u00e5\b\f\1\2\u00e5\u00e6")
        buf.write("\7\25\2\2\u00e6\u00e7\b\f\1\2\u00e7\u00e8\7\34\2\2\u00e8")
        buf.write("\u00e9\5\34\17\2\u00e9\u00ea\b\f\1\2\u00ea\u00eb\b\f\1")
        buf.write("\2\u00eb\27\3\2\2\2\u00ec\u00f2\b\r\1\2\u00ed\u00ee\7")
        buf.write("\25\2\2\u00ee\u00f3\b\r\1\2\u00ef\u00f0\5,\27\2\u00f0")
        buf.write("\u00f1\b\r\1\2\u00f1\u00f3\3\2\2\2\u00f2\u00ed\3\2\2\2")
        buf.write("\u00f2\u00ef\3\2\2\2\u00f3\u00f4\3\2\2\2\u00f4\u00f5\5")
        buf.write("$\23\2\u00f5\u00fb\b\r\1\2\u00f6\u00f7\7\25\2\2\u00f7")
        buf.write("\u00fc\b\r\1\2\u00f8\u00f9\5,\27\2\u00f9\u00fa\b\r\1\2")
        buf.write("\u00fa\u00fc\3\2\2\2\u00fb\u00f6\3\2\2\2\u00fb\u00f8\3")
        buf.write("\2\2\2\u00fc\u00fd\3\2\2\2\u00fd\u00fe\b\r\1\2\u00fe\31")
        buf.write("\3\2\2\2\u00ff\u0100\b\16\1\2\u0100\u0101\5&\24\2\u0101")
        buf.write("\u0102\b\16\1\2\u0102\u0108\7+\2\2\u0103\u0104\7\25\2")
        buf.write("\2\u0104\u0109\b\16\1\2\u0105\u0106\5\34\17\2\u0106\u0107")
        buf.write("\b\16\1\2\u0107\u0109\3\2\2\2\u0108\u0103\3\2\2\2\u0108")
        buf.write("\u0105\3\2\2\2\u0109\u010a\3\2\2\2\u010a\u010b\7,\2\2")
        buf.write("\u010b\u010c\b\16\1\2\u010c\33\3\2\2\2\u010d\u0113\b\17")
        buf.write("\1\2\u010e\u010f\7\25\2\2\u010f\u0114\b\17\1\2\u0110\u0111")
        buf.write("\5,\27\2\u0111\u0112\b\17\1\2\u0112\u0114\3\2\2\2\u0113")
        buf.write("\u010e\3\2\2\2\u0113\u0110\3\2\2\2\u0114\u0115\3\2\2\2")
        buf.write("\u0115\u0116\5(\25\2\u0116\u011c\b\17\1\2\u0117\u0118")
        buf.write("\7\25\2\2\u0118\u011d\b\17\1\2\u0119\u011a\5,\27\2\u011a")
        buf.write("\u011b\b\17\1\2\u011b\u011d\3\2\2\2\u011c\u0117\3\2\2")
        buf.write("\2\u011c\u0119\3\2\2\2\u011d\u011e\3\2\2\2\u011e\u011f")
        buf.write("\b\17\1\2\u011f\35\3\2\2\2\u0120\u0121\5\"\22\2\u0121")
        buf.write("\u0122\b\20\1\2\u0122\u0127\3\2\2\2\u0123\u0124\5 \21")
        buf.write("\2\u0124\u0125\b\20\1\2\u0125\u0127\3\2\2\2\u0126\u0120")
        buf.write("\3\2\2\2\u0126\u0123\3\2\2\2\u0127\37\3\2\2\2\u0128\u0129")
        buf.write("\b\21\1\2\u0129\u012a\7-\2\2\u012a\u012b\7\25\2\2\u012b")
        buf.write("\u012c\b\21\1\2\u012c\u012d\7.\2\2\u012d\u012e\5.\30\2")
        buf.write("\u012e\u012f\b\21\1\2\u012f\u0130\b\21\1\2\u0130!\3\2")
        buf.write("\2\2\u0131\u0132\b\22\1\2\u0132\u0133\7\25\2\2\u0133\u0134")
        buf.write("\b\22\1\2\u0134\u0135\5.\30\2\u0135\u0136\b\22\1\2\u0136")
        buf.write("\u0137\b\22\1\2\u0137#\3\2\2\2\u0138\u0139\7%\2\2\u0139")
        buf.write("\u0145\b\23\1\2\u013a\u013b\7&\2\2\u013b\u0145\b\23\1")
        buf.write("\2\u013c\u013d\7(\2\2\u013d\u0145\b\23\1\2\u013e\u013f")
        buf.write("\7\'\2\2\u013f\u0145\b\23\1\2\u0140\u0141\7*\2\2\u0141")
        buf.write("\u0145\b\23\1\2\u0142\u0143\7)\2\2\u0143\u0145\b\23\1")
        buf.write("\2\u0144\u0138\3\2\2\2\u0144\u013a\3\2\2\2\u0144\u013c")
        buf.write("\3\2\2\2\u0144\u013e\3\2\2\2\u0144\u0140\3\2\2\2\u0144")
        buf.write("\u0142\3\2\2\2\u0145%\3\2\2\2\u0146\u0147\7\20\2\2\u0147")
        buf.write("\u0151\b\24\1\2\u0148\u0149\7\21\2\2\u0149\u0151\b\24")
        buf.write("\1\2\u014a\u014b\7\22\2\2\u014b\u0151\b\24\1\2\u014c\u014d")
        buf.write("\7\23\2\2\u014d\u0151\b\24\1\2\u014e\u014f\7\24\2\2\u014f")
        buf.write("\u0151\b\24\1\2\u0150\u0146\3\2\2\2\u0150\u0148\3\2\2")
        buf.write("\2\u0150\u014a\3\2\2\2\u0150\u014c\3\2\2\2\u0150\u014e")
        buf.write("\3\2\2\2\u0151\'\3\2\2\2\u0152\u0153\7\35\2\2\u0153\u015b")
        buf.write("\b\25\1\2\u0154\u0155\7\36\2\2\u0155\u015b\b\25\1\2\u0156")
        buf.write("\u0157\7\37\2\2\u0157\u015b\b\25\1\2\u0158\u0159\7 \2")
        buf.write("\2\u0159\u015b\b\25\1\2\u015a\u0152\3\2\2\2\u015a\u0154")
        buf.write("\3\2\2\2\u015a\u0156\3\2\2\2\u015a\u0158\3\2\2\2\u015b")
        buf.write(")\3\2\2\2\u015c\u015d\5,\27\2\u015d\u015e\b\26\1\2\u015e")
        buf.write("\u0162\3\2\2\2\u015f\u0160\7\7\2\2\u0160\u0162\b\26\1")
        buf.write("\2\u0161\u015c\3\2\2\2\u0161\u015f\3\2\2\2\u0162+\3\2")
        buf.write("\2\2\u0163\u0164\7\6\2\2\u0164\u0165\b\27\1\2\u0165-\3")
        buf.write("\2\2\2\u0166\u0167\7\b\2\2\u0167\u0177\b\30\1\2\u0168")
        buf.write("\u0169\7\t\2\2\u0169\u0177\b\30\1\2\u016a\u016b\7\n\2")
        buf.write("\2\u016b\u0177\b\30\1\2\u016c\u016d\7\13\2\2\u016d\u0177")
        buf.write("\b\30\1\2\u016e\u016f\7\f\2\2\u016f\u0177\b\30\1\2\u0170")
        buf.write("\u0171\7\r\2\2\u0171\u0177\b\30\1\2\u0172\u0173\7\16\2")
        buf.write("\2\u0173\u0177\b\30\1\2\u0174\u0175\7\17\2\2\u0175\u0177")
        buf.write("\b\30\1\2\u0176\u0166\3\2\2\2\u0176\u0168\3\2\2\2\u0176")
        buf.write("\u016a\3\2\2\2\u0176\u016c\3\2\2\2\u0176\u016e\3\2\2\2")
        buf.write("\u0176\u0170\3\2\2\2\u0176\u0172\3\2\2\2\u0176\u0174\3")
        buf.write("\2\2\2\u0177/\3\2\2\2\33:IZnvz~\u0087\u009c\u00a2\u00b1")
        buf.write("\u00ca\u00da\u00de\u00f2\u00fb\u0108\u0113\u011c\u0126")
        buf.write("\u0144\u0150\u015a\u0161\u0176")
        return buf.getvalue()


class DatalogParser ( Parser ):

    grammarFileName = "Datalog.g4"

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    sharedContextCache = PredictionContextCache()

    literalNames = [ "<INVALID>", "'EDB_DECL'", "'IDB_DECL'", "'RULE_DECL'", 
                     "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "<INVALID>", "'MIN'", "'MAX'", "'SUM'", 
                     "'COUNT'", "'COUNT_DISTINCT'", "<INVALID>", "':-'", 
                     "'_'", "','", "';'", "':'", "'.'", "'='", "'+'", "'-'", 
                     "'*'", "'/'", "'!'", "'[!dedup]'", "'[!set-diff]'", 
                     "'[dedup-only]'", "'!='", "'=='", "'>='", "'>'", "'<='", 
                     "'<'", "'('", "')'", "'['", "']'" ]

    symbolicNames = [ "<INVALID>", "TOKEN_EDB", "TOKEN_IDB", "TOKEN_RULE", 
                      "TOKEN_INTEGER", "TOKEN_STRING", "TOKEN_INT", "TOKEN_LONG", 
                      "TOKEN_FLOAT", "TOKEN_DOUBLE", "TOKEN_VARCHAR", "TOKEN_CHAR", 
                      "TOKEN_DATE", "TOKEN_DATETIME", "TOKEN_MIN", "TOKEN_MAX", 
                      "TOKEN_SUM", "TOKEN_COUNT", "TOKEN_COUNT_DISTINCT", 
                      "TOKEN_ID", "TOKEN_BODY_HEAD_SEP", "TOKEN_ANY", "TOKEN_COMMA", 
                      "TOKEN_SEMICOLON", "TOKEN_COLON", "TOKEN_DOT", "TOKEN_ASSIGN", 
                      "TOKEN_PLUS", "TOKEN_MINUS", "TOKEN_MULT", "TOKEN_DIV", 
                      "TOKEN_NOT", "TOKEN_NON_DEDUP", "TOKEN_NON_SET_DIFF", 
                      "TOKEN_DEDUP_ONLY", "TOKEN_NOT_EQUALS", "TOKEN_EQUALS", 
                      "TOKEN_GREATER_EQUAL_THAN", "TOKEN_GREATER_THAN", 
                      "TOKEN_LESS_EQUAL_THAN", "TOKEN_LESS_THAN", "TOKEN_LEFT_PAREN", 
                      "TOKEN_RIGHT_PAREN", "TOKEN_LEFT_BRACKET", "TOKEN_RIGHT_BRACKET", 
                      "TOKEN_WS", "LINE_COMMENT" ]

    RULE_datalog_edb_declare = 0
    RULE_datalog_idb_declare = 1
    RULE_datalog_relation_schema = 2
    RULE_datalog_rule_declare = 3
    RULE_datalog_program = 4
    RULE_datalog_rule = 5
    RULE_head = 6
    RULE_body = 7
    RULE_negation = 8
    RULE_atom = 9
    RULE_assign = 10
    RULE_compare_expr = 11
    RULE_aggregation_expr = 12
    RULE_math_expr = 13
    RULE_attribute = 14
    RULE_key_attribute = 15
    RULE_non_key_attribute = 16
    RULE_compare_op = 17
    RULE_aggregation_op = 18
    RULE_math_op = 19
    RULE_constant = 20
    RULE_number = 21
    RULE_data_type = 22

    ruleNames =  [ "datalog_edb_declare", "datalog_idb_declare", "datalog_relation_schema", 
                   "datalog_rule_declare", "datalog_program", "datalog_rule", 
                   "head", "body", "negation", "atom", "assign", "compare_expr", 
                   "aggregation_expr", "math_expr", "attribute", "key_attribute", 
                   "non_key_attribute", "compare_op", "aggregation_op", 
                   "math_op", "constant", "number", "data_type" ]

    EOF = Token.EOF
    TOKEN_EDB=1
    TOKEN_IDB=2
    TOKEN_RULE=3
    TOKEN_INTEGER=4
    TOKEN_STRING=5
    TOKEN_INT=6
    TOKEN_LONG=7
    TOKEN_FLOAT=8
    TOKEN_DOUBLE=9
    TOKEN_VARCHAR=10
    TOKEN_CHAR=11
    TOKEN_DATE=12
    TOKEN_DATETIME=13
    TOKEN_MIN=14
    TOKEN_MAX=15
    TOKEN_SUM=16
    TOKEN_COUNT=17
    TOKEN_COUNT_DISTINCT=18
    TOKEN_ID=19
    TOKEN_BODY_HEAD_SEP=20
    TOKEN_ANY=21
    TOKEN_COMMA=22
    TOKEN_SEMICOLON=23
    TOKEN_COLON=24
    TOKEN_DOT=25
    TOKEN_ASSIGN=26
    TOKEN_PLUS=27
    TOKEN_MINUS=28
    TOKEN_MULT=29
    TOKEN_DIV=30
    TOKEN_NOT=31
    TOKEN_NON_DEDUP=32
    TOKEN_NON_SET_DIFF=33
    TOKEN_DEDUP_ONLY=34
    TOKEN_NOT_EQUALS=35
    TOKEN_EQUALS=36
    TOKEN_GREATER_EQUAL_THAN=37
    TOKEN_GREATER_THAN=38
    TOKEN_LESS_EQUAL_THAN=39
    TOKEN_LESS_THAN=40
    TOKEN_LEFT_PAREN=41
    TOKEN_RIGHT_PAREN=42
    TOKEN_LEFT_BRACKET=43
    TOKEN_RIGHT_BRACKET=44
    TOKEN_WS=45
    LINE_COMMENT=46

    def __init__(self, input:TokenStream, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.8")
        self._interp = ParserATNSimulator(self, self.atn, self.decisionsToDFA, self.sharedContextCache)
        self._predicates = None




    class AtomArg():
        def __init__(self, arg_name, arg_type, key_attribute=False):
            self.name = arg_name
            self.type = arg_type
            self.key_attribute = key_attribute

        def __str__(self):
    	    return f"{self.name}, {self.type}, {self.key_attribute}"



    class Datalog_edb_declareContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.schema1 = None # Datalog_relation_schemaContext
            self.schema2 = None # Datalog_relation_schemaContext

        def TOKEN_EDB(self):
            return self.getToken(DatalogParser.TOKEN_EDB, 0)

        def TOKEN_COLON(self):
            return self.getToken(DatalogParser.TOKEN_COLON, 0)

        def datalog_relation_schema(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Datalog_relation_schemaContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Datalog_relation_schemaContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_edb_declare




    def datalog_edb_declare(self):

        localctx = DatalogParser.Datalog_edb_declareContext(self, self._ctx, self.state)
        self.enterRule(localctx, 0, self.RULE_datalog_edb_declare)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            edb_list = []
            self.state = 47
            self.match(DatalogParser.TOKEN_EDB)
            self.state = 48
            self.match(DatalogParser.TOKEN_COLON)
            self.state = 49
            localctx.schema1 = self.datalog_relation_schema()
            edb_list.append(localctx.schema1.r)
            self.state = 56
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_ID:
                self.state = 51
                localctx.schema2 = self.datalog_relation_schema()
                edb_list.append(localctx.schema2.r)
                self.state = 58
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            localctx.r = edb_list
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_idb_declareContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.schema1 = None # Datalog_relation_schemaContext
            self.schema2 = None # Datalog_relation_schemaContext

        def TOKEN_IDB(self):
            return self.getToken(DatalogParser.TOKEN_IDB, 0)

        def TOKEN_COLON(self):
            return self.getToken(DatalogParser.TOKEN_COLON, 0)

        def datalog_relation_schema(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Datalog_relation_schemaContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Datalog_relation_schemaContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_idb_declare




    def datalog_idb_declare(self):

        localctx = DatalogParser.Datalog_idb_declareContext(self, self._ctx, self.state)
        self.enterRule(localctx, 2, self.RULE_datalog_idb_declare)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            idb_list = []
            self.state = 62
            self.match(DatalogParser.TOKEN_IDB)
            self.state = 63
            self.match(DatalogParser.TOKEN_COLON)
            self.state = 64
            localctx.schema1 = self.datalog_relation_schema()
            idb_list.append(localctx.schema1.r)
            self.state = 71
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_ID:
                self.state = 66
                localctx.schema2 = self.datalog_relation_schema()
                idb_list.append(localctx.schema2.r)
                self.state = 73
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            localctx.r = idb_list
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_relation_schemaContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.relation_name = None # Token
            self.t1 = None # AttributeContext
            self.t2 = None # AttributeContext

        def TOKEN_LEFT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_PAREN, 0)

        def TOKEN_RIGHT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_PAREN, 0)

        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def attribute(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.AttributeContext)
            else:
                return self.getTypedRuleContext(DatalogParser.AttributeContext,i)


        def TOKEN_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_COMMA)
            else:
                return self.getToken(DatalogParser.TOKEN_COMMA, i)

        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_relation_schema




    def datalog_relation_schema(self):

        localctx = DatalogParser.Datalog_relation_schemaContext(self, self._ctx, self.state)
        self.enterRule(localctx, 4, self.RULE_datalog_relation_schema)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            schema = {'name': '', 'attributes': []}
            self.state = 77
            localctx.relation_name = self.match(DatalogParser.TOKEN_ID)
            schema['name'] = (None if localctx.relation_name is None else localctx.relation_name.text)
            self.state = 79
            self.match(DatalogParser.TOKEN_LEFT_PAREN)
            self.state = 80
            localctx.t1 = self.attribute()
            schema['attributes'].append(self.AtomArg(localctx.t1.r['name'], localctx.t1.r['type'], localctx.t1.r['is_key']))
            self.state = 88
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_COMMA:
                self.state = 82
                self.match(DatalogParser.TOKEN_COMMA)
                self.state = 83
                localctx.t2 = self.attribute()
                schema['attributes'].append(self.AtomArg(localctx.t2.r['name'], localctx.t2.r['type'], localctx.t2.r['is_key']))
                self.state = 90
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 91
            self.match(DatalogParser.TOKEN_RIGHT_PAREN)
            localctx.r = schema
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_rule_declareContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.dp = None # Datalog_programContext

        def TOKEN_RULE(self):
            return self.getToken(DatalogParser.TOKEN_RULE, 0)

        def TOKEN_COLON(self):
            return self.getToken(DatalogParser.TOKEN_COLON, 0)

        def EOF(self):
            return self.getToken(DatalogParser.EOF, 0)

        def datalog_program(self):
            return self.getTypedRuleContext(DatalogParser.Datalog_programContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_rule_declare




    def datalog_rule_declare(self):

        localctx = DatalogParser.Datalog_rule_declareContext(self, self._ctx, self.state)
        self.enterRule(localctx, 6, self.RULE_datalog_rule_declare)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 94
            self.match(DatalogParser.TOKEN_RULE)
            self.state = 95
            self.match(DatalogParser.TOKEN_COLON)
            self.state = 96
            localctx.dp = self.datalog_program()
            localctx.r = localctx.dp.r
            self.state = 98
            self.match(DatalogParser.EOF)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_programContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.r1 = None # Datalog_ruleContext
            self.r2 = None # Datalog_ruleContext

        def datalog_rule(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Datalog_ruleContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Datalog_ruleContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_program




    def datalog_program(self):

        localctx = DatalogParser.Datalog_programContext(self, self._ctx, self.state)
        self.enterRule(localctx, 8, self.RULE_datalog_program)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            rule_list = []
            self.state = 101
            localctx.r1 = self.datalog_rule()
            rule_list.append(localctx.r1.r)
            self.state = 108
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << DatalogParser.TOKEN_ID) | (1 << DatalogParser.TOKEN_NON_DEDUP) | (1 << DatalogParser.TOKEN_NON_SET_DIFF) | (1 << DatalogParser.TOKEN_DEDUP_ONLY))) != 0):
                self.state = 103
                localctx.r2 = self.datalog_rule()
                rule_list.append(localctx.r2.r)
                self.state = 110
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            localctx.r = rule_list
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_ruleContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.h = None # HeadContext
            self.b = None # BodyContext

        def TOKEN_BODY_HEAD_SEP(self):
            return self.getToken(DatalogParser.TOKEN_BODY_HEAD_SEP, 0)

        def TOKEN_DOT(self):
            return self.getToken(DatalogParser.TOKEN_DOT, 0)

        def head(self):
            return self.getTypedRuleContext(DatalogParser.HeadContext,0)


        def TOKEN_NON_DEDUP(self):
            return self.getToken(DatalogParser.TOKEN_NON_DEDUP, 0)

        def TOKEN_NON_SET_DIFF(self):
            return self.getToken(DatalogParser.TOKEN_NON_SET_DIFF, 0)

        def TOKEN_DEDUP_ONLY(self):
            return self.getToken(DatalogParser.TOKEN_DEDUP_ONLY, 0)

        def body(self):
            return self.getTypedRuleContext(DatalogParser.BodyContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_rule




    def datalog_rule(self):

        localctx = DatalogParser.Datalog_ruleContext(self, self._ctx, self.state)
        self.enterRule(localctx, 10, self.RULE_datalog_rule)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            rule_map = {}
            self.state = 116
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==DatalogParser.TOKEN_NON_DEDUP:
                self.state = 114
                self.match(DatalogParser.TOKEN_NON_DEDUP)
                rule_map['non-dedup'] = True


            self.state = 120
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==DatalogParser.TOKEN_NON_SET_DIFF:
                self.state = 118
                self.match(DatalogParser.TOKEN_NON_SET_DIFF)
                rule_map['non-set-diff'] = True


            self.state = 124
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==DatalogParser.TOKEN_DEDUP_ONLY:
                self.state = 122
                self.match(DatalogParser.TOKEN_DEDUP_ONLY)
                rule_map['dedup-only'] = True


            self.state = 126
            localctx.h = self.head()
            rule_map['head'] = localctx.h.r
            self.state = 128
            self.match(DatalogParser.TOKEN_BODY_HEAD_SEP)
            rule_map['body'] = None
            self.state = 133
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << DatalogParser.TOKEN_INTEGER) | (1 << DatalogParser.TOKEN_ID) | (1 << DatalogParser.TOKEN_NOT))) != 0):
                self.state = 130
                localctx.b = self.body()
                rule_map['body'] = localctx.b.r


            self.state = 135
            self.match(DatalogParser.TOKEN_DOT)
            localctx.r = rule_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class HeadContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a = None # AtomContext

        def atom(self):
            return self.getTypedRuleContext(DatalogParser.AtomContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_head




    def head(self):

        localctx = DatalogParser.HeadContext(self, self._ctx, self.state)
        self.enterRule(localctx, 12, self.RULE_head)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 138
            localctx.a = self.atom()
            localctx.r = localctx.a.r
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class BodyContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.b1 = None # AtomContext
            self.b2 = None # Compare_exprContext
            self.b3 = None # AssignContext
            self.b4 = None # NegationContext
            self.b5 = None # AtomContext
            self.b6 = None # Compare_exprContext
            self.b7 = None # AssignContext
            self.b8 = None # NegationContext

        def TOKEN_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_COMMA)
            else:
                return self.getToken(DatalogParser.TOKEN_COMMA, i)

        def atom(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.AtomContext)
            else:
                return self.getTypedRuleContext(DatalogParser.AtomContext,i)


        def compare_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Compare_exprContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Compare_exprContext,i)


        def assign(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.AssignContext)
            else:
                return self.getTypedRuleContext(DatalogParser.AssignContext,i)


        def negation(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.NegationContext)
            else:
                return self.getTypedRuleContext(DatalogParser.NegationContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_body




    def body(self):

        localctx = DatalogParser.BodyContext(self, self._ctx, self.state)
        self.enterRule(localctx, 14, self.RULE_body)
        try:
            self.enterOuterAlt(localctx, 1)
            body_map = {'atoms':[], 'compares': [], 'assigns':[], 'negations':[]}
            self.state = 160
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,9,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 154
                    self._errHandler.sync(self)
                    la_ = self._interp.adaptivePredict(self._input,8,self._ctx)
                    if la_ == 1:
                        self.state = 142
                        localctx.b1 = self.atom()
                        body_map['atoms'].append(localctx.b1.r)
                        pass

                    elif la_ == 2:
                        self.state = 145
                        localctx.b2 = self.compare_expr()
                        body_map['compares'].append(localctx.b2.r)
                        pass

                    elif la_ == 3:
                        self.state = 148
                        localctx.b3 = self.assign()
                        body_map['assigns'].append(localctx.b3.r)
                        pass

                    elif la_ == 4:
                        self.state = 151
                        localctx.b4 = self.negation()
                        body_map['negations'].append(localctx.b4.r)
                        pass


                    self.state = 156
                    self.match(DatalogParser.TOKEN_COMMA) 
                self.state = 162
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,9,self._ctx)

            self.state = 175
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,10,self._ctx)
            if la_ == 1:
                self.state = 163
                localctx.b5 = self.atom()
                body_map['atoms'].append(localctx.b5.r)
                pass

            elif la_ == 2:
                self.state = 166
                localctx.b6 = self.compare_expr()
                body_map['compares'].append(localctx.b6.r)
                pass

            elif la_ == 3:
                self.state = 169
                localctx.b7 = self.assign()
                body_map['assigns'].append(localctx.b7.r)
                pass

            elif la_ == 4:
                self.state = 172
                localctx.b8 = self.negation()
                body_map['negations'].append(localctx.b8.r)
                pass


            localctx.r = body_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class NegationContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a = None # AtomContext

        def TOKEN_NOT(self):
            return self.getToken(DatalogParser.TOKEN_NOT, 0)

        def atom(self):
            return self.getTypedRuleContext(DatalogParser.AtomContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_negation




    def negation(self):

        localctx = DatalogParser.NegationContext(self, self._ctx, self.state)
        self.enterRule(localctx, 16, self.RULE_negation)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 179
            self.match(DatalogParser.TOKEN_NOT)
            self.state = 180
            localctx.a = self.atom()
            localctx.r = localctx.a.r
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AtomContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token
            self.a2 = None # Token
            self.a3 = None # Aggregation_exprContext
            self.a4 = None # Token
            self.a5 = None # ConstantContext
            self.a6 = None # Math_exprContext
            self.a7 = None # Token
            self.a8 = None # Aggregation_exprContext
            self.a9 = None # Token
            self.a10 = None # ConstantContext
            self.a11 = None # Math_exprContext

        def TOKEN_LEFT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_PAREN, 0)

        def TOKEN_RIGHT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_PAREN, 0)

        def TOKEN_ID(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ID)
            else:
                return self.getToken(DatalogParser.TOKEN_ID, i)

        def aggregation_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Aggregation_exprContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Aggregation_exprContext,i)


        def TOKEN_ANY(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ANY)
            else:
                return self.getToken(DatalogParser.TOKEN_ANY, i)

        def constant(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.ConstantContext)
            else:
                return self.getTypedRuleContext(DatalogParser.ConstantContext,i)


        def math_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Math_exprContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Math_exprContext,i)


        def TOKEN_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_COMMA)
            else:
                return self.getToken(DatalogParser.TOKEN_COMMA, i)

        def getRuleIndex(self):
            return DatalogParser.RULE_atom




    def atom(self):

        localctx = DatalogParser.AtomContext(self, self._ctx, self.state)
        self.enterRule(localctx, 18, self.RULE_atom)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            atom_map = {'name': None, 'arg_list':[]}
            self.state = 184
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            atom_map['name'] = (None if localctx.a1 is None else localctx.a1.text)
            self.state = 186
            self.match(DatalogParser.TOKEN_LEFT_PAREN)
            self.state = 200
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,11,self._ctx)
            if la_ == 1:
                self.state = 187
                localctx.a2 = self.match(DatalogParser.TOKEN_ID)
                atom_map['arg_list'].append(self.AtomArg((None if localctx.a2 is None else localctx.a2.text), 'variable'))
                pass

            elif la_ == 2:
                self.state = 189
                localctx.a3 = self.aggregation_expr()
                atom_map['arg_list'].append(self.AtomArg(localctx.a3.r, 'aggregation'))
                pass

            elif la_ == 3:
                self.state = 192
                localctx.a4 = self.match(DatalogParser.TOKEN_ANY)
                atom_map['arg_list'].append(self.AtomArg((None if localctx.a4 is None else localctx.a4.text), 'any'))
                pass

            elif la_ == 4:
                self.state = 194
                localctx.a5 = self.constant()
                atom_map['arg_list'].append(self.AtomArg((None if localctx.a5 is None else self._input.getText(localctx.a5.start,localctx.a5.stop)), 'constant'))
                pass

            elif la_ == 5:
                self.state = 197
                localctx.a6 = self.math_expr()
                atom_map['arg_list'].append(self.AtomArg(localctx.a6.r, 'math_expr'))
                pass


            self.state = 220
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_COMMA:
                self.state = 202
                self.match(DatalogParser.TOKEN_COMMA)
                self.state = 216
                self._errHandler.sync(self)
                la_ = self._interp.adaptivePredict(self._input,12,self._ctx)
                if la_ == 1:
                    self.state = 203
                    localctx.a7 = self.match(DatalogParser.TOKEN_ID)
                    atom_map['arg_list'].append(self.AtomArg((None if localctx.a7 is None else localctx.a7.text), 'variable'))
                    pass

                elif la_ == 2:
                    self.state = 205
                    localctx.a8 = self.aggregation_expr()
                    atom_map['arg_list'].append(self.AtomArg(localctx.a8.r, 'aggregation'))
                    pass

                elif la_ == 3:
                    self.state = 208
                    localctx.a9 = self.match(DatalogParser.TOKEN_ANY)
                    atom_map['arg_list'].append(self.AtomArg((None if localctx.a9 is None else localctx.a9.text), 'any'))
                    pass

                elif la_ == 4:
                    self.state = 210
                    localctx.a10 = self.constant()
                    atom_map['arg_list'].append(self.AtomArg((None if localctx.a10 is None else self._input.getText(localctx.a10.start,localctx.a10.stop)), 'constant'))
                    pass

                elif la_ == 5:
                    self.state = 213
                    localctx.a11 = self.math_expr()
                    atom_map['arg_list'].append(self.AtomArg(localctx.a11.r, 'math_expr'))
                    pass


                self.state = 222
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 223
            self.match(DatalogParser.TOKEN_RIGHT_PAREN)
            localctx.r = atom_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AssignContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token
            self.a2 = None # Math_exprContext

        def TOKEN_ASSIGN(self):
            return self.getToken(DatalogParser.TOKEN_ASSIGN, 0)

        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def math_expr(self):
            return self.getTypedRuleContext(DatalogParser.Math_exprContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_assign




    def assign(self):

        localctx = DatalogParser.AssignContext(self, self._ctx, self.state)
        self.enterRule(localctx, 20, self.RULE_assign)
        try:
            self.enterOuterAlt(localctx, 1)
            assign_map = {}
            self.state = 227
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            assign_map['lhs'] = (None if localctx.a1 is None else localctx.a1.text)
            self.state = 229
            self.match(DatalogParser.TOKEN_ASSIGN)
            self.state = 230
            localctx.a2 = self.math_expr()
            assign_map['rhs'] = localctx.a2.r
            localctx.r = assign_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Compare_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.c1 = None # Token
            self.c2 = None # NumberContext
            self.op = None # Compare_opContext
            self.c4 = None # Token
            self.c5 = None # NumberContext

        def compare_op(self):
            return self.getTypedRuleContext(DatalogParser.Compare_opContext,0)


        def TOKEN_ID(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ID)
            else:
                return self.getToken(DatalogParser.TOKEN_ID, i)

        def number(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.NumberContext)
            else:
                return self.getTypedRuleContext(DatalogParser.NumberContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_compare_expr




    def compare_expr(self):

        localctx = DatalogParser.Compare_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 22, self.RULE_compare_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            compare_map = {}
            self.state = 240
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_ID]:
                self.state = 235
                localctx.c1 = self.match(DatalogParser.TOKEN_ID)
                compare_map['lhs'] = {"type": "variable", "value": (None if localctx.c1 is None else localctx.c1.text)}
                pass
            elif token in [DatalogParser.TOKEN_INTEGER]:
                self.state = 237
                localctx.c2 = self.number()
                compare_map['lhs'] = {"type": "number", "value": (None if localctx.c2 is None else self._input.getText(localctx.c2.start,localctx.c2.stop))}
                pass
            else:
                raise NoViableAltException(self)

            self.state = 242
            localctx.op = self.compare_op()
            compare_map['op'] = localctx.op.r
            self.state = 249
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_ID]:
                self.state = 244
                localctx.c4 = self.match(DatalogParser.TOKEN_ID)
                compare_map['rhs'] = {"type": "variable", "value": (None if localctx.c4 is None else localctx.c4.text)}
                pass
            elif token in [DatalogParser.TOKEN_INTEGER]:
                self.state = 246
                localctx.c5 = self.number()
                compare_map['rhs'] = {"type": "number", "value": (None if localctx.c5 is None else self._input.getText(localctx.c5.start,localctx.c5.stop))}
                pass
            else:
                raise NoViableAltException(self)

            localctx.r = compare_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Aggregation_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Aggregation_opContext
            self.a2 = None # Token
            self.a3 = None # Math_exprContext

        def TOKEN_LEFT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_PAREN, 0)

        def TOKEN_RIGHT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_PAREN, 0)

        def aggregation_op(self):
            return self.getTypedRuleContext(DatalogParser.Aggregation_opContext,0)


        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def math_expr(self):
            return self.getTypedRuleContext(DatalogParser.Math_exprContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_aggregation_expr




    def aggregation_expr(self):

        localctx = DatalogParser.Aggregation_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 24, self.RULE_aggregation_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            agg_map = {'agg_op': None, 'agg_arg': None}
            self.state = 254
            localctx.a1 = self.aggregation_op()
            agg_map['agg_op'] = localctx.a1.r
            self.state = 256
            self.match(DatalogParser.TOKEN_LEFT_PAREN)
            self.state = 262
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,16,self._ctx)
            if la_ == 1:
                self.state = 257
                localctx.a2 = self.match(DatalogParser.TOKEN_ID)
                agg_map['agg_arg'] = {'type': 'attribute', 'content': (None if localctx.a2 is None else localctx.a2.text)}
                pass

            elif la_ == 2:
                self.state = 259
                localctx.a3 = self.math_expr()
                agg_map['agg_arg'] = {'type': 'math_expr', 'content': localctx.a3.r}
                pass


            self.state = 264
            self.match(DatalogParser.TOKEN_RIGHT_PAREN)
            localctx.r = agg_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Math_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.m1 = None # Token
            self.m2 = None # NumberContext
            self.m3 = None # Math_opContext
            self.m4 = None # Token
            self.m5 = None # NumberContext

        def math_op(self):
            return self.getTypedRuleContext(DatalogParser.Math_opContext,0)


        def TOKEN_ID(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ID)
            else:
                return self.getToken(DatalogParser.TOKEN_ID, i)

        def number(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.NumberContext)
            else:
                return self.getTypedRuleContext(DatalogParser.NumberContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_math_expr




    def math_expr(self):

        localctx = DatalogParser.Math_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 26, self.RULE_math_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            math_map = {}
            self.state = 273
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_ID]:
                self.state = 268
                localctx.m1 = self.match(DatalogParser.TOKEN_ID)
                math_map['lhs'] = {"type": "variable", "value": (None if localctx.m1 is None else localctx.m1.text)}
                pass
            elif token in [DatalogParser.TOKEN_INTEGER]:
                self.state = 270
                localctx.m2 = self.number()
                math_map['lhs'] = {"type": "number", "value": (None if localctx.m2 is None else self._input.getText(localctx.m2.start,localctx.m2.stop))}
                pass
            else:
                raise NoViableAltException(self)

            self.state = 275
            localctx.m3 = self.math_op()
            math_map['op'] = localctx.m3.r
            self.state = 282
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_ID]:
                self.state = 277
                localctx.m4 = self.match(DatalogParser.TOKEN_ID)
                math_map['rhs'] = {"type": "variable", "value": (None if localctx.m4 is None else localctx.m4.text)}
                pass
            elif token in [DatalogParser.TOKEN_INTEGER]:
                self.state = 279
                localctx.m5 = self.number()
                math_map['rhs'] = {"type": "number", "value": (None if localctx.m5 is None else self._input.getText(localctx.m5.start,localctx.m5.stop))}
                pass
            else:
                raise NoViableAltException(self)

            localctx.r = math_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AttributeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Non_key_attributeContext
            self.a2 = None # Key_attributeContext

        def non_key_attribute(self):
            return self.getTypedRuleContext(DatalogParser.Non_key_attributeContext,0)


        def key_attribute(self):
            return self.getTypedRuleContext(DatalogParser.Key_attributeContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_attribute




    def attribute(self):

        localctx = DatalogParser.AttributeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 28, self.RULE_attribute)
        try:
            self.state = 292
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_ID]:
                self.enterOuterAlt(localctx, 1)
                self.state = 286
                localctx.a1 = self.non_key_attribute()
                localctx.r = localctx.a1.r
                pass
            elif token in [DatalogParser.TOKEN_LEFT_BRACKET]:
                self.enterOuterAlt(localctx, 2)
                self.state = 289
                localctx.a2 = self.key_attribute()
                localctx.r = localctx.a2.r
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Key_attributeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token
            self.d1 = None # Data_typeContext

        def TOKEN_LEFT_BRACKET(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_BRACKET, 0)

        def TOKEN_RIGHT_BRACKET(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_BRACKET, 0)

        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def data_type(self):
            return self.getTypedRuleContext(DatalogParser.Data_typeContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_key_attribute




    def key_attribute(self):

        localctx = DatalogParser.Key_attributeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 30, self.RULE_key_attribute)
        try:
            self.enterOuterAlt(localctx, 1)
            attribute_map = {'name': None, 'type': None, 'is_key': True}
            self.state = 295
            self.match(DatalogParser.TOKEN_LEFT_BRACKET)
            self.state = 296
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            attribute_map['name'] = (None if localctx.a1 is None else localctx.a1.text)
            self.state = 298
            self.match(DatalogParser.TOKEN_RIGHT_BRACKET)
            self.state = 299
            localctx.d1 = self.data_type()
            attribute_map['type'] = localctx.d1.r
            localctx.r = attribute_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Non_key_attributeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token
            self.d1 = None # Data_typeContext

        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def data_type(self):
            return self.getTypedRuleContext(DatalogParser.Data_typeContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_non_key_attribute




    def non_key_attribute(self):

        localctx = DatalogParser.Non_key_attributeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 32, self.RULE_non_key_attribute)
        try:
            self.enterOuterAlt(localctx, 1)
            attribute_map = {'name': None, 'type': None, 'is_key': False}
            self.state = 304
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            attribute_map['name'] = (None if localctx.a1 is None else localctx.a1.text)
            self.state = 306
            localctx.d1 = self.data_type()
            attribute_map['type'] = localctx.d1.r
            localctx.r = attribute_map
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Compare_opContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.op1 = None # Token
            self.op2 = None # Token
            self.op3 = None # Token
            self.op4 = None # Token
            self.op5 = None # Token
            self.op6 = None # Token

        def TOKEN_NOT_EQUALS(self):
            return self.getToken(DatalogParser.TOKEN_NOT_EQUALS, 0)

        def TOKEN_EQUALS(self):
            return self.getToken(DatalogParser.TOKEN_EQUALS, 0)

        def TOKEN_GREATER_THAN(self):
            return self.getToken(DatalogParser.TOKEN_GREATER_THAN, 0)

        def TOKEN_GREATER_EQUAL_THAN(self):
            return self.getToken(DatalogParser.TOKEN_GREATER_EQUAL_THAN, 0)

        def TOKEN_LESS_THAN(self):
            return self.getToken(DatalogParser.TOKEN_LESS_THAN, 0)

        def TOKEN_LESS_EQUAL_THAN(self):
            return self.getToken(DatalogParser.TOKEN_LESS_EQUAL_THAN, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_compare_op




    def compare_op(self):

        localctx = DatalogParser.Compare_opContext(self, self._ctx, self.state)
        self.enterRule(localctx, 34, self.RULE_compare_op)
        try:
            self.state = 322
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_NOT_EQUALS]:
                self.enterOuterAlt(localctx, 1)
                self.state = 310
                localctx.op1 = self.match(DatalogParser.TOKEN_NOT_EQUALS)
                localctx.r = (None if localctx.op1 is None else localctx.op1.text)
                pass
            elif token in [DatalogParser.TOKEN_EQUALS]:
                self.enterOuterAlt(localctx, 2)
                self.state = 312
                localctx.op2 = self.match(DatalogParser.TOKEN_EQUALS)
                localctx.r = (None if localctx.op2 is None else localctx.op2.text)
                pass
            elif token in [DatalogParser.TOKEN_GREATER_THAN]:
                self.enterOuterAlt(localctx, 3)
                self.state = 314
                localctx.op3 = self.match(DatalogParser.TOKEN_GREATER_THAN)
                localctx.r = (None if localctx.op3 is None else localctx.op3.text)
                pass
            elif token in [DatalogParser.TOKEN_GREATER_EQUAL_THAN]:
                self.enterOuterAlt(localctx, 4)
                self.state = 316
                localctx.op4 = self.match(DatalogParser.TOKEN_GREATER_EQUAL_THAN)
                localctx.r = (None if localctx.op4 is None else localctx.op4.text)
                pass
            elif token in [DatalogParser.TOKEN_LESS_THAN]:
                self.enterOuterAlt(localctx, 5)
                self.state = 318
                localctx.op5 = self.match(DatalogParser.TOKEN_LESS_THAN)
                localctx.r = (None if localctx.op5 is None else localctx.op5.text)
                pass
            elif token in [DatalogParser.TOKEN_LESS_EQUAL_THAN]:
                self.enterOuterAlt(localctx, 6)
                self.state = 320
                localctx.op6 = self.match(DatalogParser.TOKEN_LESS_EQUAL_THAN)
                localctx.r = (None if localctx.op6 is None else localctx.op6.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Aggregation_opContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.op1 = None # Token
            self.op2 = None # Token
            self.op3 = None # Token
            self.op4 = None # Token
            self.op5 = None # Token

        def TOKEN_MIN(self):
            return self.getToken(DatalogParser.TOKEN_MIN, 0)

        def TOKEN_MAX(self):
            return self.getToken(DatalogParser.TOKEN_MAX, 0)

        def TOKEN_SUM(self):
            return self.getToken(DatalogParser.TOKEN_SUM, 0)

        def TOKEN_COUNT(self):
            return self.getToken(DatalogParser.TOKEN_COUNT, 0)

        def TOKEN_COUNT_DISTINCT(self):
            return self.getToken(DatalogParser.TOKEN_COUNT_DISTINCT, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_aggregation_op




    def aggregation_op(self):

        localctx = DatalogParser.Aggregation_opContext(self, self._ctx, self.state)
        self.enterRule(localctx, 36, self.RULE_aggregation_op)
        try:
            self.state = 334
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_MIN]:
                self.enterOuterAlt(localctx, 1)
                self.state = 324
                localctx.op1 = self.match(DatalogParser.TOKEN_MIN)
                localctx.r = (None if localctx.op1 is None else localctx.op1.text)
                pass
            elif token in [DatalogParser.TOKEN_MAX]:
                self.enterOuterAlt(localctx, 2)
                self.state = 326
                localctx.op2 = self.match(DatalogParser.TOKEN_MAX)
                localctx.r = (None if localctx.op2 is None else localctx.op2.text)
                pass
            elif token in [DatalogParser.TOKEN_SUM]:
                self.enterOuterAlt(localctx, 3)
                self.state = 328
                localctx.op3 = self.match(DatalogParser.TOKEN_SUM)
                localctx.r = (None if localctx.op3 is None else localctx.op3.text)
                pass
            elif token in [DatalogParser.TOKEN_COUNT]:
                self.enterOuterAlt(localctx, 4)
                self.state = 330
                localctx.op4 = self.match(DatalogParser.TOKEN_COUNT)
                localctx.r = (None if localctx.op4 is None else localctx.op4.text)
                pass
            elif token in [DatalogParser.TOKEN_COUNT_DISTINCT]:
                self.enterOuterAlt(localctx, 5)
                self.state = 332
                localctx.op5 = self.match(DatalogParser.TOKEN_COUNT_DISTINCT)
                localctx.r = (None if localctx.op5 is None else localctx.op5.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Math_opContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.op1 = None # Token
            self.op2 = None # Token
            self.op3 = None # Token
            self.op4 = None # Token

        def TOKEN_PLUS(self):
            return self.getToken(DatalogParser.TOKEN_PLUS, 0)

        def TOKEN_MINUS(self):
            return self.getToken(DatalogParser.TOKEN_MINUS, 0)

        def TOKEN_MULT(self):
            return self.getToken(DatalogParser.TOKEN_MULT, 0)

        def TOKEN_DIV(self):
            return self.getToken(DatalogParser.TOKEN_DIV, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_math_op




    def math_op(self):

        localctx = DatalogParser.Math_opContext(self, self._ctx, self.state)
        self.enterRule(localctx, 38, self.RULE_math_op)
        try:
            self.state = 344
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_PLUS]:
                self.enterOuterAlt(localctx, 1)
                self.state = 336
                localctx.op1 = self.match(DatalogParser.TOKEN_PLUS)
                localctx.r = (None if localctx.op1 is None else localctx.op1.text)
                pass
            elif token in [DatalogParser.TOKEN_MINUS]:
                self.enterOuterAlt(localctx, 2)
                self.state = 338
                localctx.op2 = self.match(DatalogParser.TOKEN_MINUS)
                localctx.r = (None if localctx.op2 is None else localctx.op2.text)
                pass
            elif token in [DatalogParser.TOKEN_MULT]:
                self.enterOuterAlt(localctx, 3)
                self.state = 340
                localctx.op3 = self.match(DatalogParser.TOKEN_MULT)
                localctx.r = (None if localctx.op3 is None else localctx.op3.text)
                pass
            elif token in [DatalogParser.TOKEN_DIV]:
                self.enterOuterAlt(localctx, 4)
                self.state = 342
                localctx.op4 = self.match(DatalogParser.TOKEN_DIV)
                localctx.r = (None if localctx.op4 is None else localctx.op4.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ConstantContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.c1 = None # NumberContext
            self.c2 = None # Token

        def number(self):
            return self.getTypedRuleContext(DatalogParser.NumberContext,0)


        def TOKEN_STRING(self):
            return self.getToken(DatalogParser.TOKEN_STRING, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_constant




    def constant(self):

        localctx = DatalogParser.ConstantContext(self, self._ctx, self.state)
        self.enterRule(localctx, 40, self.RULE_constant)
        try:
            self.state = 351
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_INTEGER]:
                self.enterOuterAlt(localctx, 1)
                self.state = 346
                localctx.c1 = self.number()
                localctx.r = {"type": "number", "value": localctx.c1.r}
                pass
            elif token in [DatalogParser.TOKEN_STRING]:
                self.enterOuterAlt(localctx, 2)
                self.state = 349
                localctx.c2 = self.match(DatalogParser.TOKEN_STRING)
                localctx.r = {"type": "string", "value": (None if localctx.c2 is None else localctx.c2.text)}
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class NumberContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.n1 = None # Token

        def TOKEN_INTEGER(self):
            return self.getToken(DatalogParser.TOKEN_INTEGER, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_number




    def number(self):

        localctx = DatalogParser.NumberContext(self, self._ctx, self.state)
        self.enterRule(localctx, 42, self.RULE_number)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 353
            localctx.n1 = self.match(DatalogParser.TOKEN_INTEGER)
            localctx.r = {"type": "int", "value": (None if localctx.n1 is None else localctx.n1.text)}
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Data_typeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.dt1 = None # Token
            self.dt2 = None # Token
            self.dt3 = None # Token
            self.dt4 = None # Token
            self.dt5 = None # Token
            self.dt6 = None # Token
            self.dt7 = None # Token
            self.dt8 = None # Token

        def TOKEN_INT(self):
            return self.getToken(DatalogParser.TOKEN_INT, 0)

        def TOKEN_LONG(self):
            return self.getToken(DatalogParser.TOKEN_LONG, 0)

        def TOKEN_FLOAT(self):
            return self.getToken(DatalogParser.TOKEN_FLOAT, 0)

        def TOKEN_DOUBLE(self):
            return self.getToken(DatalogParser.TOKEN_DOUBLE, 0)

        def TOKEN_VARCHAR(self):
            return self.getToken(DatalogParser.TOKEN_VARCHAR, 0)

        def TOKEN_CHAR(self):
            return self.getToken(DatalogParser.TOKEN_CHAR, 0)

        def TOKEN_DATE(self):
            return self.getToken(DatalogParser.TOKEN_DATE, 0)

        def TOKEN_DATETIME(self):
            return self.getToken(DatalogParser.TOKEN_DATETIME, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_data_type




    def data_type(self):

        localctx = DatalogParser.Data_typeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 44, self.RULE_data_type)
        try:
            self.state = 372
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_INT]:
                self.enterOuterAlt(localctx, 1)
                self.state = 356
                localctx.dt1 = self.match(DatalogParser.TOKEN_INT)
                localctx.r = (None if localctx.dt1 is None else localctx.dt1.text)
                pass
            elif token in [DatalogParser.TOKEN_LONG]:
                self.enterOuterAlt(localctx, 2)
                self.state = 358
                localctx.dt2 = self.match(DatalogParser.TOKEN_LONG)
                localctx.r = (None if localctx.dt2 is None else localctx.dt2.text)
                pass
            elif token in [DatalogParser.TOKEN_FLOAT]:
                self.enterOuterAlt(localctx, 3)
                self.state = 360
                localctx.dt3 = self.match(DatalogParser.TOKEN_FLOAT)
                localctx.r = (None if localctx.dt3 is None else localctx.dt3.text)
                pass
            elif token in [DatalogParser.TOKEN_DOUBLE]:
                self.enterOuterAlt(localctx, 4)
                self.state = 362
                localctx.dt4 = self.match(DatalogParser.TOKEN_DOUBLE)
                localctx.r = (None if localctx.dt4 is None else localctx.dt4.text)
                pass
            elif token in [DatalogParser.TOKEN_VARCHAR]:
                self.enterOuterAlt(localctx, 5)
                self.state = 364
                localctx.dt5 = self.match(DatalogParser.TOKEN_VARCHAR)
                localctx.r = (None if localctx.dt5 is None else localctx.dt5.text)
                pass
            elif token in [DatalogParser.TOKEN_CHAR]:
                self.enterOuterAlt(localctx, 6)
                self.state = 366
                localctx.dt6 = self.match(DatalogParser.TOKEN_CHAR)
                localctx.r = (None if localctx.dt6 is None else localctx.dt6.text)
                pass
            elif token in [DatalogParser.TOKEN_DATE]:
                self.enterOuterAlt(localctx, 7)
                self.state = 368
                localctx.dt7 = self.match(DatalogParser.TOKEN_DATE)
                localctx.r = (None if localctx.dt7 is None else localctx.dt7.text)
                pass
            elif token in [DatalogParser.TOKEN_DATETIME]:
                self.enterOuterAlt(localctx, 8)
                self.state = 370
                localctx.dt8 = self.match(DatalogParser.TOKEN_DATETIME)
                localctx.r = (None if localctx.dt8 is None else localctx.dt8.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx





