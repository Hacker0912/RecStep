# Generated from Datalog.g4 by ANTLR 4.8
# encoding: utf-8
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
	from typing import TextIO
else:
	from typing.io import TextIO




def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3.")
        buf.write("\u0166\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7")
        buf.write("\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r\4\16")
        buf.write("\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23\t\23")
        buf.write("\4\24\t\24\4\25\t\25\4\26\t\26\3\2\3\2\3\2\3\2\3\2\3\2")
        buf.write("\3\2\3\2\7\2\65\n\2\f\2\16\28\13\2\3\2\3\2\3\3\3\3\3\3")
        buf.write("\3\3\3\3\3\3\3\3\3\3\7\3D\n\3\f\3\16\3G\13\3\3\3\3\3\3")
        buf.write("\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\5\4")
        buf.write("X\n\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\5\4d\n\4")
        buf.write("\7\4f\n\4\f\4\16\4i\13\4\3\4\3\4\3\4\3\5\3\5\3\5\3\5\3")
        buf.write("\5\3\5\3\6\3\6\3\6\3\6\3\6\3\6\7\6z\n\6\f\6\16\6}\13\6")
        buf.write("\3\6\3\6\3\7\3\7\3\7\5\7\u0084\n\7\3\7\3\7\5\7\u0088\n")
        buf.write("\7\3\7\3\7\5\7\u008c\n\7\3\7\3\7\3\7\3\7\3\7\3\7\3\7\5")
        buf.write("\7\u0095\n\7\3\7\3\7\3\7\3\b\3\b\3\b\3\t\3\t\3\t\3\t\3")
        buf.write("\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\5\t\u00aa\n\t\3\t\3")
        buf.write("\t\7\t\u00ae\n\t\f\t\16\t\u00b1\13\t\3\t\3\t\3\t\3\t\3")
        buf.write("\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\5\t\u00bf\n\t\3\t\3\t\3")
        buf.write("\n\3\n\3\n\3\n\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13")
        buf.write("\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\5\13\u00d8")
        buf.write("\n\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13\3\13")
        buf.write("\3\13\3\13\3\13\3\13\5\13\u00e8\n\13\7\13\u00ea\n\13\f")
        buf.write("\13\16\13\u00ed\13\13\3\13\3\13\3\13\3\f\3\f\3\f\3\f\3")
        buf.write("\f\3\f\3\f\3\f\3\r\3\r\3\r\3\r\3\r\3\r\3\r\3\r\3\r\3\16")
        buf.write("\3\16\3\16\3\16\3\16\5\16\u0108\n\16\3\16\3\16\3\16\3")
        buf.write("\16\3\16\3\16\5\16\u0110\n\16\3\16\3\16\3\17\3\17\3\17")
        buf.write("\3\17\3\17\3\17\3\17\3\17\3\17\5\17\u011d\n\17\3\17\3")
        buf.write("\17\3\17\3\20\3\20\3\20\3\20\3\20\3\21\3\21\3\21\3\22")
        buf.write("\3\22\3\22\3\22\3\22\3\22\3\22\3\22\3\22\3\22\3\22\3\22")
        buf.write("\5\22\u0136\n\22\3\23\3\23\3\23\3\23\3\23\3\23\3\23\3")
        buf.write("\23\3\23\3\23\5\23\u0142\n\23\3\24\3\24\3\24\3\24\3\24")
        buf.write("\3\24\3\24\3\24\5\24\u014c\n\24\3\25\3\25\3\25\3\25\5")
        buf.write("\25\u0152\n\25\3\26\3\26\3\26\3\26\3\26\3\26\3\26\3\26")
        buf.write("\3\26\3\26\3\26\3\26\3\26\3\26\3\26\3\26\5\26\u0164\n")
        buf.write("\26\3\26\2\2\27\2\4\6\b\n\f\16\20\22\24\26\30\32\34\36")
        buf.write(" \"$&(*\2\2\2\u0181\2,\3\2\2\2\4;\3\2\2\2\6J\3\2\2\2\b")
        buf.write("m\3\2\2\2\ns\3\2\2\2\f\u0080\3\2\2\2\16\u0099\3\2\2\2")
        buf.write("\20\u009c\3\2\2\2\22\u00c2\3\2\2\2\24\u00c6\3\2\2\2\26")
        buf.write("\u00f1\3\2\2\2\30\u00f9\3\2\2\2\32\u0102\3\2\2\2\34\u0113")
        buf.write("\3\2\2\2\36\u0121\3\2\2\2 \u0126\3\2\2\2\"\u0135\3\2\2")
        buf.write("\2$\u0141\3\2\2\2&\u014b\3\2\2\2(\u0151\3\2\2\2*\u0163")
        buf.write("\3\2\2\2,-\b\2\1\2-.\7\3\2\2./\7\32\2\2/\60\5\6\4\2\60")
        buf.write("\66\b\2\1\2\61\62\5\6\4\2\62\63\b\2\1\2\63\65\3\2\2\2")
        buf.write("\64\61\3\2\2\2\658\3\2\2\2\66\64\3\2\2\2\66\67\3\2\2\2")
        buf.write("\679\3\2\2\28\66\3\2\2\29:\b\2\1\2:\3\3\2\2\2;<\b\3\1")
        buf.write("\2<=\7\4\2\2=>\7\32\2\2>?\5\6\4\2?E\b\3\1\2@A\5\6\4\2")
        buf.write("AB\b\3\1\2BD\3\2\2\2C@\3\2\2\2DG\3\2\2\2EC\3\2\2\2EF\3")
        buf.write("\2\2\2FH\3\2\2\2GE\3\2\2\2HI\b\3\1\2I\5\3\2\2\2JK\b\4")
        buf.write("\1\2KL\7\25\2\2LM\b\4\1\2MW\7*\2\2NO\5 \21\2OP\5*\26\2")
        buf.write("PQ\b\4\1\2QX\3\2\2\2RS\5\36\20\2ST\b\4\1\2TU\5*\26\2U")
        buf.write("V\b\4\1\2VX\3\2\2\2WN\3\2\2\2WR\3\2\2\2Xg\3\2\2\2Yc\7")
        buf.write("\30\2\2Z[\5 \21\2[\\\5*\26\2\\]\b\4\1\2]d\3\2\2\2^_\5")
        buf.write("\36\20\2_`\b\4\1\2`a\5*\26\2ab\b\4\1\2bd\3\2\2\2cZ\3\2")
        buf.write("\2\2c^\3\2\2\2df\3\2\2\2eY\3\2\2\2fi\3\2\2\2ge\3\2\2\2")
        buf.write("gh\3\2\2\2hj\3\2\2\2ig\3\2\2\2jk\7+\2\2kl\b\4\1\2l\7\3")
        buf.write("\2\2\2mn\7\5\2\2no\7\32\2\2op\5\n\6\2pq\b\5\1\2qr\7\2")
        buf.write("\2\3r\t\3\2\2\2st\b\6\1\2tu\5\f\7\2u{\b\6\1\2vw\5\f\7")
        buf.write("\2wx\b\6\1\2xz\3\2\2\2yv\3\2\2\2z}\3\2\2\2{y\3\2\2\2{")
        buf.write("|\3\2\2\2|~\3\2\2\2}{\3\2\2\2~\177\b\6\1\2\177\13\3\2")
        buf.write("\2\2\u0080\u0083\b\7\1\2\u0081\u0082\7!\2\2\u0082\u0084")
        buf.write("\b\7\1\2\u0083\u0081\3\2\2\2\u0083\u0084\3\2\2\2\u0084")
        buf.write("\u0087\3\2\2\2\u0085\u0086\7\"\2\2\u0086\u0088\b\7\1\2")
        buf.write("\u0087\u0085\3\2\2\2\u0087\u0088\3\2\2\2\u0088\u008b\3")
        buf.write("\2\2\2\u0089\u008a\7#\2\2\u008a\u008c\b\7\1\2\u008b\u0089")
        buf.write("\3\2\2\2\u008b\u008c\3\2\2\2\u008c\u008d\3\2\2\2\u008d")
        buf.write("\u008e\5\16\b\2\u008e\u008f\b\7\1\2\u008f\u0090\7\26\2")
        buf.write("\2\u0090\u0094\b\7\1\2\u0091\u0092\5\20\t\2\u0092\u0093")
        buf.write("\b\7\1\2\u0093\u0095\3\2\2\2\u0094\u0091\3\2\2\2\u0094")
        buf.write("\u0095\3\2\2\2\u0095\u0096\3\2\2\2\u0096\u0097\7\33\2")
        buf.write("\2\u0097\u0098\b\7\1\2\u0098\r\3\2\2\2\u0099\u009a\5\24")
        buf.write("\13\2\u009a\u009b\b\b\1\2\u009b\17\3\2\2\2\u009c\u00af")
        buf.write("\b\t\1\2\u009d\u009e\5\24\13\2\u009e\u009f\b\t\1\2\u009f")
        buf.write("\u00aa\3\2\2\2\u00a0\u00a1\5\32\16\2\u00a1\u00a2\b\t\1")
        buf.write("\2\u00a2\u00aa\3\2\2\2\u00a3\u00a4\5\26\f\2\u00a4\u00a5")
        buf.write("\b\t\1\2\u00a5\u00aa\3\2\2\2\u00a6\u00a7\5\22\n\2\u00a7")
        buf.write("\u00a8\b\t\1\2\u00a8\u00aa\3\2\2\2\u00a9\u009d\3\2\2\2")
        buf.write("\u00a9\u00a0\3\2\2\2\u00a9\u00a3\3\2\2\2\u00a9\u00a6\3")
        buf.write("\2\2\2\u00aa\u00ab\3\2\2\2\u00ab\u00ac\7\30\2\2\u00ac")
        buf.write("\u00ae\3\2\2\2\u00ad\u00a9\3\2\2\2\u00ae\u00b1\3\2\2\2")
        buf.write("\u00af\u00ad\3\2\2\2\u00af\u00b0\3\2\2\2\u00b0\u00be\3")
        buf.write("\2\2\2\u00b1\u00af\3\2\2\2\u00b2\u00b3\5\24\13\2\u00b3")
        buf.write("\u00b4\b\t\1\2\u00b4\u00bf\3\2\2\2\u00b5\u00b6\5\32\16")
        buf.write("\2\u00b6\u00b7\b\t\1\2\u00b7\u00bf\3\2\2\2\u00b8\u00b9")
        buf.write("\5\26\f\2\u00b9\u00ba\b\t\1\2\u00ba\u00bf\3\2\2\2\u00bb")
        buf.write("\u00bc\5\22\n\2\u00bc\u00bd\b\t\1\2\u00bd\u00bf\3\2\2")
        buf.write("\2\u00be\u00b2\3\2\2\2\u00be\u00b5\3\2\2\2\u00be\u00b8")
        buf.write("\3\2\2\2\u00be\u00bb\3\2\2\2\u00bf\u00c0\3\2\2\2\u00c0")
        buf.write("\u00c1\b\t\1\2\u00c1\21\3\2\2\2\u00c2\u00c3\7 \2\2\u00c3")
        buf.write("\u00c4\5\24\13\2\u00c4\u00c5\b\n\1\2\u00c5\23\3\2\2\2")
        buf.write("\u00c6\u00c7\b\13\1\2\u00c7\u00c8\7\25\2\2\u00c8\u00c9")
        buf.write("\b\13\1\2\u00c9\u00d7\7*\2\2\u00ca\u00cb\7\25\2\2\u00cb")
        buf.write("\u00d8\b\13\1\2\u00cc\u00cd\5\34\17\2\u00cd\u00ce\b\13")
        buf.write("\1\2\u00ce\u00d8\3\2\2\2\u00cf\u00d0\7\27\2\2\u00d0\u00d8")
        buf.write("\b\13\1\2\u00d1\u00d2\5(\25\2\u00d2\u00d3\b\13\1\2\u00d3")
        buf.write("\u00d8\3\2\2\2\u00d4\u00d5\5\30\r\2\u00d5\u00d6\b\13\1")
        buf.write("\2\u00d6\u00d8\3\2\2\2\u00d7\u00ca\3\2\2\2\u00d7\u00cc")
        buf.write("\3\2\2\2\u00d7\u00cf\3\2\2\2\u00d7\u00d1\3\2\2\2\u00d7")
        buf.write("\u00d4\3\2\2\2\u00d8\u00eb\3\2\2\2\u00d9\u00e7\7\30\2")
        buf.write("\2\u00da\u00db\7\25\2\2\u00db\u00e8\b\13\1\2\u00dc\u00dd")
        buf.write("\5\34\17\2\u00dd\u00de\b\13\1\2\u00de\u00e8\3\2\2\2\u00df")
        buf.write("\u00e0\7\27\2\2\u00e0\u00e8\b\13\1\2\u00e1\u00e2\5(\25")
        buf.write("\2\u00e2\u00e3\b\13\1\2\u00e3\u00e8\3\2\2\2\u00e4\u00e5")
        buf.write("\5\30\r\2\u00e5\u00e6\b\13\1\2\u00e6\u00e8\3\2\2\2\u00e7")
        buf.write("\u00da\3\2\2\2\u00e7\u00dc\3\2\2\2\u00e7\u00df\3\2\2\2")
        buf.write("\u00e7\u00e1\3\2\2\2\u00e7\u00e4\3\2\2\2\u00e8\u00ea\3")
        buf.write("\2\2\2\u00e9\u00d9\3\2\2\2\u00ea\u00ed\3\2\2\2\u00eb\u00e9")
        buf.write("\3\2\2\2\u00eb\u00ec\3\2\2\2\u00ec\u00ee\3\2\2\2\u00ed")
        buf.write("\u00eb\3\2\2\2\u00ee\u00ef\7+\2\2\u00ef\u00f0\b\13\1\2")
        buf.write("\u00f0\25\3\2\2\2\u00f1\u00f2\b\f\1\2\u00f2\u00f3\7\25")
        buf.write("\2\2\u00f3\u00f4\b\f\1\2\u00f4\u00f5\7%\2\2\u00f5\u00f6")
        buf.write("\5\30\r\2\u00f6\u00f7\b\f\1\2\u00f7\u00f8\b\f\1\2\u00f8")
        buf.write("\27\3\2\2\2\u00f9\u00fa\b\r\1\2\u00fa\u00fb\7\25\2\2\u00fb")
        buf.write("\u00fc\b\r\1\2\u00fc\u00fd\5&\24\2\u00fd\u00fe\b\r\1\2")
        buf.write("\u00fe\u00ff\7\25\2\2\u00ff\u0100\b\r\1\2\u0100\u0101")
        buf.write("\b\r\1\2\u0101\31\3\2\2\2\u0102\u0107\b\16\1\2\u0103\u0104")
        buf.write("\7\25\2\2\u0104\u0108\b\16\1\2\u0105\u0106\7\6\2\2\u0106")
        buf.write("\u0108\b\16\1\2\u0107\u0103\3\2\2\2\u0107\u0105\3\2\2")
        buf.write("\2\u0108\u0109\3\2\2\2\u0109\u010a\5\"\22\2\u010a\u010f")
        buf.write("\b\16\1\2\u010b\u010c\7\25\2\2\u010c\u0110\b\16\1\2\u010d")
        buf.write("\u010e\7\6\2\2\u010e\u0110\b\16\1\2\u010f\u010b\3\2\2")
        buf.write("\2\u010f\u010d\3\2\2\2\u0110\u0111\3\2\2\2\u0111\u0112")
        buf.write("\b\16\1\2\u0112\33\3\2\2\2\u0113\u0114\b\17\1\2\u0114")
        buf.write("\u0115\5$\23\2\u0115\u0116\b\17\1\2\u0116\u011c\7*\2\2")
        buf.write("\u0117\u0118\7\25\2\2\u0118\u011d\b\17\1\2\u0119\u011a")
        buf.write("\5\30\r\2\u011a\u011b\b\17\1\2\u011b\u011d\3\2\2\2\u011c")
        buf.write("\u0117\3\2\2\2\u011c\u0119\3\2\2\2\u011d\u011e\3\2\2\2")
        buf.write("\u011e\u011f\7+\2\2\u011f\u0120\b\17\1\2\u0120\35\3\2")
        buf.write("\2\2\u0121\u0122\7,\2\2\u0122\u0123\7\25\2\2\u0123\u0124")
        buf.write("\b\20\1\2\u0124\u0125\7-\2\2\u0125\37\3\2\2\2\u0126\u0127")
        buf.write("\7\25\2\2\u0127\u0128\b\21\1\2\u0128!\3\2\2\2\u0129\u012a")
        buf.write("\7$\2\2\u012a\u0136\b\22\1\2\u012b\u012c\7%\2\2\u012c")
        buf.write("\u0136\b\22\1\2\u012d\u012e\7\'\2\2\u012e\u0136\b\22\1")
        buf.write("\2\u012f\u0130\7&\2\2\u0130\u0136\b\22\1\2\u0131\u0132")
        buf.write("\7)\2\2\u0132\u0136\b\22\1\2\u0133\u0134\7(\2\2\u0134")
        buf.write("\u0136\b\22\1\2\u0135\u0129\3\2\2\2\u0135\u012b\3\2\2")
        buf.write("\2\u0135\u012d\3\2\2\2\u0135\u012f\3\2\2\2\u0135\u0131")
        buf.write("\3\2\2\2\u0135\u0133\3\2\2\2\u0136#\3\2\2\2\u0137\u0138")
        buf.write("\7\20\2\2\u0138\u0142\b\23\1\2\u0139\u013a\7\21\2\2\u013a")
        buf.write("\u0142\b\23\1\2\u013b\u013c\7\22\2\2\u013c\u0142\b\23")
        buf.write("\1\2\u013d\u013e\7\23\2\2\u013e\u0142\b\23\1\2\u013f\u0140")
        buf.write("\7\24\2\2\u0140\u0142\b\23\1\2\u0141\u0137\3\2\2\2\u0141")
        buf.write("\u0139\3\2\2\2\u0141\u013b\3\2\2\2\u0141\u013d\3\2\2\2")
        buf.write("\u0141\u013f\3\2\2\2\u0142%\3\2\2\2\u0143\u0144\7\34\2")
        buf.write("\2\u0144\u014c\b\24\1\2\u0145\u0146\7\35\2\2\u0146\u014c")
        buf.write("\b\24\1\2\u0147\u0148\7\36\2\2\u0148\u014c\b\24\1\2\u0149")
        buf.write("\u014a\7\37\2\2\u014a\u014c\b\24\1\2\u014b\u0143\3\2\2")
        buf.write("\2\u014b\u0145\3\2\2\2\u014b\u0147\3\2\2\2\u014b\u0149")
        buf.write("\3\2\2\2\u014c\'\3\2\2\2\u014d\u014e\7\6\2\2\u014e\u0152")
        buf.write("\b\25\1\2\u014f\u0150\7\7\2\2\u0150\u0152\b\25\1\2\u0151")
        buf.write("\u014d\3\2\2\2\u0151\u014f\3\2\2\2\u0152)\3\2\2\2\u0153")
        buf.write("\u0154\7\b\2\2\u0154\u0164\b\26\1\2\u0155\u0156\7\t\2")
        buf.write("\2\u0156\u0164\b\26\1\2\u0157\u0158\7\n\2\2\u0158\u0164")
        buf.write("\b\26\1\2\u0159\u015a\7\13\2\2\u015a\u0164\b\26\1\2\u015b")
        buf.write("\u015c\7\f\2\2\u015c\u0164\b\26\1\2\u015d\u015e\7\r\2")
        buf.write("\2\u015e\u0164\b\26\1\2\u015f\u0160\7\16\2\2\u0160\u0164")
        buf.write("\b\26\1\2\u0161\u0162\7\17\2\2\u0162\u0164\b\26\1\2\u0163")
        buf.write("\u0153\3\2\2\2\u0163\u0155\3\2\2\2\u0163\u0157\3\2\2\2")
        buf.write("\u0163\u0159\3\2\2\2\u0163\u015b\3\2\2\2\u0163\u015d\3")
        buf.write("\2\2\2\u0163\u015f\3\2\2\2\u0163\u0161\3\2\2\2\u0164+")
        buf.write("\3\2\2\2\32\66EWcg{\u0083\u0087\u008b\u0094\u00a9\u00af")
        buf.write("\u00be\u00d7\u00e7\u00eb\u0107\u010f\u011c\u0135\u0141")
        buf.write("\u014b\u0151\u0163")
        return buf.getvalue()


class DatalogParser ( Parser ):

    grammarFileName = "Datalog.g4"

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    sharedContextCache = PredictionContextCache()

    literalNames = [ "<INVALID>", "'EDB_DECL'", "'IDB_DECL'", "'RULE_DECL'", 
                     "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "<INVALID>", "'MIN'", "'MAX'", "'SUM'", 
                     "'COUNT'", "'COUNT_DISTINCT'", "<INVALID>", "':-'", 
                     "'_'", "','", "';'", "':'", "'.'", "'+'", "'-'", "'*'", 
                     "'/'", "'!'", "'[!dedup]'", "'[!set-diff]'", "'[dedup-only]'", 
                     "'!='", "'='", "'>='", "'>'", "'<='", "'<'", "'('", 
                     "')'", "'['", "']'" ]

    symbolicNames = [ "<INVALID>", "TOKEN_EDB", "TOKEN_IDB", "TOKEN_RULE", 
                      "TOKEN_INTEGER", "TOKEN_STRING", "TOKEN_INT", "TOKEN_LONG", 
                      "TOKEN_FLOAT", "TOKEN_DOUBLE", "TOKEN_VARCHAR", "TOKEN_CHAR", 
                      "TOKEN_DATE", "TOKEN_DATETIME", "TOKEN_MIN", "TOKEN_MAX", 
                      "TOKEN_SUM", "TOKEN_COUNT", "TOKEN_COUNT_DISTINCT", 
                      "TOKEN_ID", "TOKEN_BODY_HEAD_SEP", "TOKEN_ANY", "TOKEN_COMMA", 
                      "TOKEN_SEMICOLON", "TOKEN_COLON", "TOKEN_DOT", "TOKEN_PLUS", 
                      "TOKEN_MINUS", "TOKEN_MULT", "TOKEN_DIV", "TOKEN_NOT", 
                      "TOKEN_NON_DEDUP", "TOKEN_NON_SET_DIFF", "TOKEN_DEDUP_ONLY", 
                      "TOKEN_NOT_EQUALS", "TOKEN_EQUALS", "TOKEN_GREATER_EQUAL_THAN", 
                      "TOKEN_GREATER_THAN", "TOKEN_LESS_EQUAL_THAN", "TOKEN_LESS_THAN", 
                      "TOKEN_LEFT_PAREN", "TOKEN_RIGHT_PAREN", "TOKEN_LEFT_BRACKET", 
                      "TOKEN_RIGHT_BRACKET", "TOKEN_WS" ]

    RULE_datalog_edb_declare = 0
    RULE_datalog_idb_declare = 1
    RULE_datalog_relation_schema = 2
    RULE_datalog_rule_declare = 3
    RULE_datalog_program = 4
    RULE_datalog_rule = 5
    RULE_head = 6
    RULE_body = 7
    RULE_negation = 8
    RULE_atom = 9
    RULE_assign = 10
    RULE_math_expr = 11
    RULE_compare_expr = 12
    RULE_aggregation_expr = 13
    RULE_key_attribute = 14
    RULE_non_key_attribute = 15
    RULE_compare_op = 16
    RULE_aggregation_op = 17
    RULE_math_op = 18
    RULE_constant = 19
    RULE_data_type = 20

    ruleNames =  [ "datalog_edb_declare", "datalog_idb_declare", "datalog_relation_schema", 
                   "datalog_rule_declare", "datalog_program", "datalog_rule", 
                   "head", "body", "negation", "atom", "assign", "math_expr", 
                   "compare_expr", "aggregation_expr", "key_attribute", 
                   "non_key_attribute", "compare_op", "aggregation_op", 
                   "math_op", "constant", "data_type" ]

    EOF = Token.EOF
    TOKEN_EDB=1
    TOKEN_IDB=2
    TOKEN_RULE=3
    TOKEN_INTEGER=4
    TOKEN_STRING=5
    TOKEN_INT=6
    TOKEN_LONG=7
    TOKEN_FLOAT=8
    TOKEN_DOUBLE=9
    TOKEN_VARCHAR=10
    TOKEN_CHAR=11
    TOKEN_DATE=12
    TOKEN_DATETIME=13
    TOKEN_MIN=14
    TOKEN_MAX=15
    TOKEN_SUM=16
    TOKEN_COUNT=17
    TOKEN_COUNT_DISTINCT=18
    TOKEN_ID=19
    TOKEN_BODY_HEAD_SEP=20
    TOKEN_ANY=21
    TOKEN_COMMA=22
    TOKEN_SEMICOLON=23
    TOKEN_COLON=24
    TOKEN_DOT=25
    TOKEN_PLUS=26
    TOKEN_MINUS=27
    TOKEN_MULT=28
    TOKEN_DIV=29
    TOKEN_NOT=30
    TOKEN_NON_DEDUP=31
    TOKEN_NON_SET_DIFF=32
    TOKEN_DEDUP_ONLY=33
    TOKEN_NOT_EQUALS=34
    TOKEN_EQUALS=35
    TOKEN_GREATER_EQUAL_THAN=36
    TOKEN_GREATER_THAN=37
    TOKEN_LESS_EQUAL_THAN=38
    TOKEN_LESS_THAN=39
    TOKEN_LEFT_PAREN=40
    TOKEN_RIGHT_PAREN=41
    TOKEN_LEFT_BRACKET=42
    TOKEN_RIGHT_BRACKET=43
    TOKEN_WS=44

    def __init__(self, input:TokenStream, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.8")
        self._interp = ParserATNSimulator(self, self.atn, self.decisionsToDFA, self.sharedContextCache)
        self._predicates = None




    class AtomArg():
        def __init__(self, arg_name, arg_type):
            self.name = arg_name
            self.type = arg_type



    class Datalog_edb_declareContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.schema1 = None # Datalog_relation_schemaContext
            self.schema2 = None # Datalog_relation_schemaContext

        def TOKEN_EDB(self):
            return self.getToken(DatalogParser.TOKEN_EDB, 0)

        def TOKEN_COLON(self):
            return self.getToken(DatalogParser.TOKEN_COLON, 0)

        def datalog_relation_schema(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Datalog_relation_schemaContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Datalog_relation_schemaContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_edb_declare




    def datalog_edb_declare(self):

        localctx = DatalogParser.Datalog_edb_declareContext(self, self._ctx, self.state)
        self.enterRule(localctx, 0, self.RULE_datalog_edb_declare)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            edb_list = []
            self.state = 43
            self.match(DatalogParser.TOKEN_EDB)
            self.state = 44
            self.match(DatalogParser.TOKEN_COLON)
            self.state = 45
            localctx.schema1 = self.datalog_relation_schema()
            edb_list.append(localctx.schema1.r)
            self.state = 52
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_ID:
                self.state = 47
                localctx.schema2 = self.datalog_relation_schema()
                edb_list.append(localctx.schema2.r)
                self.state = 54
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            localctx.r = edb_list
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_idb_declareContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.schema1 = None # Datalog_relation_schemaContext
            self.schema2 = None # Datalog_relation_schemaContext

        def TOKEN_IDB(self):
            return self.getToken(DatalogParser.TOKEN_IDB, 0)

        def TOKEN_COLON(self):
            return self.getToken(DatalogParser.TOKEN_COLON, 0)

        def datalog_relation_schema(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Datalog_relation_schemaContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Datalog_relation_schemaContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_idb_declare




    def datalog_idb_declare(self):

        localctx = DatalogParser.Datalog_idb_declareContext(self, self._ctx, self.state)
        self.enterRule(localctx, 2, self.RULE_datalog_idb_declare)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            idb_list = []
            self.state = 58
            self.match(DatalogParser.TOKEN_IDB)
            self.state = 59
            self.match(DatalogParser.TOKEN_COLON)
            self.state = 60
            localctx.schema1 = self.datalog_relation_schema()
            idb_list.append(localctx.schema1.r)
            self.state = 67
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_ID:
                self.state = 62
                localctx.schema2 = self.datalog_relation_schema()
                idb_list.append(localctx.schema2.r)
                self.state = 69
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            localctx.r = idb_list
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_relation_schemaContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.relation_name = None # Token
            self.t1 = None # Non_key_attributeContext
            self.dt1 = None # Data_typeContext
            self.t2 = None # Key_attributeContext
            self.dt2 = None # Data_typeContext
            self.t3 = None # Non_key_attributeContext
            self.dt3 = None # Data_typeContext
            self.t4 = None # Key_attributeContext
            self.dt4 = None # Data_typeContext

        def TOKEN_LEFT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_PAREN, 0)

        def TOKEN_RIGHT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_PAREN, 0)

        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def non_key_attribute(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Non_key_attributeContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Non_key_attributeContext,i)


        def data_type(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Data_typeContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Data_typeContext,i)


        def key_attribute(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Key_attributeContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Key_attributeContext,i)


        def TOKEN_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_COMMA)
            else:
                return self.getToken(DatalogParser.TOKEN_COMMA, i)

        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_relation_schema




    def datalog_relation_schema(self):

        localctx = DatalogParser.Datalog_relation_schemaContext(self, self._ctx, self.state)
        self.enterRule(localctx, 4, self.RULE_datalog_relation_schema)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            schema = {'name': '', 'attributes': [], 'keys': []}
            self.state = 73
            localctx.relation_name = self.match(DatalogParser.TOKEN_ID)
            schema['name'] = (None if localctx.relation_name is None else localctx.relation_name.text)
            self.state = 75
            self.match(DatalogParser.TOKEN_LEFT_PAREN)
            self.state = 85
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_ID]:
                self.state = 76
                localctx.t1 = self.non_key_attribute()
                self.state = 77
                localctx.dt1 = self.data_type()
                schema['attributes'].append(self.AtomArg(localctx.t1.r, localctx.dt1.r))
                pass
            elif token in [DatalogParser.TOKEN_LEFT_BRACKET]:
                self.state = 80
                localctx.t2 = self.key_attribute()
                schema['keys'].append(localctx.t2.r)
                self.state = 82
                localctx.dt2 = self.data_type()
                schema['attributes'].append(self.AtomArg(localctx.t2.r, localctx.dt2.r))
                pass
            else:
                raise NoViableAltException(self)

            self.state = 101
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_COMMA:
                self.state = 87
                self.match(DatalogParser.TOKEN_COMMA)
                self.state = 97
                self._errHandler.sync(self)
                token = self._input.LA(1)
                if token in [DatalogParser.TOKEN_ID]:
                    self.state = 88
                    localctx.t3 = self.non_key_attribute()
                    self.state = 89
                    localctx.dt3 = self.data_type()
                    schema['attributes'].append(self.AtomArg(localctx.t3.r, localctx.dt3.r))
                    pass
                elif token in [DatalogParser.TOKEN_LEFT_BRACKET]:
                    self.state = 92
                    localctx.t4 = self.key_attribute()
                    schema['keys'].append(localctx.t4.r)
                    self.state = 94
                    localctx.dt4 = self.data_type()
                    schema['attributes'].append(self.AtomArg(localctx.t4.r, localctx.dt4.r))
                    pass
                else:
                    raise NoViableAltException(self)

                self.state = 103
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 104
            self.match(DatalogParser.TOKEN_RIGHT_PAREN)
            localctx.r = schema
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_rule_declareContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.dp = None # Datalog_programContext

        def TOKEN_RULE(self):
            return self.getToken(DatalogParser.TOKEN_RULE, 0)

        def TOKEN_COLON(self):
            return self.getToken(DatalogParser.TOKEN_COLON, 0)

        def EOF(self):
            return self.getToken(DatalogParser.EOF, 0)

        def datalog_program(self):
            return self.getTypedRuleContext(DatalogParser.Datalog_programContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_rule_declare




    def datalog_rule_declare(self):

        localctx = DatalogParser.Datalog_rule_declareContext(self, self._ctx, self.state)
        self.enterRule(localctx, 6, self.RULE_datalog_rule_declare)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 107
            self.match(DatalogParser.TOKEN_RULE)
            self.state = 108
            self.match(DatalogParser.TOKEN_COLON)
            self.state = 109
            localctx.dp = self.datalog_program()
            localctx.r = localctx.dp.r
            self.state = 111
            self.match(DatalogParser.EOF)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_programContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.r1 = None # Datalog_ruleContext
            self.r2 = None # Datalog_ruleContext

        def datalog_rule(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Datalog_ruleContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Datalog_ruleContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_program




    def datalog_program(self):

        localctx = DatalogParser.Datalog_programContext(self, self._ctx, self.state)
        self.enterRule(localctx, 8, self.RULE_datalog_program)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            rule_list = []
            self.state = 114
            localctx.r1 = self.datalog_rule()
            rule_list.append(localctx.r1.r)
            self.state = 121
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << DatalogParser.TOKEN_ID) | (1 << DatalogParser.TOKEN_NON_DEDUP) | (1 << DatalogParser.TOKEN_NON_SET_DIFF) | (1 << DatalogParser.TOKEN_DEDUP_ONLY))) != 0):
                self.state = 116
                localctx.r2 = self.datalog_rule()
                rule_list.append(localctx.r2.r)
                self.state = 123
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            localctx.r = rule_list
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Datalog_ruleContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.h = None # HeadContext
            self.b = None # BodyContext

        def TOKEN_BODY_HEAD_SEP(self):
            return self.getToken(DatalogParser.TOKEN_BODY_HEAD_SEP, 0)

        def TOKEN_DOT(self):
            return self.getToken(DatalogParser.TOKEN_DOT, 0)

        def head(self):
            return self.getTypedRuleContext(DatalogParser.HeadContext,0)


        def TOKEN_NON_DEDUP(self):
            return self.getToken(DatalogParser.TOKEN_NON_DEDUP, 0)

        def TOKEN_NON_SET_DIFF(self):
            return self.getToken(DatalogParser.TOKEN_NON_SET_DIFF, 0)

        def TOKEN_DEDUP_ONLY(self):
            return self.getToken(DatalogParser.TOKEN_DEDUP_ONLY, 0)

        def body(self):
            return self.getTypedRuleContext(DatalogParser.BodyContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_datalog_rule




    def datalog_rule(self):

        localctx = DatalogParser.Datalog_ruleContext(self, self._ctx, self.state)
        self.enterRule(localctx, 10, self.RULE_datalog_rule)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            rule_dic = {}
            self.state = 129
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==DatalogParser.TOKEN_NON_DEDUP:
                self.state = 127
                self.match(DatalogParser.TOKEN_NON_DEDUP)
                rule_dic['non-dedup'] = True


            self.state = 133
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==DatalogParser.TOKEN_NON_SET_DIFF:
                self.state = 131
                self.match(DatalogParser.TOKEN_NON_SET_DIFF)
                rule_dic['non-set-diff'] = True


            self.state = 137
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==DatalogParser.TOKEN_DEDUP_ONLY:
                self.state = 135
                self.match(DatalogParser.TOKEN_DEDUP_ONLY)
                rule_dic['dedup-only'] = True


            self.state = 139
            localctx.h = self.head()
            rule_dic['head'] = localctx.h.r
            self.state = 141
            self.match(DatalogParser.TOKEN_BODY_HEAD_SEP)
            rule_dic['body'] = None
            self.state = 146
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << DatalogParser.TOKEN_INTEGER) | (1 << DatalogParser.TOKEN_ID) | (1 << DatalogParser.TOKEN_NOT))) != 0):
                self.state = 143
                localctx.b = self.body()
                rule_dic['body'] = localctx.b.r


            self.state = 148
            self.match(DatalogParser.TOKEN_DOT)
            localctx.r = rule_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class HeadContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a = None # AtomContext

        def atom(self):
            return self.getTypedRuleContext(DatalogParser.AtomContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_head




    def head(self):

        localctx = DatalogParser.HeadContext(self, self._ctx, self.state)
        self.enterRule(localctx, 12, self.RULE_head)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 151
            localctx.a = self.atom()
            localctx.r = localctx.a.r
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class BodyContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.b1 = None # AtomContext
            self.b2 = None # Compare_exprContext
            self.b3 = None # AssignContext
            self.b4 = None # NegationContext
            self.b5 = None # AtomContext
            self.b6 = None # Compare_exprContext
            self.b7 = None # AssignContext
            self.b8 = None # NegationContext

        def TOKEN_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_COMMA)
            else:
                return self.getToken(DatalogParser.TOKEN_COMMA, i)

        def atom(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.AtomContext)
            else:
                return self.getTypedRuleContext(DatalogParser.AtomContext,i)


        def compare_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Compare_exprContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Compare_exprContext,i)


        def assign(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.AssignContext)
            else:
                return self.getTypedRuleContext(DatalogParser.AssignContext,i)


        def negation(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.NegationContext)
            else:
                return self.getTypedRuleContext(DatalogParser.NegationContext,i)


        def getRuleIndex(self):
            return DatalogParser.RULE_body




    def body(self):

        localctx = DatalogParser.BodyContext(self, self._ctx, self.state)
        self.enterRule(localctx, 14, self.RULE_body)
        try:
            self.enterOuterAlt(localctx, 1)
            body_dic = {'atoms':[], 'compares': [], 'assigns':[], 'negations':[]}
            self.state = 173
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,11,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 167
                    self._errHandler.sync(self)
                    la_ = self._interp.adaptivePredict(self._input,10,self._ctx)
                    if la_ == 1:
                        self.state = 155
                        localctx.b1 = self.atom()
                        body_dic['atoms'].append(localctx.b1.r)
                        pass

                    elif la_ == 2:
                        self.state = 158
                        localctx.b2 = self.compare_expr()
                        body_dic['compares'].append(localctx.b2.r)
                        pass

                    elif la_ == 3:
                        self.state = 161
                        localctx.b3 = self.assign()
                        body_dic['assigns'].append(localctx.b3.r)
                        pass

                    elif la_ == 4:
                        self.state = 164
                        localctx.b4 = self.negation()
                        body_dic['negations'].append(localctx.b4.r)
                        pass


                    self.state = 169
                    self.match(DatalogParser.TOKEN_COMMA) 
                self.state = 175
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,11,self._ctx)

            self.state = 188
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,12,self._ctx)
            if la_ == 1:
                self.state = 176
                localctx.b5 = self.atom()
                body_dic['atoms'].append(localctx.b5.r)
                pass

            elif la_ == 2:
                self.state = 179
                localctx.b6 = self.compare_expr()
                body_dic['compares'].append(localctx.b6.r)
                pass

            elif la_ == 3:
                self.state = 182
                localctx.b7 = self.assign()
                body_dic['assigns'].append(localctx.b7.r)
                pass

            elif la_ == 4:
                self.state = 185
                localctx.b8 = self.negation()
                body_dic['negations'].append(localctx.b8.r)
                pass


            localctx.r = body_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class NegationContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a = None # AtomContext

        def TOKEN_NOT(self):
            return self.getToken(DatalogParser.TOKEN_NOT, 0)

        def atom(self):
            return self.getTypedRuleContext(DatalogParser.AtomContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_negation




    def negation(self):

        localctx = DatalogParser.NegationContext(self, self._ctx, self.state)
        self.enterRule(localctx, 16, self.RULE_negation)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 192
            self.match(DatalogParser.TOKEN_NOT)
            self.state = 193
            localctx.a = self.atom()
            localctx.r = localctx.a.r
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AtomContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token
            self.a2 = None # Token
            self.a3 = None # Aggregation_exprContext
            self.a4 = None # Token
            self.a5 = None # ConstantContext
            self.a6 = None # Math_exprContext
            self.a7 = None # Token
            self.a8 = None # Aggregation_exprContext
            self.a9 = None # Token
            self.a10 = None # ConstantContext
            self.a11 = None # Math_exprContext

        def TOKEN_LEFT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_PAREN, 0)

        def TOKEN_RIGHT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_PAREN, 0)

        def TOKEN_ID(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ID)
            else:
                return self.getToken(DatalogParser.TOKEN_ID, i)

        def aggregation_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Aggregation_exprContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Aggregation_exprContext,i)


        def TOKEN_ANY(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ANY)
            else:
                return self.getToken(DatalogParser.TOKEN_ANY, i)

        def constant(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.ConstantContext)
            else:
                return self.getTypedRuleContext(DatalogParser.ConstantContext,i)


        def math_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(DatalogParser.Math_exprContext)
            else:
                return self.getTypedRuleContext(DatalogParser.Math_exprContext,i)


        def TOKEN_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_COMMA)
            else:
                return self.getToken(DatalogParser.TOKEN_COMMA, i)

        def getRuleIndex(self):
            return DatalogParser.RULE_atom




    def atom(self):

        localctx = DatalogParser.AtomContext(self, self._ctx, self.state)
        self.enterRule(localctx, 18, self.RULE_atom)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            atom_dic = {'name': None, 'arg_list':[]}
            self.state = 197
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            atom_dic['name'] = (None if localctx.a1 is None else localctx.a1.text)
            self.state = 199
            self.match(DatalogParser.TOKEN_LEFT_PAREN)
            self.state = 213
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,13,self._ctx)
            if la_ == 1:
                self.state = 200
                localctx.a2 = self.match(DatalogParser.TOKEN_ID)
                atom_dic['arg_list'].append(self.AtomArg((None if localctx.a2 is None else localctx.a2.text), 'variable'))
                pass

            elif la_ == 2:
                self.state = 202
                localctx.a3 = self.aggregation_expr()
                atom_dic['arg_list'].append(self.AtomArg(localctx.a3.r, 'aggregation'))
                pass

            elif la_ == 3:
                self.state = 205
                localctx.a4 = self.match(DatalogParser.TOKEN_ANY)
                atom_dic['arg_list'].append(self.AtomArg((None if localctx.a4 is None else localctx.a4.text), 'any'))
                pass

            elif la_ == 4:
                self.state = 207
                localctx.a5 = self.constant()
                atom_dic['arg_list'].append(self.AtomArg((None if localctx.a5 is None else self._input.getText(localctx.a5.start,localctx.a5.stop)), 'constant'))
                pass

            elif la_ == 5:
                self.state = 210
                localctx.a6 = self.math_expr()
                atom_dic['arg_list'].append(self.AtomArg(localctx.a6.r, 'math_expr'))
                pass


            self.state = 233
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==DatalogParser.TOKEN_COMMA:
                self.state = 215
                self.match(DatalogParser.TOKEN_COMMA)
                self.state = 229
                self._errHandler.sync(self)
                la_ = self._interp.adaptivePredict(self._input,14,self._ctx)
                if la_ == 1:
                    self.state = 216
                    localctx.a7 = self.match(DatalogParser.TOKEN_ID)
                    atom_dic['arg_list'].append(self.AtomArg((None if localctx.a7 is None else localctx.a7.text), 'variable'))
                    pass

                elif la_ == 2:
                    self.state = 218
                    localctx.a8 = self.aggregation_expr()
                    atom_dic['arg_list'].append(self.AtomArg(localctx.a8.r, 'aggregation'))
                    pass

                elif la_ == 3:
                    self.state = 221
                    localctx.a9 = self.match(DatalogParser.TOKEN_ANY)
                    atom_dic['arg_list'].append(self.AtomArg((None if localctx.a9 is None else localctx.a9.text), 'any'))
                    pass

                elif la_ == 4:
                    self.state = 223
                    localctx.a10 = self.constant()
                    atom_dic['arg_list'].append(self.AtomArg((None if localctx.a10 is None else self._input.getText(localctx.a10.start,localctx.a10.stop)), 'constant'))
                    pass

                elif la_ == 5:
                    self.state = 226
                    localctx.a11 = self.math_expr()
                    atom_dic['arg_list'].append(self.AtomArg(localctx.a11.r, 'math_expr'))
                    pass


                self.state = 235
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 236
            self.match(DatalogParser.TOKEN_RIGHT_PAREN)
            localctx.r = atom_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AssignContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token
            self.a2 = None # Math_exprContext

        def TOKEN_EQUALS(self):
            return self.getToken(DatalogParser.TOKEN_EQUALS, 0)

        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def math_expr(self):
            return self.getTypedRuleContext(DatalogParser.Math_exprContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_assign




    def assign(self):

        localctx = DatalogParser.AssignContext(self, self._ctx, self.state)
        self.enterRule(localctx, 20, self.RULE_assign)
        try:
            self.enterOuterAlt(localctx, 1)
            assign_dic = {}
            self.state = 240
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            assign_dic['lhs'] = (None if localctx.a1 is None else localctx.a1.text)
            self.state = 242
            self.match(DatalogParser.TOKEN_EQUALS)
            self.state = 243
            localctx.a2 = self.math_expr()
            assign_dic['rhs'] = localctx.a2.r
            localctx.r = assign_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Math_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.m1 = None # Token
            self.m2 = None # Math_opContext
            self.m3 = None # Token

        def TOKEN_ID(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ID)
            else:
                return self.getToken(DatalogParser.TOKEN_ID, i)

        def math_op(self):
            return self.getTypedRuleContext(DatalogParser.Math_opContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_math_expr




    def math_expr(self):

        localctx = DatalogParser.Math_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 22, self.RULE_math_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            math_dic = {}
            self.state = 248
            localctx.m1 = self.match(DatalogParser.TOKEN_ID)
            math_dic['lhs'] = (None if localctx.m1 is None else localctx.m1.text)
            self.state = 250
            localctx.m2 = self.math_op()
            math_dic['op'] = localctx.m2.r
            self.state = 252
            localctx.m3 = self.match(DatalogParser.TOKEN_ID)
            math_dic['rhs'] = (None if localctx.m3 is None else localctx.m3.text)
            localctx.r = math_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Compare_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.c1 = None # Token
            self.c2 = None # Token
            self.op = None # Compare_opContext
            self.c4 = None # Token
            self.c5 = None # Token

        def compare_op(self):
            return self.getTypedRuleContext(DatalogParser.Compare_opContext,0)


        def TOKEN_ID(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_ID)
            else:
                return self.getToken(DatalogParser.TOKEN_ID, i)

        def TOKEN_INTEGER(self, i:int=None):
            if i is None:
                return self.getTokens(DatalogParser.TOKEN_INTEGER)
            else:
                return self.getToken(DatalogParser.TOKEN_INTEGER, i)

        def getRuleIndex(self):
            return DatalogParser.RULE_compare_expr




    def compare_expr(self):

        localctx = DatalogParser.Compare_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 24, self.RULE_compare_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            compare_dic = {}
            self.state = 261
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_ID]:
                self.state = 257
                localctx.c1 = self.match(DatalogParser.TOKEN_ID)
                compare_dic['lhs'] = [(None if localctx.c1 is None else localctx.c1.text), 'var']
                pass
            elif token in [DatalogParser.TOKEN_INTEGER]:
                self.state = 259
                localctx.c2 = self.match(DatalogParser.TOKEN_INTEGER)
                compare_dic['lhs'] = [(None if localctx.c2 is None else localctx.c2.text), 'num']
                pass
            else:
                raise NoViableAltException(self)

            self.state = 263
            localctx.op = self.compare_op()
            compare_dic['op'] = localctx.op.r
            self.state = 269
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_ID]:
                self.state = 265
                localctx.c4 = self.match(DatalogParser.TOKEN_ID)
                compare_dic['rhs'] = [(None if localctx.c4 is None else localctx.c4.text), 'var']
                pass
            elif token in [DatalogParser.TOKEN_INTEGER]:
                self.state = 267
                localctx.c5 = self.match(DatalogParser.TOKEN_INTEGER)
                compare_dic['rhs'] = [(None if localctx.c5 is None else localctx.c5.text), 'num']
                pass
            else:
                raise NoViableAltException(self)

            localctx.r = compare_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Aggregation_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Aggregation_opContext
            self.a2 = None # Token
            self.a3 = None # Math_exprContext

        def TOKEN_LEFT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_PAREN, 0)

        def TOKEN_RIGHT_PAREN(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_PAREN, 0)

        def aggregation_op(self):
            return self.getTypedRuleContext(DatalogParser.Aggregation_opContext,0)


        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def math_expr(self):
            return self.getTypedRuleContext(DatalogParser.Math_exprContext,0)


        def getRuleIndex(self):
            return DatalogParser.RULE_aggregation_expr




    def aggregation_expr(self):

        localctx = DatalogParser.Aggregation_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 26, self.RULE_aggregation_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            agg_dic = {'agg_op': None, 'agg_arg': None}
            self.state = 274
            localctx.a1 = self.aggregation_op()
            agg_dic['agg_op'] = localctx.a1.r
            self.state = 276
            self.match(DatalogParser.TOKEN_LEFT_PAREN)
            self.state = 282
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,18,self._ctx)
            if la_ == 1:
                self.state = 277
                localctx.a2 = self.match(DatalogParser.TOKEN_ID)
                agg_dic['agg_arg'] = {'type': 'attribute', 'content': (None if localctx.a2 is None else localctx.a2.text)}
                pass

            elif la_ == 2:
                self.state = 279
                localctx.a3 = self.math_expr()
                agg_dic['agg_arg'] = {'type': 'math_expr', 'content': localctx.a3.r}
                pass


            self.state = 284
            self.match(DatalogParser.TOKEN_RIGHT_PAREN)
            localctx.r = agg_dic
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Key_attributeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token

        def TOKEN_LEFT_BRACKET(self):
            return self.getToken(DatalogParser.TOKEN_LEFT_BRACKET, 0)

        def TOKEN_RIGHT_BRACKET(self):
            return self.getToken(DatalogParser.TOKEN_RIGHT_BRACKET, 0)

        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_key_attribute




    def key_attribute(self):

        localctx = DatalogParser.Key_attributeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 28, self.RULE_key_attribute)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 287
            self.match(DatalogParser.TOKEN_LEFT_BRACKET)
            self.state = 288
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            localctx.r = (None if localctx.a1 is None else localctx.a1.text)
            self.state = 290
            self.match(DatalogParser.TOKEN_RIGHT_BRACKET)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Non_key_attributeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.a1 = None # Token

        def TOKEN_ID(self):
            return self.getToken(DatalogParser.TOKEN_ID, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_non_key_attribute




    def non_key_attribute(self):

        localctx = DatalogParser.Non_key_attributeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 30, self.RULE_non_key_attribute)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 292
            localctx.a1 = self.match(DatalogParser.TOKEN_ID)
            localctx.r = (None if localctx.a1 is None else localctx.a1.text)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Compare_opContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.op1 = None # Token
            self.op2 = None # Token
            self.op3 = None # Token
            self.op4 = None # Token
            self.op5 = None # Token
            self.op6 = None # Token

        def TOKEN_NOT_EQUALS(self):
            return self.getToken(DatalogParser.TOKEN_NOT_EQUALS, 0)

        def TOKEN_EQUALS(self):
            return self.getToken(DatalogParser.TOKEN_EQUALS, 0)

        def TOKEN_GREATER_THAN(self):
            return self.getToken(DatalogParser.TOKEN_GREATER_THAN, 0)

        def TOKEN_GREATER_EQUAL_THAN(self):
            return self.getToken(DatalogParser.TOKEN_GREATER_EQUAL_THAN, 0)

        def TOKEN_LESS_THAN(self):
            return self.getToken(DatalogParser.TOKEN_LESS_THAN, 0)

        def TOKEN_LESS_EQUAL_THAN(self):
            return self.getToken(DatalogParser.TOKEN_LESS_EQUAL_THAN, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_compare_op




    def compare_op(self):

        localctx = DatalogParser.Compare_opContext(self, self._ctx, self.state)
        self.enterRule(localctx, 32, self.RULE_compare_op)
        try:
            self.state = 307
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_NOT_EQUALS]:
                self.enterOuterAlt(localctx, 1)
                self.state = 295
                localctx.op1 = self.match(DatalogParser.TOKEN_NOT_EQUALS)
                localctx.r = (None if localctx.op1 is None else localctx.op1.text)
                pass
            elif token in [DatalogParser.TOKEN_EQUALS]:
                self.enterOuterAlt(localctx, 2)
                self.state = 297
                localctx.op2 = self.match(DatalogParser.TOKEN_EQUALS)
                localctx.r = (None if localctx.op2 is None else localctx.op2.text)
                pass
            elif token in [DatalogParser.TOKEN_GREATER_THAN]:
                self.enterOuterAlt(localctx, 3)
                self.state = 299
                localctx.op3 = self.match(DatalogParser.TOKEN_GREATER_THAN)
                localctx.r = (None if localctx.op3 is None else localctx.op3.text)
                pass
            elif token in [DatalogParser.TOKEN_GREATER_EQUAL_THAN]:
                self.enterOuterAlt(localctx, 4)
                self.state = 301
                localctx.op4 = self.match(DatalogParser.TOKEN_GREATER_EQUAL_THAN)
                localctx.r = (None if localctx.op4 is None else localctx.op4.text)
                pass
            elif token in [DatalogParser.TOKEN_LESS_THAN]:
                self.enterOuterAlt(localctx, 5)
                self.state = 303
                localctx.op5 = self.match(DatalogParser.TOKEN_LESS_THAN)
                localctx.r = (None if localctx.op5 is None else localctx.op5.text)
                pass
            elif token in [DatalogParser.TOKEN_LESS_EQUAL_THAN]:
                self.enterOuterAlt(localctx, 6)
                self.state = 305
                localctx.op6 = self.match(DatalogParser.TOKEN_LESS_EQUAL_THAN)
                localctx.r = (None if localctx.op6 is None else localctx.op6.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Aggregation_opContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.op1 = None # Token
            self.op2 = None # Token
            self.op3 = None # Token
            self.op4 = None # Token
            self.op5 = None # Token

        def TOKEN_MIN(self):
            return self.getToken(DatalogParser.TOKEN_MIN, 0)

        def TOKEN_MAX(self):
            return self.getToken(DatalogParser.TOKEN_MAX, 0)

        def TOKEN_SUM(self):
            return self.getToken(DatalogParser.TOKEN_SUM, 0)

        def TOKEN_COUNT(self):
            return self.getToken(DatalogParser.TOKEN_COUNT, 0)

        def TOKEN_COUNT_DISTINCT(self):
            return self.getToken(DatalogParser.TOKEN_COUNT_DISTINCT, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_aggregation_op




    def aggregation_op(self):

        localctx = DatalogParser.Aggregation_opContext(self, self._ctx, self.state)
        self.enterRule(localctx, 34, self.RULE_aggregation_op)
        try:
            self.state = 319
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_MIN]:
                self.enterOuterAlt(localctx, 1)
                self.state = 309
                localctx.op1 = self.match(DatalogParser.TOKEN_MIN)
                localctx.r = (None if localctx.op1 is None else localctx.op1.text)
                pass
            elif token in [DatalogParser.TOKEN_MAX]:
                self.enterOuterAlt(localctx, 2)
                self.state = 311
                localctx.op2 = self.match(DatalogParser.TOKEN_MAX)
                localctx.r = (None if localctx.op2 is None else localctx.op2.text)
                pass
            elif token in [DatalogParser.TOKEN_SUM]:
                self.enterOuterAlt(localctx, 3)
                self.state = 313
                localctx.op3 = self.match(DatalogParser.TOKEN_SUM)
                localctx.r = (None if localctx.op3 is None else localctx.op3.text)
                pass
            elif token in [DatalogParser.TOKEN_COUNT]:
                self.enterOuterAlt(localctx, 4)
                self.state = 315
                localctx.op4 = self.match(DatalogParser.TOKEN_COUNT)
                localctx.r = (None if localctx.op4 is None else localctx.op4.text)
                pass
            elif token in [DatalogParser.TOKEN_COUNT_DISTINCT]:
                self.enterOuterAlt(localctx, 5)
                self.state = 317
                localctx.op5 = self.match(DatalogParser.TOKEN_COUNT_DISTINCT)
                localctx.r = (None if localctx.op5 is None else localctx.op5.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Math_opContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.op1 = None # Token
            self.op2 = None # Token
            self.op3 = None # Token
            self.op4 = None # Token

        def TOKEN_PLUS(self):
            return self.getToken(DatalogParser.TOKEN_PLUS, 0)

        def TOKEN_MINUS(self):
            return self.getToken(DatalogParser.TOKEN_MINUS, 0)

        def TOKEN_MULT(self):
            return self.getToken(DatalogParser.TOKEN_MULT, 0)

        def TOKEN_DIV(self):
            return self.getToken(DatalogParser.TOKEN_DIV, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_math_op




    def math_op(self):

        localctx = DatalogParser.Math_opContext(self, self._ctx, self.state)
        self.enterRule(localctx, 36, self.RULE_math_op)
        try:
            self.state = 329
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_PLUS]:
                self.enterOuterAlt(localctx, 1)
                self.state = 321
                localctx.op1 = self.match(DatalogParser.TOKEN_PLUS)
                localctx.r = (None if localctx.op1 is None else localctx.op1.text)
                pass
            elif token in [DatalogParser.TOKEN_MINUS]:
                self.enterOuterAlt(localctx, 2)
                self.state = 323
                localctx.op2 = self.match(DatalogParser.TOKEN_MINUS)
                localctx.r = (None if localctx.op2 is None else localctx.op2.text)
                pass
            elif token in [DatalogParser.TOKEN_MULT]:
                self.enterOuterAlt(localctx, 3)
                self.state = 325
                localctx.op3 = self.match(DatalogParser.TOKEN_MULT)
                localctx.r = (None if localctx.op3 is None else localctx.op3.text)
                pass
            elif token in [DatalogParser.TOKEN_DIV]:
                self.enterOuterAlt(localctx, 4)
                self.state = 327
                localctx.op4 = self.match(DatalogParser.TOKEN_DIV)
                localctx.r = (None if localctx.op4 is None else localctx.op4.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ConstantContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.c1 = None # Token
            self.c2 = None # Token

        def TOKEN_INTEGER(self):
            return self.getToken(DatalogParser.TOKEN_INTEGER, 0)

        def TOKEN_STRING(self):
            return self.getToken(DatalogParser.TOKEN_STRING, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_constant




    def constant(self):

        localctx = DatalogParser.ConstantContext(self, self._ctx, self.state)
        self.enterRule(localctx, 38, self.RULE_constant)
        try:
            self.state = 335
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_INTEGER]:
                self.enterOuterAlt(localctx, 1)
                self.state = 331
                localctx.c1 = self.match(DatalogParser.TOKEN_INTEGER)
                localctx.r = (None if localctx.c1 is None else localctx.c1.text)
                pass
            elif token in [DatalogParser.TOKEN_STRING]:
                self.enterOuterAlt(localctx, 2)
                self.state = 333
                localctx.c2 = self.match(DatalogParser.TOKEN_STRING)
                localctx.r = (None if localctx.c2 is None else localctx.c2.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Data_typeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser
            self.r = None
            self.dt1 = None # Token
            self.dt2 = None # Token
            self.dt3 = None # Token
            self.dt4 = None # Token
            self.dt5 = None # Token
            self.dt6 = None # Token
            self.dt7 = None # Token
            self.dt8 = None # Token

        def TOKEN_INT(self):
            return self.getToken(DatalogParser.TOKEN_INT, 0)

        def TOKEN_LONG(self):
            return self.getToken(DatalogParser.TOKEN_LONG, 0)

        def TOKEN_FLOAT(self):
            return self.getToken(DatalogParser.TOKEN_FLOAT, 0)

        def TOKEN_DOUBLE(self):
            return self.getToken(DatalogParser.TOKEN_DOUBLE, 0)

        def TOKEN_VARCHAR(self):
            return self.getToken(DatalogParser.TOKEN_VARCHAR, 0)

        def TOKEN_CHAR(self):
            return self.getToken(DatalogParser.TOKEN_CHAR, 0)

        def TOKEN_DATE(self):
            return self.getToken(DatalogParser.TOKEN_DATE, 0)

        def TOKEN_DATETIME(self):
            return self.getToken(DatalogParser.TOKEN_DATETIME, 0)

        def getRuleIndex(self):
            return DatalogParser.RULE_data_type




    def data_type(self):

        localctx = DatalogParser.Data_typeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 40, self.RULE_data_type)
        try:
            self.state = 353
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [DatalogParser.TOKEN_INT]:
                self.enterOuterAlt(localctx, 1)
                self.state = 337
                localctx.dt1 = self.match(DatalogParser.TOKEN_INT)
                localctx.r = (None if localctx.dt1 is None else localctx.dt1.text)
                pass
            elif token in [DatalogParser.TOKEN_LONG]:
                self.enterOuterAlt(localctx, 2)
                self.state = 339
                localctx.dt2 = self.match(DatalogParser.TOKEN_LONG)
                localctx.r = (None if localctx.dt2 is None else localctx.dt2.text)
                pass
            elif token in [DatalogParser.TOKEN_FLOAT]:
                self.enterOuterAlt(localctx, 3)
                self.state = 341
                localctx.dt3 = self.match(DatalogParser.TOKEN_FLOAT)
                localctx.r = (None if localctx.dt3 is None else localctx.dt3.text)
                pass
            elif token in [DatalogParser.TOKEN_DOUBLE]:
                self.enterOuterAlt(localctx, 4)
                self.state = 343
                localctx.dt4 = self.match(DatalogParser.TOKEN_DOUBLE)
                localctx.r = (None if localctx.dt4 is None else localctx.dt4.text)
                pass
            elif token in [DatalogParser.TOKEN_VARCHAR]:
                self.enterOuterAlt(localctx, 5)
                self.state = 345
                localctx.dt5 = self.match(DatalogParser.TOKEN_VARCHAR)
                localctx.r = (None if localctx.dt5 is None else localctx.dt5.text)
                pass
            elif token in [DatalogParser.TOKEN_CHAR]:
                self.enterOuterAlt(localctx, 6)
                self.state = 347
                localctx.dt6 = self.match(DatalogParser.TOKEN_CHAR)
                localctx.r = (None if localctx.dt6 is None else localctx.dt6.text)
                pass
            elif token in [DatalogParser.TOKEN_DATE]:
                self.enterOuterAlt(localctx, 7)
                self.state = 349
                localctx.dt7 = self.match(DatalogParser.TOKEN_DATE)
                localctx.r = (None if localctx.dt7 is None else localctx.dt7.text)
                pass
            elif token in [DatalogParser.TOKEN_DATETIME]:
                self.enterOuterAlt(localctx, 8)
                self.state = 351
                localctx.dt8 = self.match(DatalogParser.TOKEN_DATETIME)
                localctx.r = (None if localctx.dt8 is None else localctx.dt8.text)
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx





